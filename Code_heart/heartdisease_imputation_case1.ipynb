{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요한 라이브러리 Import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score,roc_auc_score,mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import random\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train data와 Test data 로드하기\n",
    "\n",
    "train_data=pd.read_csv('/dshome/WoongLab/heo/construction_oil/preprocessed_data/heart_train_data.csv')\n",
    "test_data=pd.read_csv('/dshome/WoongLab/heo/construction_oil/preprocessed_data/heart_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stage_features=['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke',\n",
    "       'Diabetes', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump',\n",
    "       'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth',\n",
    "       'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
    "\n",
    "test_stage_features=['CholCheck','HvyAlcoholConsump','AnyHealthcare','Veggies','Fruits',\n",
    "                     'NoDocbcCost','PhysActivity','Education','MentHlth','Smoker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202939</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202940</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202941</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202942</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202943</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202944 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  Diabetes  \\\n",
       "0          1.0       1.0        1.0  27.0     0.0     0.0         0   \n",
       "1          1.0       1.0        1.0  25.0     0.0     0.0         0   \n",
       "2          0.0       0.0        1.0  24.0     1.0     0.0         0   \n",
       "3          1.0       1.0        1.0  24.0     1.0     0.0         0   \n",
       "4          0.0       0.0        1.0  20.0     0.0     0.0         0   \n",
       "...        ...       ...        ...   ...     ...     ...       ...   \n",
       "202939     1.0       0.0        1.0  41.0     1.0     0.0         0   \n",
       "202940     1.0       1.0        1.0  35.0     1.0     1.0         0   \n",
       "202941     1.0       1.0        1.0  25.0     0.0     0.0         0   \n",
       "202942     0.0       0.0        1.0  21.0     0.0     0.0         0   \n",
       "202943     1.0       1.0        1.0  34.0     1.0     0.0         0   \n",
       "\n",
       "        PhysActivity  Fruits  Veggies  ...  NoDocbcCost  GenHlth  MentHlth  \\\n",
       "0                1.0     1.0      1.0  ...          0.0        2       2.0   \n",
       "1                1.0     1.0      1.0  ...          0.0        0       0.0   \n",
       "2                1.0     1.0      1.0  ...          0.0        0       0.0   \n",
       "3                0.0     1.0      1.0  ...          0.0        2       0.0   \n",
       "4                1.0     1.0      1.0  ...          0.0        1      15.0   \n",
       "...              ...     ...      ...  ...          ...      ...       ...   \n",
       "202939           1.0     1.0      1.0  ...          0.0        2       0.0   \n",
       "202940           1.0     1.0      1.0  ...          0.0        3      30.0   \n",
       "202941           1.0     1.0      1.0  ...          0.0        3       0.0   \n",
       "202942           1.0     1.0      1.0  ...          0.0        0       0.0   \n",
       "202943           1.0     1.0      1.0  ...          0.0        1       0.0   \n",
       "\n",
       "        PhysHlth  DiffWalk  Sex   Age  Education  Income  HeartDiseaseorAttack  \n",
       "0            1.0       0.0  0.0  13.0          4       1                   0.0  \n",
       "1            0.0       0.0  0.0  10.0          5       6                   0.0  \n",
       "2            0.0       0.0  1.0   7.0          3       6                   0.0  \n",
       "3           30.0       1.0  0.0  11.0          3       3                   0.0  \n",
       "4            0.0       0.0  0.0   2.0          5       5                   0.0  \n",
       "...          ...       ...  ...   ...        ...     ...                   ...  \n",
       "202939       0.0       0.0  1.0   9.0          3       4                   0.0  \n",
       "202940      30.0       1.0  1.0   9.0          5       4                   1.0  \n",
       "202941      20.0       0.0  0.0  11.0          1       0                   0.0  \n",
       "202942       0.0       0.0  0.0  13.0          5       7                   0.0  \n",
       "202943       0.0       0.0  1.0  10.0          5       7                   1.0  \n",
       "\n",
       "[202944 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=train_data.loc[:,train_stage_features]\n",
    "train_y=train_data['HeartDiseaseorAttack']\n",
    "new_test_data_X=test_data.loc[:,test_stage_features]\n",
    "new_test_data_y=test_data['HeartDiseaseorAttack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=train_y.value_counts()[0]/train_y.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Age', 'BMI', 'Diabetes', 'DiffWalk', 'GenHlth', 'HighBP',\n",
       "       'HighChol', 'Income', 'PhysHlth', 'Sex', 'Stroke'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train에는 있는데 test data에는 없는 컬럼 찾기\n",
    "\n",
    "train_data_columns=np.array(train_X.columns)\n",
    "test_data_columns=np.array(new_test_data_X.columns)\n",
    "np.setdiff1d(train_data_columns,test_data_columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 누락된 피처들 생성해주기\n",
    "\n",
    "## Test data에 없는 변수들을 다 생성했으므로 LightgbmRegressor 분류모델을 만듬\n",
    "\n",
    "### 베이지안 최적화해주기 - LightgbmRegressor\n",
    "\n",
    "**1. 5-fold 교차검증 이용해서 Train data로 Validation set을 RMSE가 최저였을 때의 하이퍼파라미터 구하기**\n",
    "\n",
    "**2. Learning rate 0.01~0.1, max_depth 3~9, n_estimators 100~1000이었을 때에서 가장 최적의 하이퍼파라미터 구하기**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 00:29:54,457]\u001b[0m A new study created in memory with name: no-name-e368d52b-7bc3-4ae4-8ccb-4b99ae691759\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:30:08,228]\u001b[0m Trial 0 finished with value: 8.35596655480609 and parameters: {'n_estimators': 895, 'max_depth': 7, 'learning_rate': 0.09952093499073741}. Best is trial 0 with value: 8.35596655480609.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:30:15,791]\u001b[0m Trial 1 finished with value: 8.310763597493995 and parameters: {'n_estimators': 472, 'max_depth': 7, 'learning_rate': 0.03806288198144968}. Best is trial 1 with value: 8.310763597493995.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:30:20,290]\u001b[0m Trial 2 finished with value: 8.30676830257934 and parameters: {'n_estimators': 251, 'max_depth': 9, 'learning_rate': 0.048680371106398855}. Best is trial 2 with value: 8.30676830257934.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:30:28,164]\u001b[0m Trial 3 finished with value: 8.299919083982399 and parameters: {'n_estimators': 778, 'max_depth': 4, 'learning_rate': 0.01507871270051649}. Best is trial 3 with value: 8.299919083982399.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:30:39,665]\u001b[0m Trial 4 finished with value: 8.323251407257462 and parameters: {'n_estimators': 724, 'max_depth': 8, 'learning_rate': 0.04370636868353559}. Best is trial 3 with value: 8.299919083982399.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:30:54,851]\u001b[0m Trial 5 finished with value: 8.314991181137085 and parameters: {'n_estimators': 951, 'max_depth': 8, 'learning_rate': 0.02330194176267701}. Best is trial 3 with value: 8.299919083982399.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:31:02,541]\u001b[0m Trial 6 finished with value: 8.300209246996863 and parameters: {'n_estimators': 338, 'max_depth': 4, 'learning_rate': 0.047880119358898666}. Best is trial 3 with value: 8.299919083982399.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:31:11,325]\u001b[0m Trial 7 finished with value: 8.32310460162793 and parameters: {'n_estimators': 569, 'max_depth': 6, 'learning_rate': 0.06342959917184694}. Best is trial 3 with value: 8.299919083982399.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:31:25,882]\u001b[0m Trial 8 finished with value: 8.35162343417763 and parameters: {'n_estimators': 912, 'max_depth': 9, 'learning_rate': 0.07655146279006461}. Best is trial 3 with value: 8.299919083982399.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:31:31,407]\u001b[0m Trial 9 finished with value: 8.300846505054778 and parameters: {'n_estimators': 706, 'max_depth': 3, 'learning_rate': 0.08132812481963439}. Best is trial 3 with value: 8.299919083982399.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 778, 'max_depth': 4, 'learning_rate': 0.01507871270051649}\n"
     ]
    }
   ],
   "source": [
    "# 변수 Age을 예측하는 모형 만들어 주기\n",
    "import optuna\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "test_data_columns=test_stage_features\n",
    "y='Age'\n",
    "\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "\n",
    "\n",
    "\n",
    "# Objective 함수 정의\n",
    "def objective(trial):\n",
    "    \n",
    "    # 하이퍼파라미터 탐색할 공간 정의\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators',100,1000),\n",
    "        'max_depth': trial.suggest_int('max_depth',3,9),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate',0.01,0.1),\n",
    "    }\n",
    "    \n",
    "    # LGBMRegressor 모델 객체 생성\n",
    "    model = LGBMRegressor(**params, random_state=42)\n",
    "    \n",
    "    # 교차검증 수행하여 모델 성능 측정\n",
    "    scores = -1 * cross_val_score(model, train_X_new, train_y_new,\n",
    "                                  cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # 교차검증 평균 점수 리턴\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Optuna study 생성\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 778, 'max_depth': 4, 'learning_rate': 0.01507871270051649}\n",
      "Best RMSE: 8.2999\n"
     ]
    }
   ],
   "source": [
    "# Print best hyperparameters and auc\n",
    "\n",
    "print(f'Best hyperparameters: {study.best_params}')\n",
    "print(f'Best RMSE: {study.best_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(est,depth,rate)=study.best_params.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestreg_parametertuning(rate,depth,est,test_data_columns,y):\n",
    "    best_lgbmreg=LGBMRegressor(learning_rate=rate,max_depth=depth,n_estimators=est,random_state=42)\n",
    "    best_lgbmreg.fit(train_X[test_data_columns], train_X[y])\n",
    "    new_test_data_X[y]=best_lgbmreg.predict(new_test_data_X[test_data_columns])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Education</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.033004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.139105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.044871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.696760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.621035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50731</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.929674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50732</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.148429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50733</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.383784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50734</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.596866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50735</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.648451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50736 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CholCheck  HvyAlcoholConsump  AnyHealthcare  Veggies  Fruits  \\\n",
       "0            1.0                0.0            1.0      1.0     0.0   \n",
       "1            1.0                0.0            1.0      1.0     0.0   \n",
       "2            1.0                0.0            1.0      1.0     0.0   \n",
       "3            1.0                0.0            1.0      0.0     0.0   \n",
       "4            1.0                0.0            1.0      1.0     1.0   \n",
       "...          ...                ...            ...      ...     ...   \n",
       "50731        1.0                0.0            1.0      1.0     1.0   \n",
       "50732        1.0                0.0            0.0      1.0     1.0   \n",
       "50733        1.0                0.0            1.0      0.0     0.0   \n",
       "50734        1.0                0.0            1.0      1.0     1.0   \n",
       "50735        1.0                0.0            1.0      1.0     1.0   \n",
       "\n",
       "       NoDocbcCost  PhysActivity  Education  MentHlth  Smoker       Age  \n",
       "0              0.0           0.0          5       0.0     1.0  9.033004  \n",
       "1              0.0           0.0          5       4.0     0.0  7.139105  \n",
       "2              0.0           0.0          5       3.0     0.0  7.044871  \n",
       "3              0.0           1.0          5       0.0     1.0  8.696760  \n",
       "4              0.0           0.0          4       0.0     1.0  9.621035  \n",
       "...            ...           ...        ...       ...     ...       ...  \n",
       "50731          0.0           0.0          5       1.0     0.0  7.929674  \n",
       "50732          1.0           0.0          3      10.0     0.0  6.148429  \n",
       "50733          0.0           0.0          3      10.0     0.0  8.383784  \n",
       "50734          0.0           0.0          5       0.0     0.0  8.596866  \n",
       "50735          0.0           1.0          4      10.0     1.0  7.648451  \n",
       "\n",
       "[50736 rows x 11 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 00:31:33,497]\u001b[0m A new study created in memory with name: no-name-5adb0500-aba6-4006-b1a4-a6e1d25a5ae4\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:31:46,556]\u001b[0m Trial 0 finished with value: 41.800324544652696 and parameters: {'n_estimators': 817, 'max_depth': 8, 'learning_rate': 0.01596049923134578}. Best is trial 0 with value: 41.800324544652696.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:31:59,951]\u001b[0m Trial 1 finished with value: 42.16701982819702 and parameters: {'n_estimators': 801, 'max_depth': 9, 'learning_rate': 0.0964240840937961}. Best is trial 0 with value: 41.800324544652696.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:32:01,565]\u001b[0m Trial 2 finished with value: 42.01757713946688 and parameters: {'n_estimators': 118, 'max_depth': 4, 'learning_rate': 0.011863591527918552}. Best is trial 0 with value: 41.800324544652696.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:32:14,075]\u001b[0m Trial 3 finished with value: 42.049802713786946 and parameters: {'n_estimators': 771, 'max_depth': 9, 'learning_rate': 0.0693187999342597}. Best is trial 0 with value: 41.800324544652696.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:32:19,226]\u001b[0m Trial 4 finished with value: 41.788943662237116 and parameters: {'n_estimators': 314, 'max_depth': 7, 'learning_rate': 0.037261717479526016}. Best is trial 4 with value: 41.788943662237116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:32:29,126]\u001b[0m Trial 5 finished with value: 41.77209429949222 and parameters: {'n_estimators': 610, 'max_depth': 8, 'learning_rate': 0.014516029421979812}. Best is trial 5 with value: 41.77209429949222.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:32:35,025]\u001b[0m Trial 6 finished with value: 41.746386167654045 and parameters: {'n_estimators': 332, 'max_depth': 8, 'learning_rate': 0.014230304560721233}. Best is trial 6 with value: 41.746386167654045.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:32:43,121]\u001b[0m Trial 7 finished with value: 41.74539916102823 and parameters: {'n_estimators': 546, 'max_depth': 5, 'learning_rate': 0.011142522459068235}. Best is trial 7 with value: 41.74539916102823.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:32:51,740]\u001b[0m Trial 8 finished with value: 41.74944567724882 and parameters: {'n_estimators': 516, 'max_depth': 6, 'learning_rate': 0.011882405476182816}. Best is trial 7 with value: 41.74539916102823.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:33:05,025]\u001b[0m Trial 9 finished with value: 41.870305991196425 and parameters: {'n_estimators': 860, 'max_depth': 7, 'learning_rate': 0.028515690889095623}. Best is trial 7 with value: 41.74539916102823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 546, 'max_depth': 5, 'learning_rate': 0.011142522459068235}\n",
      "0.011142522459068235 5 546\n"
     ]
    }
   ],
   "source": [
    "y='BMI'\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "\n",
    "(est,depth,rate)=study.best_params.values()\n",
    "print(rate,depth,est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Education</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.033004</td>\n",
       "      <td>29.620222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.139105</td>\n",
       "      <td>30.964247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.044871</td>\n",
       "      <td>30.643909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.696760</td>\n",
       "      <td>28.160780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.621035</td>\n",
       "      <td>29.623515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50731</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.929674</td>\n",
       "      <td>29.534726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50732</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.148429</td>\n",
       "      <td>31.697114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50733</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.383784</td>\n",
       "      <td>32.189805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50734</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.596866</td>\n",
       "      <td>29.024121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50735</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.648451</td>\n",
       "      <td>28.552030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50736 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CholCheck  HvyAlcoholConsump  AnyHealthcare  Veggies  Fruits  \\\n",
       "0            1.0                0.0            1.0      1.0     0.0   \n",
       "1            1.0                0.0            1.0      1.0     0.0   \n",
       "2            1.0                0.0            1.0      1.0     0.0   \n",
       "3            1.0                0.0            1.0      0.0     0.0   \n",
       "4            1.0                0.0            1.0      1.0     1.0   \n",
       "...          ...                ...            ...      ...     ...   \n",
       "50731        1.0                0.0            1.0      1.0     1.0   \n",
       "50732        1.0                0.0            0.0      1.0     1.0   \n",
       "50733        1.0                0.0            1.0      0.0     0.0   \n",
       "50734        1.0                0.0            1.0      1.0     1.0   \n",
       "50735        1.0                0.0            1.0      1.0     1.0   \n",
       "\n",
       "       NoDocbcCost  PhysActivity  Education  MentHlth  Smoker       Age  \\\n",
       "0              0.0           0.0          5       0.0     1.0  9.033004   \n",
       "1              0.0           0.0          5       4.0     0.0  7.139105   \n",
       "2              0.0           0.0          5       3.0     0.0  7.044871   \n",
       "3              0.0           1.0          5       0.0     1.0  8.696760   \n",
       "4              0.0           0.0          4       0.0     1.0  9.621035   \n",
       "...            ...           ...        ...       ...     ...       ...   \n",
       "50731          0.0           0.0          5       1.0     0.0  7.929674   \n",
       "50732          1.0           0.0          3      10.0     0.0  6.148429   \n",
       "50733          0.0           0.0          3      10.0     0.0  8.383784   \n",
       "50734          0.0           0.0          5       0.0     0.0  8.596866   \n",
       "50735          0.0           1.0          4      10.0     1.0  7.648451   \n",
       "\n",
       "             BMI  \n",
       "0      29.620222  \n",
       "1      30.964247  \n",
       "2      30.643909  \n",
       "3      28.160780  \n",
       "4      29.623515  \n",
       "...          ...  \n",
       "50731  29.534726  \n",
       "50732  31.697114  \n",
       "50733  32.189805  \n",
       "50734  29.024121  \n",
       "50735  28.552030  \n",
       "\n",
       "[50736 rows x 12 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'BMI')\n",
    "\n",
    "# BMI 열 추가하기\n",
    "new_test_data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 00:33:06,943]\u001b[0m A new study created in memory with name: no-name-81d13703-23bf-4635-b7e9-0b54fabeeeac\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:33:21,745]\u001b[0m Trial 0 finished with value: 0.4687333656466352 and parameters: {'n_estimators': 985, 'max_depth': 6, 'learning_rate': 0.04304040528252487}. Best is trial 0 with value: 0.4687333656466352.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:33:36,846]\u001b[0m Trial 1 finished with value: 0.4712903374797685 and parameters: {'n_estimators': 972, 'max_depth': 8, 'learning_rate': 0.09818917401212222}. Best is trial 0 with value: 0.4687333656466352.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:33:48,960]\u001b[0m Trial 2 finished with value: 0.47042051875352503 and parameters: {'n_estimators': 787, 'max_depth': 7, 'learning_rate': 0.09738084452838408}. Best is trial 0 with value: 0.4687333656466352.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:33:51,818]\u001b[0m Trial 3 finished with value: 0.4672365740679162 and parameters: {'n_estimators': 176, 'max_depth': 5, 'learning_rate': 0.0733392487560017}. Best is trial 3 with value: 0.4672365740679162.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:33:59,937]\u001b[0m Trial 4 finished with value: 0.4670292708334213 and parameters: {'n_estimators': 808, 'max_depth': 4, 'learning_rate': 0.018848045707723787}. Best is trial 4 with value: 0.4670292708334213.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:34:08,951]\u001b[0m Trial 5 finished with value: 0.4674992046660484 and parameters: {'n_estimators': 920, 'max_depth': 4, 'learning_rate': 0.04977774159636591}. Best is trial 4 with value: 0.4670292708334213.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:34:11,169]\u001b[0m Trial 6 finished with value: 0.46728714821430656 and parameters: {'n_estimators': 244, 'max_depth': 3, 'learning_rate': 0.02215260037345221}. Best is trial 4 with value: 0.4670292708334213.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:34:25,317]\u001b[0m Trial 7 finished with value: 0.4674728562987383 and parameters: {'n_estimators': 861, 'max_depth': 9, 'learning_rate': 0.01610417369874614}. Best is trial 4 with value: 0.4670292708334213.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:34:40,180]\u001b[0m Trial 8 finished with value: 0.46837989252914447 and parameters: {'n_estimators': 920, 'max_depth': 9, 'learning_rate': 0.029961457819634416}. Best is trial 4 with value: 0.4670292708334213.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:34:47,391]\u001b[0m Trial 9 finished with value: 0.4691988455696433 and parameters: {'n_estimators': 438, 'max_depth': 9, 'learning_rate': 0.08626051644810491}. Best is trial 4 with value: 0.4670292708334213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 808, 'max_depth': 4, 'learning_rate': 0.018848045707723787}\n",
      "0.018848045707723787 4 808\n"
     ]
    }
   ],
   "source": [
    "y='Diabetes'\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "\n",
    "(est,depth,rate)=study.best_params.values()\n",
    "print(rate,depth,est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'Diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 00:34:49,338]\u001b[0m A new study created in memory with name: no-name-dc204895-082b-44fc-8ffb-28d51bdad451\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:34:55,971]\u001b[0m Trial 0 finished with value: 0.1200026223147477 and parameters: {'n_estimators': 420, 'max_depth': 6, 'learning_rate': 0.06209141587203206}. Best is trial 0 with value: 0.1200026223147477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:35:07,820]\u001b[0m Trial 1 finished with value: 0.12068781100284279 and parameters: {'n_estimators': 747, 'max_depth': 9, 'learning_rate': 0.07744203330278472}. Best is trial 0 with value: 0.1200026223147477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:35:10,486]\u001b[0m Trial 2 finished with value: 0.11960270146319255 and parameters: {'n_estimators': 142, 'max_depth': 6, 'learning_rate': 0.029170467942792908}. Best is trial 2 with value: 0.11960270146319255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:35:18,140]\u001b[0m Trial 3 finished with value: 0.12012979819656314 and parameters: {'n_estimators': 568, 'max_depth': 5, 'learning_rate': 0.0998302142793063}. Best is trial 2 with value: 0.11960270146319255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:35:26,165]\u001b[0m Trial 4 finished with value: 0.11983843689818974 and parameters: {'n_estimators': 508, 'max_depth': 6, 'learning_rate': 0.03577956268755446}. Best is trial 2 with value: 0.11960270146319255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:35:31,262]\u001b[0m Trial 5 finished with value: 0.11954655313737654 and parameters: {'n_estimators': 660, 'max_depth': 3, 'learning_rate': 0.06742787816636775}. Best is trial 5 with value: 0.11954655313737654.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:35:44,137]\u001b[0m Trial 6 finished with value: 0.11967493561032021 and parameters: {'n_estimators': 790, 'max_depth': 8, 'learning_rate': 0.014096479615088345}. Best is trial 5 with value: 0.11954655313737654.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:35:55,285]\u001b[0m Trial 7 finished with value: 0.12023475330593218 and parameters: {'n_estimators': 690, 'max_depth': 9, 'learning_rate': 0.05276439432765398}. Best is trial 5 with value: 0.11954655313737654.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:35:58,195]\u001b[0m Trial 8 finished with value: 0.11986506277550042 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.018535248505895725}. Best is trial 5 with value: 0.11954655313737654.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:36:05,378]\u001b[0m Trial 9 finished with value: 0.11975751999554829 and parameters: {'n_estimators': 449, 'max_depth': 6, 'learning_rate': 0.032221712305590504}. Best is trial 5 with value: 0.11954655313737654.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 660, 'max_depth': 3, 'learning_rate': 0.06742787816636775}\n",
      "0.06742787816636775 3 660\n"
     ]
    }
   ],
   "source": [
    "y='DiffWalk'\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "\n",
    "(est,depth,rate)=study.best_params.values()\n",
    "print(rate,depth,est)\n",
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'DiffWalk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 00:36:06,626]\u001b[0m A new study created in memory with name: no-name-7ee20bfc-00b8-4681-a346-789aaf423807\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:36:18,530]\u001b[0m Trial 0 finished with value: 0.8926778114450024 and parameters: {'n_estimators': 896, 'max_depth': 5, 'learning_rate': 0.036633818446817346}. Best is trial 0 with value: 0.8926778114450024.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:36:29,673]\u001b[0m Trial 1 finished with value: 0.8919955899030253 and parameters: {'n_estimators': 663, 'max_depth': 9, 'learning_rate': 0.018654343233590498}. Best is trial 1 with value: 0.8919955899030253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:36:36,911]\u001b[0m Trial 2 finished with value: 0.8915820646439508 and parameters: {'n_estimators': 718, 'max_depth': 4, 'learning_rate': 0.045858624511359886}. Best is trial 2 with value: 0.8915820646439508.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:36:40,618]\u001b[0m Trial 3 finished with value: 0.8916539299655802 and parameters: {'n_estimators': 208, 'max_depth': 7, 'learning_rate': 0.04741569157746367}. Best is trial 2 with value: 0.8915820646439508.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:36:47,259]\u001b[0m Trial 4 finished with value: 0.8924997908931911 and parameters: {'n_estimators': 390, 'max_depth': 9, 'learning_rate': 0.04423943587255502}. Best is trial 2 with value: 0.8915820646439508.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 718, 'max_depth': 4, 'learning_rate': 0.045858624511359886}\n",
      "0.045858624511359886 4 718\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y='GenHlth'\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "\n",
    "(est,depth,rate)=study.best_params.values()\n",
    "print(rate,depth,est)\n",
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'GenHlth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 00:36:48,931]\u001b[0m A new study created in memory with name: no-name-14faeeb7-feac-4631-91a3-b038dba24cbc\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:37:00,230]\u001b[0m Trial 0 finished with value: 0.2321150589533491 and parameters: {'n_estimators': 675, 'max_depth': 9, 'learning_rate': 0.012625468442624266}. Best is trial 0 with value: 0.2321150589533491.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:37:07,399]\u001b[0m Trial 1 finished with value: 0.23195217633141155 and parameters: {'n_estimators': 962, 'max_depth': 3, 'learning_rate': 0.01573633483082614}. Best is trial 1 with value: 0.23195217633141155.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:37:19,143]\u001b[0m Trial 2 finished with value: 0.23289841103818412 and parameters: {'n_estimators': 729, 'max_depth': 9, 'learning_rate': 0.051470300637347664}. Best is trial 1 with value: 0.23195217633141155.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:37:22,916]\u001b[0m Trial 3 finished with value: 0.23205426810761165 and parameters: {'n_estimators': 216, 'max_depth': 6, 'learning_rate': 0.018413065950644934}. Best is trial 1 with value: 0.23195217633141155.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:37:31,668]\u001b[0m Trial 4 finished with value: 0.23269133011550772 and parameters: {'n_estimators': 658, 'max_depth': 5, 'learning_rate': 0.08616621419328294}. Best is trial 1 with value: 0.23195217633141155.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:37:39,535]\u001b[0m Trial 5 finished with value: 0.2323244981731924 and parameters: {'n_estimators': 557, 'max_depth': 5, 'learning_rate': 0.04111966143048989}. Best is trial 1 with value: 0.23195217633141155.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:37:43,679]\u001b[0m Trial 6 finished with value: 0.23198176779411264 and parameters: {'n_estimators': 512, 'max_depth': 3, 'learning_rate': 0.017969158105587503}. Best is trial 1 with value: 0.23195217633141155.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:37:56,225]\u001b[0m Trial 7 finished with value: 0.2321022559978152 and parameters: {'n_estimators': 883, 'max_depth': 5, 'learning_rate': 0.012058586903117919}. Best is trial 1 with value: 0.23195217633141155.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:37:59,556]\u001b[0m Trial 8 finished with value: 0.23209051120361793 and parameters: {'n_estimators': 207, 'max_depth': 5, 'learning_rate': 0.045927264595235266}. Best is trial 1 with value: 0.23195217633141155.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:38:13,809]\u001b[0m Trial 9 finished with value: 0.23369261607340358 and parameters: {'n_estimators': 958, 'max_depth': 7, 'learning_rate': 0.09067783311781771}. Best is trial 1 with value: 0.23195217633141155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 962, 'max_depth': 3, 'learning_rate': 0.01573633483082614}\n",
      "0.01573633483082614 3 962\n"
     ]
    }
   ],
   "source": [
    "y='HighBP'\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "\n",
    "(est,depth,rate)=study.best_params.values()\n",
    "print(rate,depth,est)\n",
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'HighBP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 00:38:15,555]\u001b[0m A new study created in memory with name: no-name-dd9fd530-548c-44e9-b0aa-1e9fcd9c57de\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:38:24,821]\u001b[0m Trial 0 finished with value: 0.23794070619779992 and parameters: {'n_estimators': 700, 'max_depth': 5, 'learning_rate': 0.07012948556393786}. Best is trial 0 with value: 0.23794070619779992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:38:34,278]\u001b[0m Trial 1 finished with value: 0.23761873861888141 and parameters: {'n_estimators': 580, 'max_depth': 9, 'learning_rate': 0.030300833393382836}. Best is trial 1 with value: 0.23761873861888141.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:38:40,471]\u001b[0m Trial 2 finished with value: 0.2371067113408561 and parameters: {'n_estimators': 830, 'max_depth': 3, 'learning_rate': 0.015431096490448493}. Best is trial 2 with value: 0.2371067113408561.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:38:42,696]\u001b[0m Trial 3 finished with value: 0.2374770710143868 and parameters: {'n_estimators': 108, 'max_depth': 8, 'learning_rate': 0.016674555027644124}. Best is trial 2 with value: 0.2371067113408561.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:38:49,053]\u001b[0m Trial 4 finished with value: 0.23730728020337022 and parameters: {'n_estimators': 405, 'max_depth': 6, 'learning_rate': 0.02079123617317645}. Best is trial 2 with value: 0.2371067113408561.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:38:52,820]\u001b[0m Trial 5 finished with value: 0.2372806422085345 and parameters: {'n_estimators': 223, 'max_depth': 6, 'learning_rate': 0.032876704489627845}. Best is trial 2 with value: 0.2371067113408561.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:38:55,066]\u001b[0m Trial 6 finished with value: 0.23711990396371005 and parameters: {'n_estimators': 239, 'max_depth': 3, 'learning_rate': 0.05992980013661384}. Best is trial 2 with value: 0.2371067113408561.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:39:02,903]\u001b[0m Trial 7 finished with value: 0.2376928071415719 and parameters: {'n_estimators': 553, 'max_depth': 5, 'learning_rate': 0.05565980499198847}. Best is trial 2 with value: 0.2371067113408561.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:39:15,235]\u001b[0m Trial 8 finished with value: 0.23900546713083237 and parameters: {'n_estimators': 803, 'max_depth': 8, 'learning_rate': 0.08855630752959545}. Best is trial 2 with value: 0.2371067113408561.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:39:21,148]\u001b[0m Trial 9 finished with value: 0.237224368307893 and parameters: {'n_estimators': 774, 'max_depth': 3, 'learning_rate': 0.057905259223112855}. Best is trial 2 with value: 0.2371067113408561.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 830, 'max_depth': 3, 'learning_rate': 0.015431096490448493}\n",
      "0.015431096490448493 3 830\n"
     ]
    }
   ],
   "source": [
    "y='HighChol'\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "\n",
    "(est,depth,rate)=study.best_params.values()\n",
    "print(rate,depth,est)\n",
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'HighChol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 00:39:22,672]\u001b[0m A new study created in memory with name: no-name-c83090a9-f94d-4484-b2ca-e75c78c4a9ef\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:39:24,788]\u001b[0m Trial 0 finished with value: 3.1100784031859656 and parameters: {'n_estimators': 237, 'max_depth': 3, 'learning_rate': 0.050186130194675056}. Best is trial 0 with value: 3.1100784031859656.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:39:35,675]\u001b[0m Trial 1 finished with value: 3.1235000102534007 and parameters: {'n_estimators': 694, 'max_depth': 8, 'learning_rate': 0.048489700370042764}. Best is trial 0 with value: 3.1100784031859656.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:39:45,891]\u001b[0m Trial 2 finished with value: 3.111650266201802 and parameters: {'n_estimators': 583, 'max_depth': 8, 'learning_rate': 0.010411678370555125}. Best is trial 0 with value: 3.1100784031859656.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:39:51,611]\u001b[0m Trial 3 finished with value: 3.1134605739504844 and parameters: {'n_estimators': 305, 'max_depth': 9, 'learning_rate': 0.012909673653994189}. Best is trial 0 with value: 3.1100784031859656.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:39:57,613]\u001b[0m Trial 4 finished with value: 3.114850130292063 and parameters: {'n_estimators': 603, 'max_depth': 4, 'learning_rate': 0.09325940001731309}. Best is trial 0 with value: 3.1100784031859656.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:40:07,759]\u001b[0m Trial 5 finished with value: 3.1119570668245693 and parameters: {'n_estimators': 599, 'max_depth': 8, 'learning_rate': 0.012331681513368577}. Best is trial 0 with value: 3.1100784031859656.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:40:13,128]\u001b[0m Trial 6 finished with value: 3.1117342933521686 and parameters: {'n_estimators': 304, 'max_depth': 7, 'learning_rate': 0.023286981220675036}. Best is trial 0 with value: 3.1100784031859656.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:40:18,448]\u001b[0m Trial 7 finished with value: 3.1118286623976124 and parameters: {'n_estimators': 320, 'max_depth': 6, 'learning_rate': 0.025500903059520418}. Best is trial 0 with value: 3.1100784031859656.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:40:29,849]\u001b[0m Trial 8 finished with value: 3.1265975288034165 and parameters: {'n_estimators': 769, 'max_depth': 6, 'learning_rate': 0.06426646625795257}. Best is trial 0 with value: 3.1100784031859656.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:40:31,990]\u001b[0m Trial 9 finished with value: 3.1389354497997637 and parameters: {'n_estimators': 238, 'max_depth': 3, 'learning_rate': 0.014677748516671132}. Best is trial 0 with value: 3.1100784031859656.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 237, 'max_depth': 3, 'learning_rate': 0.050186130194675056}\n",
      "0.050186130194675056 3 237\n"
     ]
    }
   ],
   "source": [
    "y='Income'\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "\n",
    "(est,depth,rate)=study.best_params.values()\n",
    "print(rate,depth,est)\n",
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 00:40:32,509]\u001b[0m A new study created in memory with name: no-name-bbc7fab4-8cc8-4244-a124-cf304647fa69\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:40:37,004]\u001b[0m Trial 0 finished with value: 61.78433223644205 and parameters: {'n_estimators': 255, 'max_depth': 7, 'learning_rate': 0.022373607318996507}. Best is trial 0 with value: 61.78433223644205.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:40:43,683]\u001b[0m Trial 1 finished with value: 61.79953212068367 and parameters: {'n_estimators': 407, 'max_depth': 6, 'learning_rate': 0.013953221734594451}. Best is trial 0 with value: 61.78433223644205.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:40:58,196]\u001b[0m Trial 2 finished with value: 61.99871392746927 and parameters: {'n_estimators': 937, 'max_depth': 8, 'learning_rate': 0.029420616955494545}. Best is trial 0 with value: 61.78433223644205.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:40:59,679]\u001b[0m Trial 3 finished with value: 61.81297027832204 and parameters: {'n_estimators': 144, 'max_depth': 3, 'learning_rate': 0.05859057266624568}. Best is trial 0 with value: 61.78433223644205.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:41:11,585]\u001b[0m Trial 4 finished with value: 61.89460937417566 and parameters: {'n_estimators': 763, 'max_depth': 6, 'learning_rate': 0.022656726714619067}. Best is trial 0 with value: 61.78433223644205.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:41:16,271]\u001b[0m Trial 5 finished with value: 61.80239949519883 and parameters: {'n_estimators': 277, 'max_depth': 6, 'learning_rate': 0.028565744469441958}. Best is trial 0 with value: 61.78433223644205.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:41:30,027]\u001b[0m Trial 6 finished with value: 61.80641919660375 and parameters: {'n_estimators': 827, 'max_depth': 8, 'learning_rate': 0.01091960257526207}. Best is trial 0 with value: 61.78433223644205.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:41:32,946]\u001b[0m Trial 7 finished with value: 61.80980757914455 and parameters: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.05883441606806007}. Best is trial 0 with value: 61.78433223644205.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:41:39,611]\u001b[0m Trial 8 finished with value: 61.83452510035962 and parameters: {'n_estimators': 661, 'max_depth': 4, 'learning_rate': 0.051544236289524176}. Best is trial 0 with value: 61.78433223644205.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:41:46,064]\u001b[0m Trial 9 finished with value: 61.925274644907674 and parameters: {'n_estimators': 285, 'max_depth': 9, 'learning_rate': 0.010290044983919253}. Best is trial 0 with value: 61.78433223644205.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 255, 'max_depth': 7, 'learning_rate': 0.022373607318996507}\n",
      "0.022373607318996507 7 255\n"
     ]
    }
   ],
   "source": [
    "y='PhysHlth'\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "\n",
    "(est,depth,rate)=study.best_params.values()\n",
    "print(rate,depth,est)\n",
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'PhysHlth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 00:41:47,157]\u001b[0m A new study created in memory with name: no-name-9bf4ed8a-f437-413c-b871-576fcf603fec\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:41:55,821]\u001b[0m Trial 0 finished with value: 0.23431474836302574 and parameters: {'n_estimators': 841, 'max_depth': 4, 'learning_rate': 0.019550346200793146}. Best is trial 0 with value: 0.23431474836302574.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:41:57,940]\u001b[0m Trial 1 finished with value: 0.23513317999781683 and parameters: {'n_estimators': 166, 'max_depth': 4, 'learning_rate': 0.018098119883696376}. Best is trial 0 with value: 0.23431474836302574.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:42:07,704]\u001b[0m Trial 2 finished with value: 0.23448318896173198 and parameters: {'n_estimators': 658, 'max_depth': 5, 'learning_rate': 0.02181129018026924}. Best is trial 0 with value: 0.23431474836302574.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:42:10,247]\u001b[0m Trial 3 finished with value: 0.2353732664581948 and parameters: {'n_estimators': 128, 'max_depth': 6, 'learning_rate': 0.014747187020962615}. Best is trial 0 with value: 0.23431474836302574.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:42:19,776]\u001b[0m Trial 4 finished with value: 0.23448853700875166 and parameters: {'n_estimators': 579, 'max_depth': 7, 'learning_rate': 0.020883340064823952}. Best is trial 0 with value: 0.23431474836302574.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:42:31,424]\u001b[0m Trial 5 finished with value: 0.2351014539559399 and parameters: {'n_estimators': 907, 'max_depth': 5, 'learning_rate': 0.08676370197900478}. Best is trial 0 with value: 0.23431474836302574.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:42:33,756]\u001b[0m Trial 6 finished with value: 0.23475601753379188 and parameters: {'n_estimators': 252, 'max_depth': 3, 'learning_rate': 0.022239781743106035}. Best is trial 0 with value: 0.23431474836302574.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:42:42,158]\u001b[0m Trial 7 finished with value: 0.23438669006664506 and parameters: {'n_estimators': 521, 'max_depth': 6, 'learning_rate': 0.01661864135511777}. Best is trial 0 with value: 0.23431474836302574.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:42:48,907]\u001b[0m Trial 8 finished with value: 0.2346234204014602 and parameters: {'n_estimators': 403, 'max_depth': 7, 'learning_rate': 0.040562077902243844}. Best is trial 0 with value: 0.23431474836302574.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:42:52,831]\u001b[0m Trial 9 finished with value: 0.23436079312115918 and parameters: {'n_estimators': 201, 'max_depth': 9, 'learning_rate': 0.022756327015783208}. Best is trial 0 with value: 0.23431474836302574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 841, 'max_depth': 4, 'learning_rate': 0.019550346200793146}\n",
      "0.019550346200793146 4 841\n"
     ]
    }
   ],
   "source": [
    "y='Sex'\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "\n",
    "(est,depth,rate)=study.best_params.values()\n",
    "print(rate,depth,est)\n",
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 00:42:54,750]\u001b[0m A new study created in memory with name: no-name-f99d1d50-6164-4000-8586-e4e074e6b0b1\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:42:59,663]\u001b[0m Trial 0 finished with value: 0.03811570398524013 and parameters: {'n_estimators': 275, 'max_depth': 8, 'learning_rate': 0.03332157794840853}. Best is trial 0 with value: 0.03811570398524013.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:43:05,607]\u001b[0m Trial 1 finished with value: 0.03807806288488745 and parameters: {'n_estimators': 333, 'max_depth': 8, 'learning_rate': 0.011590286112903856}. Best is trial 1 with value: 0.03807806288488745.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:43:08,324]\u001b[0m Trial 2 finished with value: 0.03813423259987839 and parameters: {'n_estimators': 141, 'max_depth': 8, 'learning_rate': 0.07834847240572329}. Best is trial 1 with value: 0.03807806288488745.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:43:19,206]\u001b[0m Trial 3 finished with value: 0.03809534812853856 and parameters: {'n_estimators': 770, 'max_depth': 5, 'learning_rate': 0.012888401439171832}. Best is trial 1 with value: 0.03807806288488745.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:43:23,208]\u001b[0m Trial 4 finished with value: 0.0381219695149051 and parameters: {'n_estimators': 226, 'max_depth': 8, 'learning_rate': 0.04436468657171478}. Best is trial 1 with value: 0.03807806288488745.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:43:34,722]\u001b[0m Trial 5 finished with value: 0.03809963411525623 and parameters: {'n_estimators': 637, 'max_depth': 9, 'learning_rate': 0.010466311461250195}. Best is trial 1 with value: 0.03807806288488745.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:43:42,063]\u001b[0m Trial 6 finished with value: 0.03808938650547346 and parameters: {'n_estimators': 434, 'max_depth': 8, 'learning_rate': 0.013173430567211866}. Best is trial 1 with value: 0.03807806288488745.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:43:47,581]\u001b[0m Trial 7 finished with value: 0.038060911898400544 and parameters: {'n_estimators': 520, 'max_depth': 4, 'learning_rate': 0.012423259157251077}. Best is trial 7 with value: 0.038060911898400544.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:43:59,751]\u001b[0m Trial 8 finished with value: 0.03815954441207605 and parameters: {'n_estimators': 756, 'max_depth': 8, 'learning_rate': 0.02100605125450703}. Best is trial 7 with value: 0.038060911898400544.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:44:03,149]\u001b[0m Trial 9 finished with value: 0.03806112797557716 and parameters: {'n_estimators': 408, 'max_depth': 3, 'learning_rate': 0.021871131418127524}. Best is trial 7 with value: 0.038060911898400544.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 520, 'max_depth': 4, 'learning_rate': 0.012423259157251077}\n",
      "0.012423259157251077 4 520\n"
     ]
    }
   ],
   "source": [
    "y='Stroke'\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "\n",
    "(est,depth,rate)=study.best_params.values()\n",
    "print(rate,depth,est)\n",
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'Stroke')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 00:44:04,438]\u001b[0m A new study created in memory with name: lgb_boost_opt\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:44:12,497]\u001b[0m Trial 0 finished with value: 0.8498533524981641 and parameters: {'learning_rate': 0.019357281877591417, 'max_depth': 4, 'n_estimators': 596}. Best is trial 0 with value: 0.8498533524981641.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:44:19,863]\u001b[0m Trial 1 finished with value: 0.8495065163268751 and parameters: {'learning_rate': 0.012436240302912219, 'max_depth': 7, 'n_estimators': 312}. Best is trial 0 with value: 0.8498533524981641.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:44:37,335]\u001b[0m Trial 2 finished with value: 0.8476675242653979 and parameters: {'learning_rate': 0.020408483246054838, 'max_depth': 7, 'n_estimators': 988}. Best is trial 0 with value: 0.8498533524981641.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:44:50,975]\u001b[0m Trial 3 finished with value: 0.8411509509412142 and parameters: {'learning_rate': 0.07652914595594465, 'max_depth': 5, 'n_estimators': 828}. Best is trial 0 with value: 0.8498533524981641.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:45:06,842]\u001b[0m Trial 4 finished with value: 0.8474826044884869 and parameters: {'learning_rate': 0.024579318378460384, 'max_depth': 7, 'n_estimators': 892}. Best is trial 0 with value: 0.8498533524981641.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:45:17,121]\u001b[0m Trial 5 finished with value: 0.8498552438910547 and parameters: {'learning_rate': 0.011592226655361365, 'max_depth': 6, 'n_estimators': 496}. Best is trial 5 with value: 0.8498552438910547.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:45:28,082]\u001b[0m Trial 6 finished with value: 0.8460225411156841 and parameters: {'learning_rate': 0.04667134969538217, 'max_depth': 7, 'n_estimators': 607}. Best is trial 5 with value: 0.8498552438910547.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:45:39,378]\u001b[0m Trial 7 finished with value: 0.8483138699481776 and parameters: {'learning_rate': 0.026526073880848336, 'max_depth': 5, 'n_estimators': 659}. Best is trial 5 with value: 0.8498552438910547.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:45:48,453]\u001b[0m Trial 8 finished with value: 0.8457334316100609 and parameters: {'learning_rate': 0.06041381556086162, 'max_depth': 7, 'n_estimators': 494}. Best is trial 5 with value: 0.8498552438910547.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:46:02,855]\u001b[0m Trial 9 finished with value: 0.8491388197879317 and parameters: {'learning_rate': 0.01481883989202767, 'max_depth': 7, 'n_estimators': 750}. Best is trial 5 with value: 0.8498552438910547.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:46:07,076]\u001b[0m Trial 10 finished with value: 0.8471263063611836 and parameters: {'learning_rate': 0.010943089715987066, 'max_depth': 9, 'n_estimators': 143}. Best is trial 5 with value: 0.8498552438910547.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:46:12,116]\u001b[0m Trial 11 finished with value: 0.849497453054511 and parameters: {'learning_rate': 0.01728052107828868, 'max_depth': 3, 'n_estimators': 433}. Best is trial 5 with value: 0.8498552438910547.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:46:16,579]\u001b[0m Trial 12 finished with value: 0.8475425556106917 and parameters: {'learning_rate': 0.010006553580619977, 'max_depth': 3, 'n_estimators': 369}. Best is trial 5 with value: 0.8498552438910547.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:46:27,002]\u001b[0m Trial 13 finished with value: 0.8494208765546436 and parameters: {'learning_rate': 0.016570248372619046, 'max_depth': 5, 'n_estimators': 582}. Best is trial 5 with value: 0.8498552438910547.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:46:30,755]\u001b[0m Trial 14 finished with value: 0.849914889212305 and parameters: {'learning_rate': 0.03590457960875961, 'max_depth': 4, 'n_estimators': 228}. Best is trial 14 with value: 0.849914889212305.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:46:35,370]\u001b[0m Trial 15 finished with value: 0.8497391625751056 and parameters: {'learning_rate': 0.035292192291475594, 'max_depth': 9, 'n_estimators': 176}. Best is trial 14 with value: 0.849914889212305.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:46:39,357]\u001b[0m Trial 16 finished with value: 0.8499616702978601 and parameters: {'learning_rate': 0.038235275274092075, 'max_depth': 4, 'n_estimators': 250}. Best is trial 16 with value: 0.8499616702978601.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:46:43,640]\u001b[0m Trial 17 finished with value: 0.8498831027497795 and parameters: {'learning_rate': 0.03816803807487018, 'max_depth': 4, 'n_estimators': 275}. Best is trial 16 with value: 0.8499616702978601.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:46:46,034]\u001b[0m Trial 18 finished with value: 0.8494841402887966 and parameters: {'learning_rate': 0.045442232423646894, 'max_depth': 4, 'n_estimators': 111}. Best is trial 16 with value: 0.8499616702978601.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:46:49,096]\u001b[0m Trial 19 finished with value: 0.8493438428377829 and parameters: {'learning_rate': 0.02929578171806219, 'max_depth': 3, 'n_estimators': 226}. Best is trial 16 with value: 0.8499616702978601.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:46:54,070]\u001b[0m Trial 20 finished with value: 0.84985582220875 and parameters: {'learning_rate': 0.0325781761053138, 'max_depth': 4, 'n_estimators': 336}. Best is trial 16 with value: 0.8499616702978601.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:46:57,975]\u001b[0m Trial 21 finished with value: 0.8499986384685897 and parameters: {'learning_rate': 0.03851343740983625, 'max_depth': 4, 'n_estimators': 240}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:47:02,522]\u001b[0m Trial 22 finished with value: 0.8495006971081095 and parameters: {'learning_rate': 0.0415092223418789, 'max_depth': 5, 'n_estimators': 213}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:47:10,356]\u001b[0m Trial 23 finished with value: 0.8469090789621327 and parameters: {'learning_rate': 0.05776735788327729, 'max_depth': 6, 'n_estimators': 417}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:47:14,362]\u001b[0m Trial 24 finished with value: 0.8499648912973875 and parameters: {'learning_rate': 0.03304615201902596, 'max_depth': 4, 'n_estimators': 240}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:47:17,997]\u001b[0m Trial 25 finished with value: 0.849329844761278 and parameters: {'learning_rate': 0.024610285648984275, 'max_depth': 3, 'n_estimators': 271}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:47:25,299]\u001b[0m Trial 26 finished with value: 0.8491055060761976 and parameters: {'learning_rate': 0.031077343274455164, 'max_depth': 5, 'n_estimators': 385}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:47:27,938]\u001b[0m Trial 27 finished with value: 0.8497333279043712 and parameters: {'learning_rate': 0.05053878531954672, 'max_depth': 4, 'n_estimators': 120}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:47:31,743]\u001b[0m Trial 28 finished with value: 0.8499810639849927 and parameters: {'learning_rate': 0.039034670885919505, 'max_depth': 3, 'n_estimators': 286}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:47:37,222]\u001b[0m Trial 29 finished with value: 0.8499720501051684 and parameters: {'learning_rate': 0.030711904690133945, 'max_depth': 3, 'n_estimators': 485}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:47:42,570]\u001b[0m Trial 30 finished with value: 0.8498815704390175 and parameters: {'learning_rate': 0.02193479336390772, 'max_depth': 3, 'n_estimators': 467}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:47:46,748]\u001b[0m Trial 31 finished with value: 0.8497514566264746 and parameters: {'learning_rate': 0.027114661862268602, 'max_depth': 3, 'n_estimators': 324}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:47:49,485]\u001b[0m Trial 32 finished with value: 0.8488475246322527 and parameters: {'learning_rate': 0.030985832511945522, 'max_depth': 3, 'n_estimators': 168}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:47:53,459]\u001b[0m Trial 33 finished with value: 0.8499549366006184 and parameters: {'learning_rate': 0.0414284965424023, 'max_depth': 3, 'n_estimators': 310}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:48:03,259]\u001b[0m Trial 34 finished with value: 0.848007788196127 and parameters: {'learning_rate': 0.03498548369139054, 'max_depth': 6, 'n_estimators': 527}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:48:09,041]\u001b[0m Trial 35 finished with value: 0.8499337695312382 and parameters: {'learning_rate': 0.022653534047287087, 'max_depth': 4, 'n_estimators': 369}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:48:16,006]\u001b[0m Trial 36 finished with value: 0.8498925170209768 and parameters: {'learning_rate': 0.029726521774336965, 'max_depth': 3, 'n_estimators': 661}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:48:20,331]\u001b[0m Trial 37 finished with value: 0.8499166137440752 and parameters: {'learning_rate': 0.025942936895750196, 'max_depth': 4, 'n_estimators': 275}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:48:24,368]\u001b[0m Trial 38 finished with value: 0.8492317825829693 and parameters: {'learning_rate': 0.019512388577231855, 'max_depth': 5, 'n_estimators': 174}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:48:38,443]\u001b[0m Trial 39 finished with value: 0.8465221409774764 and parameters: {'learning_rate': 0.03393253087847155, 'max_depth': 8, 'n_estimators': 773}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:48:46,125]\u001b[0m Trial 40 finished with value: 0.8456732517490559 and parameters: {'learning_rate': 0.07698838189065173, 'max_depth': 5, 'n_estimators': 431}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:48:50,001]\u001b[0m Trial 41 finished with value: 0.8499288268703445 and parameters: {'learning_rate': 0.03924739569219769, 'max_depth': 4, 'n_estimators': 239}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:48:54,635]\u001b[0m Trial 42 finished with value: 0.8496592991063092 and parameters: {'learning_rate': 0.045646917273188065, 'max_depth': 4, 'n_estimators': 308}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:49:03,612]\u001b[0m Trial 43 finished with value: 0.849535700975456 and parameters: {'learning_rate': 0.03825091346232298, 'max_depth': 3, 'n_estimators': 917}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:49:07,113]\u001b[0m Trial 44 finished with value: 0.8497165309692576 and parameters: {'learning_rate': 0.028547213018299742, 'max_depth': 4, 'n_estimators': 202}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:49:12,876]\u001b[0m Trial 45 finished with value: 0.8488109037736924 and parameters: {'learning_rate': 0.049810453125162094, 'max_depth': 6, 'n_estimators': 270}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:49:20,090]\u001b[0m Trial 46 finished with value: 0.8489903885355847 and parameters: {'learning_rate': 0.03423537542896147, 'max_depth': 5, 'n_estimators': 379}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:49:26,082]\u001b[0m Trial 47 finished with value: 0.8499816494442605 and parameters: {'learning_rate': 0.027463465158029755, 'max_depth': 3, 'n_estimators': 556}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:49:33,129]\u001b[0m Trial 48 finished with value: 0.8499456848672512 and parameters: {'learning_rate': 0.027001944451145978, 'max_depth': 3, 'n_estimators': 679}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 00:49:39,379]\u001b[0m Trial 49 finished with value: 0.849951711383347 and parameters: {'learning_rate': 0.03218281902666054, 'max_depth': 3, 'n_estimators': 583}. Best is trial 21 with value: 0.8499986384685897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.03851343740983625, 'max_depth': 4, 'n_estimators': 240}\n",
      "Best AUC: 0.8500\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameters to optimize \n",
    "    params={\n",
    "        'boosting_type':'gbdt',\n",
    "        'objective':'binary',\n",
    "        'metric':'binary_logloss',\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.1),\n",
    "        'max_depth':trial.suggest_int('max_depth',3,9),\n",
    "        'n_estimators':trial.suggest_int(\"n_estimators\",100,1000)\n",
    "    }\n",
    "    # Train and evaluate model \n",
    "    lgb_cv=lgb.LGBMClassifier(**params, random_state=42,scale_pos_weight=ratio)\n",
    "    scores=cross_val_score(lgb_cv,train_X,train_y,cv=5,scoring='roc_auc')\n",
    "    auc=scores.mean()\n",
    "    return auc \n",
    "\n",
    "# Define study object and optimize \n",
    "\n",
    "study=optuna.create_study(direction='maximize',study_name='lgb_boost_opt',load_if_exists=True)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print best hyperparameters and auc\n",
    "print(f'Best hyperparameters: {study.best_params}')\n",
    "print(f'Best AUC: {study.best_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb=lgb.LGBMClassifier(learning_rate=  0.01586784169962525,max_depth= 3,n_estimators=992,scale_pos_weight=ratio,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.01586784169962525, max_depth=3, n_estimators=992,\n",
       "               random_state=42, scale_pos_weight=9.617557811028565)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.01586784169962525, max_depth=3, n_estimators=992,\n",
       "               random_state=42, scale_pos_weight=9.617557811028565)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01586784169962525, max_depth=3, n_estimators=992,\n",
       "               random_state=42, scale_pos_weight=9.617557811028565)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=lgb.predict_proba(new_test_data_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50736, 21)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "def get_clf_prob(y_test, probability):\n",
    "  pred=np.where(probability > 0.50,1,0)\n",
    "  confusion=confusion_matrix(y_test, pred)\n",
    "  accuracy=accuracy_score(y_test,pred)\n",
    "  precision=precision_score(y_test,pred) \n",
    "  recall=recall_score(y_test,pred) \n",
    "  # F1 스코어 추가 \n",
    "  f1=f1_score(y_test,pred,average='macro')\n",
    "  Roc_score=roc_auc_score(y_test,probability)\n",
    "  print('임계값: ', 0.5) \n",
    "  print('오차행렬')\n",
    "  print(confusion) \n",
    "  # f1 score print 추가 \n",
    "  print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}, AUC:{4: .4f}'.format(accuracy,precision,recall,f1,Roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계값:  0.5\n",
      "오차행렬\n",
      "[[34714 11243]\n",
      " [ 3312  1467]]\n",
      "정확도: 0.7131, 정밀도: 0.1154, 재현율: 0.3070, F1:0.4972, AUC: 0.5236\n"
     ]
    }
   ],
   "source": [
    "get_clf_prob(new_test_data_y,pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
