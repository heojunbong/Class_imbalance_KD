{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score,roc_auc_score,mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import random\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('/home/iai/son/lastcheck/spambase_train_data.csv')\n",
    "test_data=pd.read_csv('/home/iai/son/lastcheck/spambase_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stage_features=['0.7', '278', '61', '0', '0.34', '0.30', '0.5', '0.44', '0.40', '0.778',\n",
    "                        '0.24', '1.93', '0.39', '1.29', '0.43', '0.2', '0.36', '0.17', '0.20', \n",
    "                        '0.28', '0.21', '0.32.1', '0.41', '0.29', '3.756', '0.35', '0.25', '0.15', \n",
    "                        '0.64.1', '0.38', '0.45', '0.6', '0.33', '0.42', '0.14', '0.9', '0.10', \n",
    "                        '0.3', '0.13', '0.8', '0.19', '0.23', '0.18', '0.22', '0.16', '0.64.2', \n",
    "                        '0.1', '0.31', '0.27', '0.11', '0.4', '0.12', '0.26', '0.64', '0.37', '0.32', '0.96']\n",
    "test_stage_features=['0.7', '278', '61', '0', '0.34', '0.30', '0.5', '0.44', '0.40', '0.778',\n",
    "                        '0.24', '1.93', '0.39', '1.29', '0.43', '0.2', '0.36', '0.17', '0.20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=train_data.loc[:,train_stage_features]\n",
    "train_y=train_data['1']\n",
    "new_test_data_X=test_data.loc[:,test_stage_features]\n",
    "new_test_data_y=test_data['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=train_y.value_counts()[0]/train_y.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.1', '0.10', '0.11', '0.12', '0.13', '0.14', '0.15', '0.16',\n",
       "       '0.18', '0.19', '0.21', '0.22', '0.23', '0.25', '0.26', '0.27',\n",
       "       '0.28', '0.29', '0.3', '0.31', '0.32', '0.32.1', '0.33', '0.35',\n",
       "       '0.37', '0.38', '0.4', '0.41', '0.42', '0.45', '0.6', '0.64',\n",
       "       '0.64.1', '0.64.2', '0.8', '0.9', '0.96', '3.756'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train에는 있는데 test data에는 없는 컬럼 찾기\n",
    "\n",
    "train_data_columns=np.array(train_X.columns)\n",
    "test_data_columns=np.array(new_test_data_X.columns)\n",
    "np.setdiff1d(train_data_columns,test_data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:24:40,849]\u001b[0m A new study created in memory with name: no-name-8b4e3706-51ae-4789-a612-05ee6d71bc88\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:24:43,259]\u001b[0m Trial 0 finished with value: 0.14406922470325362 and parameters: {'n_estimators': 967, 'max_depth': 6, 'learning_rate': 0.01385032417962858}. Best is trial 0 with value: 0.14406922470325362.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:24:43,820]\u001b[0m Trial 1 finished with value: 0.14934693385334918 and parameters: {'n_estimators': 687, 'max_depth': 3, 'learning_rate': 0.012005888631085334}. Best is trial 0 with value: 0.14406922470325362.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:24:45,331]\u001b[0m Trial 2 finished with value: 0.14457410800409634 and parameters: {'n_estimators': 767, 'max_depth': 6, 'learning_rate': 0.020763617020515997}. Best is trial 0 with value: 0.14406922470325362.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:24:45,594]\u001b[0m Trial 3 finished with value: 0.14705539928005557 and parameters: {'n_estimators': 245, 'max_depth': 4, 'learning_rate': 0.04029889476382111}. Best is trial 0 with value: 0.14406922470325362.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:24:45,885]\u001b[0m Trial 4 finished with value: 0.14919423298093992 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.016300579889748888}. Best is trial 0 with value: 0.14406922470325362.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:24:46,534]\u001b[0m Trial 5 finished with value: 0.14726273140694138 and parameters: {'n_estimators': 636, 'max_depth': 4, 'learning_rate': 0.015304565988470178}. Best is trial 0 with value: 0.14406922470325362.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:24:48,344]\u001b[0m Trial 6 finished with value: 0.14747231376377895 and parameters: {'n_estimators': 779, 'max_depth': 9, 'learning_rate': 0.045350563122234885}. Best is trial 0 with value: 0.14406922470325362.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:24:48,770]\u001b[0m Trial 7 finished with value: 0.1492083202301248 and parameters: {'n_estimators': 478, 'max_depth': 3, 'learning_rate': 0.029957122620657563}. Best is trial 0 with value: 0.14406922470325362.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:24:49,031]\u001b[0m Trial 8 finished with value: 0.14764379100533476 and parameters: {'n_estimators': 201, 'max_depth': 4, 'learning_rate': 0.02951096248844589}. Best is trial 0 with value: 0.14406922470325362.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:24:49,549]\u001b[0m Trial 9 finished with value: 0.14551284330016717 and parameters: {'n_estimators': 454, 'max_depth': 5, 'learning_rate': 0.05443851065870641}. Best is trial 0 with value: 0.14406922470325362.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 967, 'max_depth': 6, 'learning_rate': 0.01385032417962858}\n",
      "Best hyperparameters: {'n_estimators': 967, 'max_depth': 6, 'learning_rate': 0.01385032417962858}\n",
      "Best RMSE: 0.1441\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "test_data_columns=test_stage_features\n",
    "y='0.28'\n",
    "\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "\n",
    "\n",
    "\n",
    "# Objective 함수 정의\n",
    "def objective(trial):\n",
    "    \n",
    "    # 하이퍼파라미터 탐색할 공간 정의\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators',100,1000),\n",
    "        'max_depth': trial.suggest_int('max_depth',3,9),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate',0.01,0.1),\n",
    "    }\n",
    "    \n",
    "    # LGBMRegressor 모델 객체 생성\n",
    "    model = LGBMRegressor(**params, random_state=42)\n",
    "    \n",
    "    # 교차검증 수행하여 모델 성능 측정\n",
    "    scores = -1 * cross_val_score(model, train_X_new, train_y_new,\n",
    "                                  cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # 교차검증 평균 점수 리턴\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Optuna study 생성\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "# Print best hyperparameters and auc\n",
    "\n",
    "print(f'Best hyperparameters: {study.best_params}')\n",
    "print(f'Best RMSE: {study.best_value:.4f}')\n",
    "(est,depth,rate)=study.best_params.values()\n",
    "\n",
    "def bestreg_parametertuning(rate,depth,est,test_data_columns,y):\n",
    "    best_lgbmreg=LGBMRegressor(learning_rate=rate,max_depth=depth,n_estimators=est,random_state=42)\n",
    "    best_lgbmreg.fit(train_X[test_data_columns], train_X[y])\n",
    "    new_test_data_X[y]=best_lgbmreg.predict(new_test_data_X[test_data_columns])\n",
    "\n",
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'0.28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.7</th>\n",
       "      <th>278</th>\n",
       "      <th>61</th>\n",
       "      <th>0</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.30</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.24</th>\n",
       "      <th>1.93</th>\n",
       "      <th>0.39</th>\n",
       "      <th>1.29</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.36</th>\n",
       "      <th>0.17</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.034433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>133</td>\n",
       "      <td>51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.194212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.26</td>\n",
       "      <td>290</td>\n",
       "      <td>287</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.14</td>\n",
       "      <td>898</td>\n",
       "      <td>217</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0.00</td>\n",
       "      <td>740</td>\n",
       "      <td>54</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.081908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0.00</td>\n",
       "      <td>92</td>\n",
       "      <td>11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0.00</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.196239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.7  278   61     0  0.34  0.30   0.5   0.44  0.40  0.778  0.24  1.93  \\\n",
       "0    0.00    3    1  0.00   0.0   0.0  0.00  0.000   0.0  0.000   0.0  0.00   \n",
       "1    0.00   32    2  0.71   0.0   0.0  0.00  0.000   0.0  0.000   0.0  1.43   \n",
       "2    0.00  133   51  0.00   0.0   0.0  0.00  0.000   0.0  0.000   0.0  0.00   \n",
       "3    1.26  290  287  0.00   0.0   0.0  1.26  0.000   0.0  0.537   0.0  2.53   \n",
       "4    0.00   23    3  0.00   0.0   0.0  0.00  0.000   0.0  0.000   0.0  3.75   \n",
       "..    ...  ...  ...   ...   ...   ...   ...    ...   ...    ...   ...   ...   \n",
       "915  0.14  898  217  0.14   0.0   0.0  1.47  0.215   0.0  1.004   0.0  2.35   \n",
       "916  0.00  740   54  0.09   0.0   0.0  0.09  0.979   0.0  5.213   0.0  3.75   \n",
       "917  0.00    3    1  0.00   0.0   0.0  0.00  0.000   0.0  0.000   0.0  0.00   \n",
       "918  0.00   92   11  0.00   0.0   0.0  0.00  0.000   0.0  0.000   0.0  1.12   \n",
       "919  0.00   29    7  0.00   0.0   0.0  0.00  0.000   0.0  0.000   0.0  0.00   \n",
       "\n",
       "     0.39  1.29  0.43   0.2  0.36  0.17  0.20      0.28  \n",
       "0     0.0  0.00   0.0  0.00   0.0  0.00   0.0  0.002779  \n",
       "1     0.0  0.00   0.0  0.00   0.0  0.00   0.0 -0.034433  \n",
       "2     0.0  0.00   0.0  0.00   0.0  1.09   0.0  0.194212  \n",
       "3     0.0  0.00   0.0  0.00   0.0  0.00   0.0  0.038015  \n",
       "4     0.0  0.00   0.0  0.00   0.0  0.00   0.0  0.044489  \n",
       "..    ...   ...   ...   ...   ...   ...   ...       ...  \n",
       "915   0.0  1.62   0.0  0.29   0.0  0.00   0.0  0.010297  \n",
       "916   0.0  0.00   0.0  0.19   0.0  0.00   0.0 -0.081908  \n",
       "917   0.0  0.00   0.0  0.00   0.0  0.00   0.0  0.002779  \n",
       "918   0.0  0.00   0.0  0.00   0.0  0.56   0.0  0.082900  \n",
       "919   0.0  0.00   0.0  0.00   0.0  3.44   0.0  1.196239  \n",
       "\n",
       "[920 rows x 20 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:26:15,275]\u001b[0m A new study created in memory with name: no-name-220f8d79-6f84-4287-ad03-d178c398b61e\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:16,464]\u001b[0m Trial 0 finished with value: 0.11310878690909139 and parameters: {'n_estimators': 648, 'max_depth': 8, 'learning_rate': 0.017830814995521777}. Best is trial 0 with value: 0.11310878690909139.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:18,444]\u001b[0m Trial 1 finished with value: 0.1177235940134771 and parameters: {'n_estimators': 955, 'max_depth': 8, 'learning_rate': 0.08187911297976688}. Best is trial 0 with value: 0.11310878690909139.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:19,583]\u001b[0m Trial 2 finished with value: 0.11264144655996913 and parameters: {'n_estimators': 643, 'max_depth': 7, 'learning_rate': 0.026280161387647848}. Best is trial 2 with value: 0.11264144655996913.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:19,804]\u001b[0m Trial 3 finished with value: 0.11336486306456495 and parameters: {'n_estimators': 163, 'max_depth': 5, 'learning_rate': 0.06800679628998191}. Best is trial 2 with value: 0.11264144655996913.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:21,332]\u001b[0m Trial 4 finished with value: 0.11595282556536161 and parameters: {'n_estimators': 755, 'max_depth': 8, 'learning_rate': 0.06805450179008503}. Best is trial 2 with value: 0.11264144655996913.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:21,934]\u001b[0m Trial 5 finished with value: 0.11638552800735077 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.013606143314301421}. Best is trial 2 with value: 0.11264144655996913.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:22,269]\u001b[0m Trial 6 finished with value: 0.11301490989915264 and parameters: {'n_estimators': 174, 'max_depth': 8, 'learning_rate': 0.04983849558922178}. Best is trial 2 with value: 0.11264144655996913.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:23,026]\u001b[0m Trial 7 finished with value: 0.11300080335705683 and parameters: {'n_estimators': 467, 'max_depth': 6, 'learning_rate': 0.05470218634333026}. Best is trial 2 with value: 0.11264144655996913.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:23,811]\u001b[0m Trial 8 finished with value: 0.11343053095467362 and parameters: {'n_estimators': 467, 'max_depth': 7, 'learning_rate': 0.07507203225209778}. Best is trial 2 with value: 0.11264144655996913.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:24,445]\u001b[0m Trial 9 finished with value: 0.11373762055889033 and parameters: {'n_estimators': 325, 'max_depth': 8, 'learning_rate': 0.06535804203055665}. Best is trial 2 with value: 0.11264144655996913.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.21\n",
      "{'n_estimators': 643, 'max_depth': 7, 'learning_rate': 0.026280161387647848}\n",
      "0.026280161387647848 7 643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:26:24,757]\u001b[0m A new study created in memory with name: no-name-9f831a47-118f-470a-b558-f56bb61be2c4\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:25,188]\u001b[0m Trial 0 finished with value: 0.6356806978330608 and parameters: {'n_estimators': 577, 'max_depth': 3, 'learning_rate': 0.09194818999947596}. Best is trial 0 with value: 0.6356806978330608.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:26,102]\u001b[0m Trial 1 finished with value: 0.6289395149787586 and parameters: {'n_estimators': 968, 'max_depth': 4, 'learning_rate': 0.020372847463071893}. Best is trial 1 with value: 0.6289395149787586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:27,037]\u001b[0m Trial 2 finished with value: 0.6432645898910188 and parameters: {'n_estimators': 757, 'max_depth': 5, 'learning_rate': 0.09433430878434203}. Best is trial 1 with value: 0.6289395149787586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:27,629]\u001b[0m Trial 3 finished with value: 0.6229015895653396 and parameters: {'n_estimators': 235, 'max_depth': 8, 'learning_rate': 0.014645103951150115}. Best is trial 3 with value: 0.6229015895653396.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:28,263]\u001b[0m Trial 4 finished with value: 0.6245513373988449 and parameters: {'n_estimators': 306, 'max_depth': 6, 'learning_rate': 0.025891981586796724}. Best is trial 3 with value: 0.6229015895653396.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:29,332]\u001b[0m Trial 5 finished with value: 0.6549538746058199 and parameters: {'n_estimators': 861, 'max_depth': 5, 'learning_rate': 0.09694318555901595}. Best is trial 3 with value: 0.6229015895653396.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:29,958]\u001b[0m Trial 6 finished with value: 0.6203861316312338 and parameters: {'n_estimators': 295, 'max_depth': 8, 'learning_rate': 0.028049175367755544}. Best is trial 6 with value: 0.6203861316312338.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:30,598]\u001b[0m Trial 7 finished with value: 0.6228950028839604 and parameters: {'n_estimators': 361, 'max_depth': 6, 'learning_rate': 0.05142925351684802}. Best is trial 6 with value: 0.6203861316312338.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:30,846]\u001b[0m Trial 8 finished with value: 0.6294468119193067 and parameters: {'n_estimators': 242, 'max_depth': 4, 'learning_rate': 0.05950423576854528}. Best is trial 6 with value: 0.6203861316312338.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:31,277]\u001b[0m Trial 9 finished with value: 0.6238644634305086 and parameters: {'n_estimators': 341, 'max_depth': 5, 'learning_rate': 0.03587796329305708}. Best is trial 6 with value: 0.6203861316312338.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:31,427]\u001b[0m A new study created in memory with name: no-name-27eb6bf7-a071-43f4-8540-9bc14b805675\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.32.1\n",
      "{'n_estimators': 295, 'max_depth': 8, 'learning_rate': 0.028049175367755544}\n",
      "0.028049175367755544 8 295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:26:33,608]\u001b[0m Trial 0 finished with value: 0.028588595999779653 and parameters: {'n_estimators': 822, 'max_depth': 8, 'learning_rate': 0.02042240535047624}. Best is trial 0 with value: 0.028588595999779653.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:33,824]\u001b[0m Trial 1 finished with value: 0.0380069552690906 and parameters: {'n_estimators': 242, 'max_depth': 3, 'learning_rate': 0.017861479153952694}. Best is trial 0 with value: 0.028588595999779653.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:34,316]\u001b[0m Trial 2 finished with value: 0.03687842572633389 and parameters: {'n_estimators': 630, 'max_depth': 3, 'learning_rate': 0.010469196424766168}. Best is trial 0 with value: 0.028588595999779653.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:34,677]\u001b[0m Trial 3 finished with value: 0.03212871247378287 and parameters: {'n_estimators': 326, 'max_depth': 4, 'learning_rate': 0.035184627700520756}. Best is trial 0 with value: 0.028588595999779653.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:35,005]\u001b[0m Trial 4 finished with value: 0.03845805690507594 and parameters: {'n_estimators': 414, 'max_depth': 3, 'learning_rate': 0.010073381260382822}. Best is trial 0 with value: 0.028588595999779653.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:35,902]\u001b[0m Trial 5 finished with value: 0.028612879928553957 and parameters: {'n_estimators': 320, 'max_depth': 8, 'learning_rate': 0.039651176368189746}. Best is trial 0 with value: 0.028588595999779653.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:36,161]\u001b[0m Trial 6 finished with value: 0.03608171222681307 and parameters: {'n_estimators': 327, 'max_depth': 3, 'learning_rate': 0.03187425549277394}. Best is trial 0 with value: 0.028588595999779653.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:37,136]\u001b[0m Trial 7 finished with value: 0.030749148439203546 and parameters: {'n_estimators': 681, 'max_depth': 5, 'learning_rate': 0.012138332083752453}. Best is trial 0 with value: 0.028588595999779653.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:38,863]\u001b[0m Trial 8 finished with value: 0.028848496172552345 and parameters: {'n_estimators': 574, 'max_depth': 9, 'learning_rate': 0.03423438593320018}. Best is trial 0 with value: 0.028588595999779653.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:39,738]\u001b[0m Trial 9 finished with value: 0.032165196724596695 and parameters: {'n_estimators': 885, 'max_depth': 4, 'learning_rate': 0.09545165744002912}. Best is trial 0 with value: 0.028588595999779653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.41\n",
      "{'n_estimators': 822, 'max_depth': 8, 'learning_rate': 0.02042240535047624}\n",
      "0.02042240535047624 8 822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:26:40,096]\u001b[0m A new study created in memory with name: no-name-5ad56cdb-6d01-4fe6-83d0-7225b55a63b7\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:40,542]\u001b[0m Trial 0 finished with value: 0.04504566701103679 and parameters: {'n_estimators': 395, 'max_depth': 6, 'learning_rate': 0.08410051244343117}. Best is trial 0 with value: 0.04504566701103679.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:41,269]\u001b[0m Trial 1 finished with value: 0.04515890455857679 and parameters: {'n_estimators': 679, 'max_depth': 6, 'learning_rate': 0.06271964795583695}. Best is trial 0 with value: 0.04504566701103679.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:41,514]\u001b[0m Trial 2 finished with value: 0.043549269110793015 and parameters: {'n_estimators': 263, 'max_depth': 4, 'learning_rate': 0.03226792543838483}. Best is trial 2 with value: 0.043549269110793015.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:42,369]\u001b[0m Trial 3 finished with value: 0.045640062071136224 and parameters: {'n_estimators': 641, 'max_depth': 7, 'learning_rate': 0.059469511437791264}. Best is trial 2 with value: 0.043549269110793015.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:43,899]\u001b[0m Trial 4 finished with value: 0.04537703148630005 and parameters: {'n_estimators': 852, 'max_depth': 8, 'learning_rate': 0.03228316375899749}. Best is trial 2 with value: 0.043549269110793015.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:44,218]\u001b[0m Trial 5 finished with value: 0.0446238683865754 and parameters: {'n_estimators': 288, 'max_depth': 6, 'learning_rate': 0.07651150120162165}. Best is trial 2 with value: 0.043549269110793015.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:44,640]\u001b[0m Trial 6 finished with value: 0.04370255246950174 and parameters: {'n_estimators': 284, 'max_depth': 7, 'learning_rate': 0.013697436880248033}. Best is trial 2 with value: 0.043549269110793015.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:45,064]\u001b[0m Trial 7 finished with value: 0.044433261756210894 and parameters: {'n_estimators': 215, 'max_depth': 9, 'learning_rate': 0.034203014429155965}. Best is trial 2 with value: 0.043549269110793015.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:45,789]\u001b[0m Trial 8 finished with value: 0.0446104736376512 and parameters: {'n_estimators': 659, 'max_depth': 6, 'learning_rate': 0.03360952458481128}. Best is trial 2 with value: 0.043549269110793015.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:46,273]\u001b[0m Trial 9 finished with value: 0.04376136744571611 and parameters: {'n_estimators': 739, 'max_depth': 3, 'learning_rate': 0.03293215122850525}. Best is trial 2 with value: 0.043549269110793015.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:46,315]\u001b[0m A new study created in memory with name: no-name-258cc7c9-48d4-426b-ae81-10fd86bfb6b0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.29\n",
      "{'n_estimators': 263, 'max_depth': 4, 'learning_rate': 0.03226792543838483}\n",
      "0.03226792543838483 4 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:26:47,511]\u001b[0m Trial 0 finished with value: 449.47539529446215 and parameters: {'n_estimators': 569, 'max_depth': 9, 'learning_rate': 0.011097151359044806}. Best is trial 0 with value: 449.47539529446215.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:47,943]\u001b[0m Trial 1 finished with value: 352.45355749663184 and parameters: {'n_estimators': 489, 'max_depth': 4, 'learning_rate': 0.06566801414190258}. Best is trial 1 with value: 352.45355749663184.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:48,676]\u001b[0m Trial 2 finished with value: 441.39582772128426 and parameters: {'n_estimators': 284, 'max_depth': 9, 'learning_rate': 0.025970100545881437}. Best is trial 1 with value: 352.45355749663184.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:49,801]\u001b[0m Trial 3 finished with value: 415.7594675858412 and parameters: {'n_estimators': 724, 'max_depth': 7, 'learning_rate': 0.013056561055330936}. Best is trial 1 with value: 352.45355749663184.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:50,198]\u001b[0m Trial 4 finished with value: 402.34125350812775 and parameters: {'n_estimators': 586, 'max_depth': 3, 'learning_rate': 0.027143549160051336}. Best is trial 1 with value: 352.45355749663184.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:50,952]\u001b[0m Trial 5 finished with value: 390.9862693976798 and parameters: {'n_estimators': 715, 'max_depth': 5, 'learning_rate': 0.022774286804119626}. Best is trial 1 with value: 352.45355749663184.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:51,791]\u001b[0m Trial 6 finished with value: 371.69232461339107 and parameters: {'n_estimators': 801, 'max_depth': 5, 'learning_rate': 0.032268171599096576}. Best is trial 1 with value: 352.45355749663184.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:52,749]\u001b[0m Trial 7 finished with value: 359.58600431013315 and parameters: {'n_estimators': 659, 'max_depth': 7, 'learning_rate': 0.03503599033772135}. Best is trial 1 with value: 352.45355749663184.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:52,937]\u001b[0m Trial 8 finished with value: 478.0812926453731 and parameters: {'n_estimators': 110, 'max_depth': 6, 'learning_rate': 0.032610989048577774}. Best is trial 1 with value: 352.45355749663184.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:53,635]\u001b[0m Trial 9 finished with value: 383.4369385479931 and parameters: {'n_estimators': 694, 'max_depth': 5, 'learning_rate': 0.025089763454482435}. Best is trial 1 with value: 352.45355749663184.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:53,713]\u001b[0m A new study created in memory with name: no-name-f3ab1ba9-05e6-46fb-b38c-b7b01b97550f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 3.756\n",
      "{'n_estimators': 489, 'max_depth': 4, 'learning_rate': 0.06566801414190258}\n",
      "0.06566801414190258 4 489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:26:54,649]\u001b[0m Trial 0 finished with value: 0.03471864011392497 and parameters: {'n_estimators': 683, 'max_depth': 6, 'learning_rate': 0.024617689639966172}. Best is trial 0 with value: 0.03471864011392497.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:55,550]\u001b[0m Trial 1 finished with value: 0.0342605452470666 and parameters: {'n_estimators': 997, 'max_depth': 4, 'learning_rate': 0.017382851721178094}. Best is trial 1 with value: 0.0342605452470666.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:57,116]\u001b[0m Trial 2 finished with value: 0.036860396813069254 and parameters: {'n_estimators': 766, 'max_depth': 9, 'learning_rate': 0.041067079063605766}. Best is trial 1 with value: 0.0342605452470666.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:57,863]\u001b[0m Trial 3 finished with value: 0.03537935857720545 and parameters: {'n_estimators': 811, 'max_depth': 4, 'learning_rate': 0.07454189232878322}. Best is trial 1 with value: 0.0342605452470666.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:26:58,753]\u001b[0m Trial 4 finished with value: 0.0344234887346776 and parameters: {'n_estimators': 584, 'max_depth': 6, 'learning_rate': 0.010613089794665381}. Best is trial 1 with value: 0.0342605452470666.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:00,570]\u001b[0m Trial 5 finished with value: 0.039381215594392505 and parameters: {'n_estimators': 779, 'max_depth': 8, 'learning_rate': 0.09375205559722731}. Best is trial 1 with value: 0.0342605452470666.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:01,297]\u001b[0m Trial 6 finished with value: 0.03602305762499638 and parameters: {'n_estimators': 654, 'max_depth': 5, 'learning_rate': 0.08030917568880773}. Best is trial 1 with value: 0.0342605452470666.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:02,156]\u001b[0m Trial 7 finished with value: 0.03474330217750924 and parameters: {'n_estimators': 389, 'max_depth': 8, 'learning_rate': 0.013045348308594629}. Best is trial 1 with value: 0.0342605452470666.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:02,437]\u001b[0m Trial 8 finished with value: 0.034629038514846736 and parameters: {'n_estimators': 244, 'max_depth': 5, 'learning_rate': 0.07890303172394846}. Best is trial 1 with value: 0.0342605452470666.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:03,921]\u001b[0m Trial 9 finished with value: 0.03778108162212878 and parameters: {'n_estimators': 853, 'max_depth': 8, 'learning_rate': 0.056715177999121597}. Best is trial 1 with value: 0.0342605452470666.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.35\n",
      "{'n_estimators': 997, 'max_depth': 4, 'learning_rate': 0.017382851721178094}\n",
      "0.017382851721178094 4 997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:27:04,159]\u001b[0m A new study created in memory with name: no-name-a170a057-be48-4c3d-9d73-825e132a8dfe\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:04,850]\u001b[0m Trial 0 finished with value: 0.02676340525931657 and parameters: {'n_estimators': 705, 'max_depth': 5, 'learning_rate': 0.010877388312509258}. Best is trial 0 with value: 0.02676340525931657.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:05,052]\u001b[0m Trial 1 finished with value: 0.025424700447584252 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.06446730386392022}. Best is trial 1 with value: 0.025424700447584252.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:06,088]\u001b[0m Trial 2 finished with value: 0.02495687616851793 and parameters: {'n_estimators': 737, 'max_depth': 7, 'learning_rate': 0.03311712271665824}. Best is trial 2 with value: 0.02495687616851793.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:06,397]\u001b[0m Trial 3 finished with value: 0.02592515355239171 and parameters: {'n_estimators': 441, 'max_depth': 3, 'learning_rate': 0.02450143303207253}. Best is trial 2 with value: 0.02495687616851793.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:06,694]\u001b[0m Trial 4 finished with value: 0.024980034111880312 and parameters: {'n_estimators': 315, 'max_depth': 4, 'learning_rate': 0.0891063627886349}. Best is trial 2 with value: 0.02495687616851793.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:07,342]\u001b[0m Trial 5 finished with value: 0.034424351939729626 and parameters: {'n_estimators': 292, 'max_depth': 9, 'learning_rate': 0.01409336423131671}. Best is trial 2 with value: 0.02495687616851793.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:08,341]\u001b[0m Trial 6 finished with value: 0.025142220689679595 and parameters: {'n_estimators': 570, 'max_depth': 7, 'learning_rate': 0.07470985265997758}. Best is trial 2 with value: 0.02495687616851793.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:08,691]\u001b[0m Trial 7 finished with value: 0.02748004967693888 and parameters: {'n_estimators': 251, 'max_depth': 6, 'learning_rate': 0.028203755204998886}. Best is trial 2 with value: 0.02495687616851793.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:09,416]\u001b[0m Trial 8 finished with value: 0.025080325370832435 and parameters: {'n_estimators': 733, 'max_depth': 5, 'learning_rate': 0.018535006146846816}. Best is trial 2 with value: 0.02495687616851793.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:10,520]\u001b[0m Trial 9 finished with value: 0.025598918447252296 and parameters: {'n_estimators': 682, 'max_depth': 8, 'learning_rate': 0.014498284006304752}. Best is trial 2 with value: 0.02495687616851793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.25\n",
      "{'n_estimators': 737, 'max_depth': 7, 'learning_rate': 0.03311712271665824}\n",
      "0.03311712271665824 7 737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:27:10,937]\u001b[0m A new study created in memory with name: no-name-dbc4c886-c3a2-49a7-ad2f-35989f153627\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:11,178]\u001b[0m Trial 0 finished with value: 0.1438195138421326 and parameters: {'n_estimators': 160, 'max_depth': 3, 'learning_rate': 0.05527275970607102}. Best is trial 0 with value: 0.1438195138421326.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:11,799]\u001b[0m Trial 1 finished with value: 0.14253754862184825 and parameters: {'n_estimators': 828, 'max_depth': 3, 'learning_rate': 0.017649650922132037}. Best is trial 1 with value: 0.14253754862184825.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:12,632]\u001b[0m Trial 2 finished with value: 0.13550839244567556 and parameters: {'n_estimators': 591, 'max_depth': 5, 'learning_rate': 0.023442399837254883}. Best is trial 2 with value: 0.13550839244567556.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:14,037]\u001b[0m Trial 3 finished with value: 0.13369605276495858 and parameters: {'n_estimators': 859, 'max_depth': 7, 'learning_rate': 0.019852488539425357}. Best is trial 3 with value: 0.13369605276495858.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:14,371]\u001b[0m Trial 4 finished with value: 0.13849248713394108 and parameters: {'n_estimators': 382, 'max_depth': 4, 'learning_rate': 0.037454399768854084}. Best is trial 3 with value: 0.13369605276495858.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:14,662]\u001b[0m Trial 5 finished with value: 0.14281467887164187 and parameters: {'n_estimators': 378, 'max_depth': 3, 'learning_rate': 0.032415810026805866}. Best is trial 3 with value: 0.13369605276495858.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:15,161]\u001b[0m Trial 6 finished with value: 0.13424224846308772 and parameters: {'n_estimators': 229, 'max_depth': 9, 'learning_rate': 0.03257578629912288}. Best is trial 3 with value: 0.13369605276495858.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:16,287]\u001b[0m Trial 7 finished with value: 0.13415389038058623 and parameters: {'n_estimators': 523, 'max_depth': 9, 'learning_rate': 0.013918861680864793}. Best is trial 3 with value: 0.13369605276495858.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:17,591]\u001b[0m Trial 8 finished with value: 0.1469545237502171 and parameters: {'n_estimators': 630, 'max_depth': 9, 'learning_rate': 0.08054714540767245}. Best is trial 3 with value: 0.13369605276495858.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:17,893]\u001b[0m Trial 9 finished with value: 0.1422043936386009 and parameters: {'n_estimators': 221, 'max_depth': 4, 'learning_rate': 0.015402666007219633}. Best is trial 3 with value: 0.13369605276495858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.15\n",
      "{'n_estimators': 859, 'max_depth': 7, 'learning_rate': 0.019852488539425357}\n",
      "0.019852488539425357 7 859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:27:18,160]\u001b[0m A new study created in memory with name: no-name-4281c48d-da45-42f8-941f-fff9860b82d7\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:19,128]\u001b[0m Trial 0 finished with value: 0.23184130774521802 and parameters: {'n_estimators': 514, 'max_depth': 6, 'learning_rate': 0.012722609838747914}. Best is trial 0 with value: 0.23184130774521802.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:20,332]\u001b[0m Trial 1 finished with value: 0.24343678491157114 and parameters: {'n_estimators': 894, 'max_depth': 5, 'learning_rate': 0.05818839268795099}. Best is trial 0 with value: 0.23184130774521802.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:21,001]\u001b[0m Trial 2 finished with value: 0.2395794721628255 and parameters: {'n_estimators': 643, 'max_depth': 4, 'learning_rate': 0.08389773564698645}. Best is trial 0 with value: 0.23184130774521802.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:21,150]\u001b[0m Trial 3 finished with value: 0.23416837740506224 and parameters: {'n_estimators': 152, 'max_depth': 3, 'learning_rate': 0.03892956345881562}. Best is trial 0 with value: 0.23184130774521802.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:21,632]\u001b[0m Trial 4 finished with value: 0.2335301463082337 and parameters: {'n_estimators': 312, 'max_depth': 5, 'learning_rate': 0.04333717433643041}. Best is trial 0 with value: 0.23184130774521802.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:22,713]\u001b[0m Trial 5 finished with value: 0.23416857575830208 and parameters: {'n_estimators': 542, 'max_depth': 8, 'learning_rate': 0.025534750311383744}. Best is trial 0 with value: 0.23184130774521802.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:24,287]\u001b[0m Trial 6 finished with value: 0.23216233164482195 and parameters: {'n_estimators': 679, 'max_depth': 8, 'learning_rate': 0.01062213855058993}. Best is trial 0 with value: 0.23184130774521802.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:24,729]\u001b[0m Trial 7 finished with value: 0.23210335416885003 and parameters: {'n_estimators': 169, 'max_depth': 8, 'learning_rate': 0.022728210026369575}. Best is trial 0 with value: 0.23184130774521802.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:26,154]\u001b[0m Trial 8 finished with value: 0.2315563849850823 and parameters: {'n_estimators': 599, 'max_depth': 9, 'learning_rate': 0.013652899823372875}. Best is trial 8 with value: 0.2315563849850823.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:26,513]\u001b[0m Trial 9 finished with value: 0.23135473984379723 and parameters: {'n_estimators': 107, 'max_depth': 9, 'learning_rate': 0.021318225986162172}. Best is trial 9 with value: 0.23135473984379723.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:26,586]\u001b[0m A new study created in memory with name: no-name-b986fc56-9682-412a-aa71-743d42f38265\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.64.1\n",
      "{'n_estimators': 107, 'max_depth': 9, 'learning_rate': 0.021318225986162172}\n",
      "0.021318225986162172 9 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:27:29,393]\u001b[0m Trial 0 finished with value: 0.6372119359128666 and parameters: {'n_estimators': 957, 'max_depth': 9, 'learning_rate': 0.02118583562648622}. Best is trial 0 with value: 0.6372119359128666.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:30,305]\u001b[0m Trial 1 finished with value: 0.6382623418723222 and parameters: {'n_estimators': 429, 'max_depth': 7, 'learning_rate': 0.07334520373385316}. Best is trial 0 with value: 0.6372119359128666.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:30,819]\u001b[0m Trial 2 finished with value: 0.6525681655819237 and parameters: {'n_estimators': 655, 'max_depth': 3, 'learning_rate': 0.020048424393152}. Best is trial 0 with value: 0.6372119359128666.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:31,610]\u001b[0m Trial 3 finished with value: 0.6301570547393851 and parameters: {'n_estimators': 328, 'max_depth': 7, 'learning_rate': 0.027439260173225892}. Best is trial 3 with value: 0.6301570547393851.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:32,194]\u001b[0m Trial 4 finished with value: 0.6327265694945784 and parameters: {'n_estimators': 234, 'max_depth': 8, 'learning_rate': 0.06287935547489144}. Best is trial 3 with value: 0.6301570547393851.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:33,712]\u001b[0m Trial 5 finished with value: 0.6299184855778649 and parameters: {'n_estimators': 534, 'max_depth': 8, 'learning_rate': 0.015218949041095121}. Best is trial 5 with value: 0.6299184855778649.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:36,384]\u001b[0m Trial 6 finished with value: 0.6501192278598278 and parameters: {'n_estimators': 986, 'max_depth': 9, 'learning_rate': 0.03613482814151225}. Best is trial 5 with value: 0.6299184855778649.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:37,213]\u001b[0m Trial 7 finished with value: 0.6321985714633704 and parameters: {'n_estimators': 321, 'max_depth': 8, 'learning_rate': 0.0505338139516357}. Best is trial 5 with value: 0.6299184855778649.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:39,133]\u001b[0m Trial 8 finished with value: 0.6877736314672385 and parameters: {'n_estimators': 999, 'max_depth': 7, 'learning_rate': 0.08795876402693582}. Best is trial 5 with value: 0.6299184855778649.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:39,709]\u001b[0m Trial 9 finished with value: 0.6317653502299804 and parameters: {'n_estimators': 215, 'max_depth': 7, 'learning_rate': 0.03461855705008035}. Best is trial 5 with value: 0.6299184855778649.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.38\n",
      "{'n_estimators': 534, 'max_depth': 8, 'learning_rate': 0.015218949041095121}\n",
      "0.015218949041095121 8 534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:27:40,002]\u001b[0m A new study created in memory with name: no-name-6f9784cd-5573-4826-8fd4-9a75bcf6512b\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:41,673]\u001b[0m Trial 0 finished with value: 0.22245053130038245 and parameters: {'n_estimators': 627, 'max_depth': 8, 'learning_rate': 0.01020007485014651}. Best is trial 0 with value: 0.22245053130038245.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:42,646]\u001b[0m Trial 1 finished with value: 0.22265293587139473 and parameters: {'n_estimators': 393, 'max_depth': 8, 'learning_rate': 0.020467605235933932}. Best is trial 0 with value: 0.22245053130038245.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:44,185]\u001b[0m Trial 2 finished with value: 0.2221450142458914 and parameters: {'n_estimators': 515, 'max_depth': 9, 'learning_rate': 0.02245323273094376}. Best is trial 2 with value: 0.2221450142458914.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:45,386]\u001b[0m Trial 3 finished with value: 0.23889287517897198 and parameters: {'n_estimators': 584, 'max_depth': 7, 'learning_rate': 0.08555716395034325}. Best is trial 2 with value: 0.2221450142458914.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:47,713]\u001b[0m Trial 4 finished with value: 0.22380030518717633 and parameters: {'n_estimators': 875, 'max_depth': 9, 'learning_rate': 0.019217686782084728}. Best is trial 2 with value: 0.2221450142458914.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:48,270]\u001b[0m Trial 5 finished with value: 0.2259778919451378 and parameters: {'n_estimators': 209, 'max_depth': 6, 'learning_rate': 0.02912092650256461}. Best is trial 2 with value: 0.2221450142458914.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:49,040]\u001b[0m Trial 6 finished with value: 0.22191001359895482 and parameters: {'n_estimators': 288, 'max_depth': 9, 'learning_rate': 0.034255911533806915}. Best is trial 6 with value: 0.22191001359895482.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:51,654]\u001b[0m Trial 7 finished with value: 0.2241332736670778 and parameters: {'n_estimators': 993, 'max_depth': 9, 'learning_rate': 0.018125653498767498}. Best is trial 6 with value: 0.22191001359895482.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:51,841]\u001b[0m Trial 8 finished with value: 0.2305142180845082 and parameters: {'n_estimators': 214, 'max_depth': 3, 'learning_rate': 0.028737955521316288}. Best is trial 6 with value: 0.22191001359895482.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:54,382]\u001b[0m Trial 9 finished with value: 0.234107680808596 and parameters: {'n_estimators': 971, 'max_depth': 9, 'learning_rate': 0.04361105505410774}. Best is trial 6 with value: 0.22191001359895482.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:54,551]\u001b[0m A new study created in memory with name: no-name-f79477da-b371-48f7-9baf-8435567d725d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.45\n",
      "{'n_estimators': 288, 'max_depth': 9, 'learning_rate': 0.034255911533806915}\n",
      "0.034255911533806915 9 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:27:55,319]\u001b[0m Trial 0 finished with value: 0.3583880654997618 and parameters: {'n_estimators': 792, 'max_depth': 4, 'learning_rate': 0.03013588019079829}. Best is trial 0 with value: 0.3583880654997618.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:57,012]\u001b[0m Trial 1 finished with value: 0.3852442053013223 and parameters: {'n_estimators': 827, 'max_depth': 7, 'learning_rate': 0.08082978846122217}. Best is trial 0 with value: 0.3583880654997618.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:57,544]\u001b[0m Trial 2 finished with value: 0.3580071880176872 and parameters: {'n_estimators': 174, 'max_depth': 8, 'learning_rate': 0.010816654026753733}. Best is trial 2 with value: 0.3580071880176872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:58,356]\u001b[0m Trial 3 finished with value: 0.35849682362916396 and parameters: {'n_estimators': 712, 'max_depth': 4, 'learning_rate': 0.03146520853033592}. Best is trial 2 with value: 0.3580071880176872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:27:58,614]\u001b[0m Trial 4 finished with value: 0.3611673738431328 and parameters: {'n_estimators': 324, 'max_depth': 3, 'learning_rate': 0.02454051048251236}. Best is trial 2 with value: 0.3580071880176872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:00,228]\u001b[0m Trial 5 finished with value: 0.35885984261036236 and parameters: {'n_estimators': 726, 'max_depth': 8, 'learning_rate': 0.021933597180281907}. Best is trial 2 with value: 0.3580071880176872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:00,943]\u001b[0m Trial 6 finished with value: 0.3592921558184249 and parameters: {'n_estimators': 502, 'max_depth': 5, 'learning_rate': 0.048057430775276265}. Best is trial 2 with value: 0.3580071880176872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:01,281]\u001b[0m Trial 7 finished with value: 0.36264393222574703 and parameters: {'n_estimators': 106, 'max_depth': 8, 'learning_rate': 0.011077940307118136}. Best is trial 2 with value: 0.3580071880176872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:01,639]\u001b[0m Trial 8 finished with value: 0.3622742675429753 and parameters: {'n_estimators': 470, 'max_depth': 3, 'learning_rate': 0.0755726521115236}. Best is trial 2 with value: 0.3580071880176872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:02,547]\u001b[0m Trial 9 finished with value: 0.35860647870391277 and parameters: {'n_estimators': 940, 'max_depth': 4, 'learning_rate': 0.026488535484521878}. Best is trial 2 with value: 0.3580071880176872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:02,676]\u001b[0m A new study created in memory with name: no-name-40592a9d-60b7-489d-94d3-8479aa568d03\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.6\n",
      "{'n_estimators': 174, 'max_depth': 8, 'learning_rate': 0.010816654026753733}\n",
      "0.010816654026753733 8 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:28:03,417]\u001b[0m Trial 0 finished with value: 0.08941252071231645 and parameters: {'n_estimators': 265, 'max_depth': 9, 'learning_rate': 0.01890910191295218}. Best is trial 0 with value: 0.08941252071231645.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:05,226]\u001b[0m Trial 1 finished with value: 0.06808478133873379 and parameters: {'n_estimators': 773, 'max_depth': 8, 'learning_rate': 0.0827460559018621}. Best is trial 1 with value: 0.06808478133873379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:06,306]\u001b[0m Trial 2 finished with value: 0.0859748776623235 and parameters: {'n_estimators': 557, 'max_depth': 6, 'learning_rate': 0.015145856885594156}. Best is trial 1 with value: 0.06808478133873379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:06,910]\u001b[0m Trial 3 finished with value: 0.07901456316524386 and parameters: {'n_estimators': 340, 'max_depth': 5, 'learning_rate': 0.045197404214462965}. Best is trial 1 with value: 0.06808478133873379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:08,217]\u001b[0m Trial 4 finished with value: 0.06973429085712815 and parameters: {'n_estimators': 993, 'max_depth': 5, 'learning_rate': 0.03770086432785193}. Best is trial 1 with value: 0.06808478133873379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:08,360]\u001b[0m Trial 5 finished with value: 0.11043751185045259 and parameters: {'n_estimators': 129, 'max_depth': 4, 'learning_rate': 0.03353240029140627}. Best is trial 1 with value: 0.06808478133873379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:09,595]\u001b[0m Trial 6 finished with value: 0.06771095900030363 and parameters: {'n_estimators': 545, 'max_depth': 7, 'learning_rate': 0.07572413193760145}. Best is trial 6 with value: 0.06771095900030363.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:10,286]\u001b[0m Trial 7 finished with value: 0.09453183044564033 and parameters: {'n_estimators': 294, 'max_depth': 7, 'learning_rate': 0.014868239895420618}. Best is trial 6 with value: 0.06771095900030363.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:10,763]\u001b[0m Trial 8 finished with value: 0.09324507201996465 and parameters: {'n_estimators': 431, 'max_depth': 4, 'learning_rate': 0.023886327533590598}. Best is trial 6 with value: 0.06771095900030363.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:11,381]\u001b[0m Trial 9 finished with value: 0.08422750718687759 and parameters: {'n_estimators': 722, 'max_depth': 3, 'learning_rate': 0.03528892322527734}. Best is trial 6 with value: 0.06771095900030363.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.33\n",
      "{'n_estimators': 545, 'max_depth': 7, 'learning_rate': 0.07572413193760145}\n",
      "0.07572413193760145 7 545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:28:11,631]\u001b[0m A new study created in memory with name: no-name-5ee63530-eb2e-499f-bf93-d370753ef997\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:11,905]\u001b[0m Trial 0 finished with value: 0.07321317937727062 and parameters: {'n_estimators': 294, 'max_depth': 4, 'learning_rate': 0.0818387676577995}. Best is trial 0 with value: 0.07321317937727062.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:13,552]\u001b[0m Trial 1 finished with value: 0.07335797933130872 and parameters: {'n_estimators': 921, 'max_depth': 8, 'learning_rate': 0.032008015375487225}. Best is trial 0 with value: 0.07321317937727062.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:14,087]\u001b[0m Trial 2 finished with value: 0.0809939059717318 and parameters: {'n_estimators': 820, 'max_depth': 3, 'learning_rate': 0.08671071049169807}. Best is trial 0 with value: 0.07321317937727062.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:14,897]\u001b[0m Trial 3 finished with value: 0.07465540850484353 and parameters: {'n_estimators': 858, 'max_depth': 4, 'learning_rate': 0.03977782507165125}. Best is trial 0 with value: 0.07321317937727062.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:15,672]\u001b[0m Trial 4 finished with value: 0.07239538667409262 and parameters: {'n_estimators': 894, 'max_depth': 4, 'learning_rate': 0.01981258514976773}. Best is trial 4 with value: 0.07239538667409262.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:16,145]\u001b[0m Trial 5 finished with value: 0.07162546433294752 and parameters: {'n_estimators': 309, 'max_depth': 7, 'learning_rate': 0.0618549274037145}. Best is trial 5 with value: 0.07162546433294752.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:16,759]\u001b[0m Trial 6 finished with value: 0.07028424943131054 and parameters: {'n_estimators': 229, 'max_depth': 9, 'learning_rate': 0.04096820806279324}. Best is trial 6 with value: 0.07028424943131054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:17,101]\u001b[0m Trial 7 finished with value: 0.07056628392064039 and parameters: {'n_estimators': 186, 'max_depth': 8, 'learning_rate': 0.0489170922723312}. Best is trial 6 with value: 0.07028424943131054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:17,730]\u001b[0m Trial 8 finished with value: 0.07064977006535998 and parameters: {'n_estimators': 382, 'max_depth': 7, 'learning_rate': 0.01733099228232847}. Best is trial 6 with value: 0.07028424943131054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:18,113]\u001b[0m Trial 9 finished with value: 0.0709258661938505 and parameters: {'n_estimators': 188, 'max_depth': 9, 'learning_rate': 0.09115308450528742}. Best is trial 6 with value: 0.07028424943131054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:18,226]\u001b[0m A new study created in memory with name: no-name-8585b43e-e5a3-462a-87fd-42294f898230\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.42\n",
      "{'n_estimators': 229, 'max_depth': 9, 'learning_rate': 0.04096820806279324}\n",
      "0.04096820806279324 9 229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:28:18,870]\u001b[0m Trial 0 finished with value: 0.06509020111542603 and parameters: {'n_estimators': 870, 'max_depth': 3, 'learning_rate': 0.012733022180494238}. Best is trial 0 with value: 0.06509020111542603.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:19,417]\u001b[0m Trial 1 finished with value: 0.05977105881863195 and parameters: {'n_estimators': 610, 'max_depth': 4, 'learning_rate': 0.06691562161964089}. Best is trial 1 with value: 0.05977105881863195.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:21,020]\u001b[0m Trial 2 finished with value: 0.05853481655287136 and parameters: {'n_estimators': 951, 'max_depth': 7, 'learning_rate': 0.0325746856052174}. Best is trial 2 with value: 0.05853481655287136.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:21,490]\u001b[0m Trial 3 finished with value: 0.059455383166559204 and parameters: {'n_estimators': 212, 'max_depth': 9, 'learning_rate': 0.029418450392821496}. Best is trial 2 with value: 0.05853481655287136.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:22,035]\u001b[0m Trial 4 finished with value: 0.06417252795852321 and parameters: {'n_estimators': 519, 'max_depth': 4, 'learning_rate': 0.01067807860398147}. Best is trial 2 with value: 0.05853481655287136.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:23,477]\u001b[0m Trial 5 finished with value: 0.05830560152867152 and parameters: {'n_estimators': 626, 'max_depth': 9, 'learning_rate': 0.02034308424766325}. Best is trial 5 with value: 0.05830560152867152.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:24,791]\u001b[0m Trial 6 finished with value: 0.057416633004606574 and parameters: {'n_estimators': 605, 'max_depth': 9, 'learning_rate': 0.0709463047397812}. Best is trial 6 with value: 0.057416633004606574.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:24,989]\u001b[0m Trial 7 finished with value: 0.062388881903969004 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.054234295638197795}. Best is trial 6 with value: 0.057416633004606574.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:25,665]\u001b[0m Trial 8 finished with value: 0.06289234821772645 and parameters: {'n_estimators': 659, 'max_depth': 4, 'learning_rate': 0.013606883487419416}. Best is trial 6 with value: 0.057416633004606574.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:26,054]\u001b[0m Trial 9 finished with value: 0.06259890120309174 and parameters: {'n_estimators': 383, 'max_depth': 4, 'learning_rate': 0.02645189443606471}. Best is trial 6 with value: 0.057416633004606574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.14\n",
      "{'n_estimators': 605, 'max_depth': 9, 'learning_rate': 0.0709463047397812}\n",
      "0.0709463047397812 9 605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:28:26,314]\u001b[0m A new study created in memory with name: no-name-bfc4d1d2-d42b-449c-b6fa-eb793c5b8995\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:26,884]\u001b[0m Trial 0 finished with value: 0.10865187798411798 and parameters: {'n_estimators': 779, 'max_depth': 3, 'learning_rate': 0.014867311133601641}. Best is trial 0 with value: 0.10865187798411798.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:27,141]\u001b[0m Trial 1 finished with value: 0.11015410791641903 and parameters: {'n_estimators': 214, 'max_depth': 3, 'learning_rate': 0.013298092211065203}. Best is trial 0 with value: 0.10865187798411798.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:27,798]\u001b[0m Trial 2 finished with value: 0.10778077685920003 and parameters: {'n_estimators': 309, 'max_depth': 7, 'learning_rate': 0.038165198848793346}. Best is trial 2 with value: 0.10778077685920003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:28,431]\u001b[0m Trial 3 finished with value: 0.10842654779412997 and parameters: {'n_estimators': 572, 'max_depth': 4, 'learning_rate': 0.011292096005760475}. Best is trial 2 with value: 0.10778077685920003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:28,961]\u001b[0m Trial 4 finished with value: 0.11455877664498851 and parameters: {'n_estimators': 329, 'max_depth': 7, 'learning_rate': 0.09853055314359782}. Best is trial 2 with value: 0.10778077685920003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:29,809]\u001b[0m Trial 5 finished with value: 0.109268776524207 and parameters: {'n_estimators': 418, 'max_depth': 8, 'learning_rate': 0.024659184319574846}. Best is trial 2 with value: 0.10778077685920003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:31,799]\u001b[0m Trial 6 finished with value: 0.11078768610553111 and parameters: {'n_estimators': 779, 'max_depth': 9, 'learning_rate': 0.01755904437580538}. Best is trial 2 with value: 0.10778077685920003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:32,329]\u001b[0m Trial 7 finished with value: 0.10856764524590135 and parameters: {'n_estimators': 505, 'max_depth': 4, 'learning_rate': 0.033020672852418824}. Best is trial 2 with value: 0.10778077685920003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:33,265]\u001b[0m Trial 8 finished with value: 0.12201554451310707 and parameters: {'n_estimators': 499, 'max_depth': 8, 'learning_rate': 0.08059850503006771}. Best is trial 2 with value: 0.10778077685920003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:34,390]\u001b[0m Trial 9 finished with value: 0.11064495312153189 and parameters: {'n_estimators': 963, 'max_depth': 5, 'learning_rate': 0.03643220152324691}. Best is trial 2 with value: 0.10778077685920003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:34,491]\u001b[0m A new study created in memory with name: no-name-b25bed0d-0fd0-4625-9fca-42eabf2b9c46\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.9\n",
      "{'n_estimators': 309, 'max_depth': 7, 'learning_rate': 0.038165198848793346}\n",
      "0.038165198848793346 7 309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:28:36,137]\u001b[0m Trial 0 finished with value: 0.020210939906825993 and parameters: {'n_estimators': 759, 'max_depth': 9, 'learning_rate': 0.024684483300027857}. Best is trial 0 with value: 0.020210939906825993.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:36,473]\u001b[0m Trial 1 finished with value: 0.023567679367088257 and parameters: {'n_estimators': 271, 'max_depth': 4, 'learning_rate': 0.03502444024964016}. Best is trial 0 with value: 0.020210939906825993.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:37,272]\u001b[0m Trial 2 finished with value: 0.02012116054656957 and parameters: {'n_estimators': 637, 'max_depth': 5, 'learning_rate': 0.036840465589839014}. Best is trial 2 with value: 0.02012116054656957.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:37,739]\u001b[0m Trial 3 finished with value: 0.021531520018291735 and parameters: {'n_estimators': 638, 'max_depth': 3, 'learning_rate': 0.0577457166909726}. Best is trial 2 with value: 0.02012116054656957.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:39,716]\u001b[0m Trial 4 finished with value: 0.01933994379712107 and parameters: {'n_estimators': 864, 'max_depth': 9, 'learning_rate': 0.08344150925911951}. Best is trial 4 with value: 0.01933994379712107.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:40,156]\u001b[0m Trial 5 finished with value: 0.02333027445658403 and parameters: {'n_estimators': 174, 'max_depth': 9, 'learning_rate': 0.025527848701664933}. Best is trial 4 with value: 0.01933994379712107.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:42,046]\u001b[0m Trial 6 finished with value: 0.020789095822301772 and parameters: {'n_estimators': 858, 'max_depth': 9, 'learning_rate': 0.018058259436192024}. Best is trial 4 with value: 0.01933994379712107.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:42,955]\u001b[0m Trial 7 finished with value: 0.018873504318828956 and parameters: {'n_estimators': 656, 'max_depth': 5, 'learning_rate': 0.0975580623139856}. Best is trial 7 with value: 0.018873504318828956.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:43,964]\u001b[0m Trial 8 finished with value: 0.021686370296715135 and parameters: {'n_estimators': 882, 'max_depth': 5, 'learning_rate': 0.014033608803739033}. Best is trial 7 with value: 0.018873504318828956.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:44,981]\u001b[0m Trial 9 finished with value: 0.02038477683952583 and parameters: {'n_estimators': 641, 'max_depth': 7, 'learning_rate': 0.03134239445051805}. Best is trial 7 with value: 0.018873504318828956.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:45,170]\u001b[0m A new study created in memory with name: no-name-ee757cdb-7ba0-4841-a181-62ce89152b1e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.10\n",
      "{'n_estimators': 656, 'max_depth': 5, 'learning_rate': 0.0975580623139856}\n",
      "0.0975580623139856 5 656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:28:46,989]\u001b[0m Trial 0 finished with value: 0.1073973754485461 and parameters: {'n_estimators': 734, 'max_depth': 8, 'learning_rate': 0.06719231749099297}. Best is trial 0 with value: 0.1073973754485461.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:48,497]\u001b[0m Trial 1 finished with value: 0.10935968437118175 and parameters: {'n_estimators': 807, 'max_depth': 6, 'learning_rate': 0.02081211260116554}. Best is trial 0 with value: 0.1073973754485461.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:50,629]\u001b[0m Trial 2 finished with value: 0.10665582334922792 and parameters: {'n_estimators': 839, 'max_depth': 9, 'learning_rate': 0.03796441250673249}. Best is trial 2 with value: 0.10665582334922792.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:52,147]\u001b[0m Trial 3 finished with value: 0.10824928909413951 and parameters: {'n_estimators': 917, 'max_depth': 6, 'learning_rate': 0.06501794427966057}. Best is trial 2 with value: 0.10665582334922792.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:52,792]\u001b[0m Trial 4 finished with value: 0.1123662444576056 and parameters: {'n_estimators': 630, 'max_depth': 4, 'learning_rate': 0.04563958471873175}. Best is trial 2 with value: 0.10665582334922792.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:54,238]\u001b[0m Trial 5 finished with value: 0.10871006180405267 and parameters: {'n_estimators': 638, 'max_depth': 8, 'learning_rate': 0.07461129751848258}. Best is trial 2 with value: 0.10665582334922792.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:55,368]\u001b[0m Trial 6 finished with value: 0.11026252342134171 and parameters: {'n_estimators': 811, 'max_depth': 5, 'learning_rate': 0.03684370617946346}. Best is trial 2 with value: 0.10665582334922792.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:56,826]\u001b[0m Trial 7 finished with value: 0.10799514277652547 and parameters: {'n_estimators': 839, 'max_depth': 6, 'learning_rate': 0.03589047297021816}. Best is trial 2 with value: 0.10665582334922792.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:57,409]\u001b[0m Trial 8 finished with value: 0.11405786021472201 and parameters: {'n_estimators': 680, 'max_depth': 3, 'learning_rate': 0.095874758081477}. Best is trial 2 with value: 0.10665582334922792.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:28:59,113]\u001b[0m Trial 9 finished with value: 0.10822029935398036 and parameters: {'n_estimators': 907, 'max_depth': 6, 'learning_rate': 0.04103575136306415}. Best is trial 2 with value: 0.10665582334922792.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.3\n",
      "{'n_estimators': 839, 'max_depth': 9, 'learning_rate': 0.03796441250673249}\n",
      "0.03796441250673249 9 839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:28:59,640]\u001b[0m A new study created in memory with name: no-name-d44faddd-57c7-446c-a400-13c5086a5090\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:00,266]\u001b[0m Trial 0 finished with value: 0.7492711681948798 and parameters: {'n_estimators': 225, 'max_depth': 8, 'learning_rate': 0.029779749996034322}. Best is trial 0 with value: 0.7492711681948798.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:02,009]\u001b[0m Trial 1 finished with value: 0.7215455736199725 and parameters: {'n_estimators': 607, 'max_depth': 9, 'learning_rate': 0.01916419799530823}. Best is trial 1 with value: 0.7215455736199725.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:03,229]\u001b[0m Trial 2 finished with value: 0.7061843528610903 and parameters: {'n_estimators': 756, 'max_depth': 5, 'learning_rate': 0.07858557470889667}. Best is trial 2 with value: 0.7061843528610903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:03,869]\u001b[0m Trial 3 finished with value: 0.7475209177774147 and parameters: {'n_estimators': 259, 'max_depth': 7, 'learning_rate': 0.029770682936285098}. Best is trial 2 with value: 0.7061843528610903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:04,380]\u001b[0m Trial 4 finished with value: 0.8650002112187419 and parameters: {'n_estimators': 661, 'max_depth': 3, 'learning_rate': 0.012250787951362188}. Best is trial 2 with value: 0.7061843528610903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:05,593]\u001b[0m Trial 5 finished with value: 0.7031459460582383 and parameters: {'n_estimators': 871, 'max_depth': 5, 'learning_rate': 0.0723142925313709}. Best is trial 5 with value: 0.7031459460582383.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:06,062]\u001b[0m Trial 6 finished with value: 0.746233910698585 and parameters: {'n_estimators': 399, 'max_depth': 4, 'learning_rate': 0.04736047343461153}. Best is trial 5 with value: 0.7031459460582383.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:07,192]\u001b[0m Trial 7 finished with value: 0.7072384088620541 and parameters: {'n_estimators': 782, 'max_depth': 5, 'learning_rate': 0.07435181887770398}. Best is trial 5 with value: 0.7031459460582383.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:07,566]\u001b[0m Trial 8 finished with value: 0.8120160394333744 and parameters: {'n_estimators': 453, 'max_depth': 3, 'learning_rate': 0.046480018594337355}. Best is trial 5 with value: 0.7031459460582383.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:08,354]\u001b[0m Trial 9 finished with value: 0.718275489193764 and parameters: {'n_estimators': 713, 'max_depth': 4, 'learning_rate': 0.08630220778043421}. Best is trial 5 with value: 0.7031459460582383.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.13\n",
      "{'n_estimators': 871, 'max_depth': 5, 'learning_rate': 0.0723142925313709}\n",
      "0.0723142925313709 5 871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:29:08,653]\u001b[0m A new study created in memory with name: no-name-4044cdbf-f0f5-4134-b93f-a9d9a23bbad4\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:09,034]\u001b[0m Trial 0 finished with value: 0.08460782662341189 and parameters: {'n_estimators': 354, 'max_depth': 4, 'learning_rate': 0.016375870746163215}. Best is trial 0 with value: 0.08460782662341189.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:09,733]\u001b[0m Trial 1 finished with value: 0.08185680230605516 and parameters: {'n_estimators': 299, 'max_depth': 6, 'learning_rate': 0.0153453872669703}. Best is trial 1 with value: 0.08185680230605516.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:10,771]\u001b[0m Trial 2 finished with value: 0.07943371677141825 and parameters: {'n_estimators': 918, 'max_depth': 5, 'learning_rate': 0.08764038503754958}. Best is trial 2 with value: 0.07943371677141825.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:11,052]\u001b[0m Trial 3 finished with value: 0.08188782169780742 and parameters: {'n_estimators': 115, 'max_depth': 7, 'learning_rate': 0.02335541321049205}. Best is trial 2 with value: 0.07943371677141825.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:12,122]\u001b[0m Trial 4 finished with value: 0.08103377462037817 and parameters: {'n_estimators': 641, 'max_depth': 6, 'learning_rate': 0.011327720532392662}. Best is trial 2 with value: 0.07943371677141825.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:13,024]\u001b[0m Trial 5 finished with value: 0.07807824936189432 and parameters: {'n_estimators': 418, 'max_depth': 8, 'learning_rate': 0.05080314840451477}. Best is trial 5 with value: 0.07807824936189432.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:13,374]\u001b[0m Trial 6 finished with value: 0.079492244246527 and parameters: {'n_estimators': 262, 'max_depth': 5, 'learning_rate': 0.07897981983373159}. Best is trial 5 with value: 0.07807824936189432.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:13,695]\u001b[0m Trial 7 finished with value: 0.08549184552404623 and parameters: {'n_estimators': 453, 'max_depth': 3, 'learning_rate': 0.011330264463829412}. Best is trial 5 with value: 0.07807824936189432.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:14,234]\u001b[0m Trial 8 finished with value: 0.0818315078979869 and parameters: {'n_estimators': 204, 'max_depth': 7, 'learning_rate': 0.013935244733455122}. Best is trial 5 with value: 0.07807824936189432.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:14,529]\u001b[0m Trial 9 finished with value: 0.0787421650053183 and parameters: {'n_estimators': 189, 'max_depth': 6, 'learning_rate': 0.08757847624940275}. Best is trial 5 with value: 0.07807824936189432.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:14,718]\u001b[0m A new study created in memory with name: no-name-8f40e23d-5d0c-4f94-ac4e-7c36443284f9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.8\n",
      "{'n_estimators': 418, 'max_depth': 8, 'learning_rate': 0.05080314840451477}\n",
      "0.05080314840451477 8 418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:29:15,292]\u001b[0m Trial 0 finished with value: 0.15319687125636886 and parameters: {'n_estimators': 610, 'max_depth': 4, 'learning_rate': 0.06866323467178896}. Best is trial 0 with value: 0.15319687125636886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:16,225]\u001b[0m Trial 1 finished with value: 0.1530244995298882 and parameters: {'n_estimators': 464, 'max_depth': 6, 'learning_rate': 0.013932814133828247}. Best is trial 1 with value: 0.1530244995298882.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:17,660]\u001b[0m Trial 2 finished with value: 0.15106121764543778 and parameters: {'n_estimators': 802, 'max_depth': 8, 'learning_rate': 0.012166601851275488}. Best is trial 2 with value: 0.15106121764543778.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:18,130]\u001b[0m Trial 3 finished with value: 0.15188669505590272 and parameters: {'n_estimators': 370, 'max_depth': 5, 'learning_rate': 0.06575364929679166}. Best is trial 2 with value: 0.15106121764543778.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:18,484]\u001b[0m Trial 4 finished with value: 0.15542865259212518 and parameters: {'n_estimators': 466, 'max_depth': 3, 'learning_rate': 0.067167050112733}. Best is trial 2 with value: 0.15106121764543778.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:19,164]\u001b[0m Trial 5 finished with value: 0.15030688445187898 and parameters: {'n_estimators': 434, 'max_depth': 7, 'learning_rate': 0.027994271541791075}. Best is trial 5 with value: 0.15030688445187898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:20,354]\u001b[0m Trial 6 finished with value: 0.15173350711533223 and parameters: {'n_estimators': 998, 'max_depth': 5, 'learning_rate': 0.01579002389958184}. Best is trial 5 with value: 0.15030688445187898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:21,267]\u001b[0m Trial 7 finished with value: 0.1503875247837373 and parameters: {'n_estimators': 677, 'max_depth': 6, 'learning_rate': 0.029832997638140017}. Best is trial 5 with value: 0.15030688445187898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:22,248]\u001b[0m Trial 8 finished with value: 0.15193879810345792 and parameters: {'n_estimators': 899, 'max_depth': 5, 'learning_rate': 0.025479471000485605}. Best is trial 5 with value: 0.15030688445187898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:22,437]\u001b[0m Trial 9 finished with value: 0.15517253098347014 and parameters: {'n_estimators': 129, 'max_depth': 4, 'learning_rate': 0.09704446319472193}. Best is trial 5 with value: 0.15030688445187898.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:22,603]\u001b[0m A new study created in memory with name: no-name-bf1642ec-72c2-414f-a50a-4df1af3b5525\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.19\n",
      "{'n_estimators': 434, 'max_depth': 7, 'learning_rate': 0.027994271541791075}\n",
      "0.027994271541791075 7 434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:29:23,459]\u001b[0m Trial 0 finished with value: 0.024107156776085204 and parameters: {'n_estimators': 739, 'max_depth': 5, 'learning_rate': 0.025060756673959742}. Best is trial 0 with value: 0.024107156776085204.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:24,263]\u001b[0m Trial 1 finished with value: 0.024012851794418817 and parameters: {'n_estimators': 713, 'max_depth': 6, 'learning_rate': 0.032867789596035916}. Best is trial 1 with value: 0.024012851794418817.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:24,382]\u001b[0m Trial 2 finished with value: 0.035097848385784884 and parameters: {'n_estimators': 119, 'max_depth': 5, 'learning_rate': 0.032742742434204435}. Best is trial 1 with value: 0.024012851794418817.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:24,961]\u001b[0m Trial 3 finished with value: 0.02481193663237955 and parameters: {'n_estimators': 593, 'max_depth': 4, 'learning_rate': 0.017618432141745872}. Best is trial 1 with value: 0.024012851794418817.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:25,340]\u001b[0m Trial 4 finished with value: 0.02497051322354691 and parameters: {'n_estimators': 593, 'max_depth': 3, 'learning_rate': 0.036561981965647326}. Best is trial 1 with value: 0.024012851794418817.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:25,992]\u001b[0m Trial 5 finished with value: 0.027736157545368324 and parameters: {'n_estimators': 496, 'max_depth': 7, 'learning_rate': 0.012498292394625812}. Best is trial 1 with value: 0.024012851794418817.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:26,627]\u001b[0m Trial 6 finished with value: 0.02402377856247799 and parameters: {'n_estimators': 492, 'max_depth': 6, 'learning_rate': 0.03336041932391819}. Best is trial 1 with value: 0.024012851794418817.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:28,024]\u001b[0m Trial 7 finished with value: 0.02438453644527869 and parameters: {'n_estimators': 937, 'max_depth': 8, 'learning_rate': 0.02414903377801421}. Best is trial 1 with value: 0.024012851794418817.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:28,912]\u001b[0m Trial 8 finished with value: 0.024786272099770062 and parameters: {'n_estimators': 626, 'max_depth': 7, 'learning_rate': 0.0923910468038588}. Best is trial 1 with value: 0.024012851794418817.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:29,655]\u001b[0m Trial 9 finished with value: 0.024910271560504 and parameters: {'n_estimators': 788, 'max_depth': 5, 'learning_rate': 0.012518680104423181}. Best is trial 1 with value: 0.024012851794418817.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:29,845]\u001b[0m A new study created in memory with name: no-name-031c2c3a-ae53-42b5-8260-622cbb52a65e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.23\n",
      "{'n_estimators': 713, 'max_depth': 6, 'learning_rate': 0.032867789596035916}\n",
      "0.032867789596035916 6 713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:29:31,030]\u001b[0m Trial 0 finished with value: 4.6683624404886315 and parameters: {'n_estimators': 718, 'max_depth': 7, 'learning_rate': 0.011156743790437176}. Best is trial 0 with value: 4.6683624404886315.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:31,551]\u001b[0m Trial 1 finished with value: 4.586448317744107 and parameters: {'n_estimators': 278, 'max_depth': 9, 'learning_rate': 0.05531916874016962}. Best is trial 1 with value: 4.586448317744107.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:32,214]\u001b[0m Trial 2 finished with value: 4.561427986171616 and parameters: {'n_estimators': 603, 'max_depth': 5, 'learning_rate': 0.04887725562199509}. Best is trial 2 with value: 4.561427986171616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:32,874]\u001b[0m Trial 3 finished with value: 4.62365296982143 and parameters: {'n_estimators': 427, 'max_depth': 6, 'learning_rate': 0.02556780074063235}. Best is trial 2 with value: 4.561427986171616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:33,671]\u001b[0m Trial 4 finished with value: 4.675677857430644 and parameters: {'n_estimators': 701, 'max_depth': 5, 'learning_rate': 0.010710950772791425}. Best is trial 2 with value: 4.561427986171616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:34,141]\u001b[0m Trial 5 finished with value: 4.717964446298266 and parameters: {'n_estimators': 379, 'max_depth': 5, 'learning_rate': 0.01509780161668198}. Best is trial 2 with value: 4.561427986171616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:35,399]\u001b[0m Trial 6 finished with value: 4.640199363390965 and parameters: {'n_estimators': 952, 'max_depth': 5, 'learning_rate': 0.010208521702254853}. Best is trial 2 with value: 4.561427986171616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:36,278]\u001b[0m Trial 7 finished with value: 4.511026909749256 and parameters: {'n_estimators': 475, 'max_depth': 8, 'learning_rate': 0.08906404868740961}. Best is trial 7 with value: 4.511026909749256.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:36,824]\u001b[0m Trial 8 finished with value: 5.270924283599874 and parameters: {'n_estimators': 168, 'max_depth': 9, 'learning_rate': 0.010210121451309286}. Best is trial 7 with value: 4.511026909749256.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:37,284]\u001b[0m Trial 9 finished with value: 4.656561962375918 and parameters: {'n_estimators': 461, 'max_depth': 4, 'learning_rate': 0.032350659929890044}. Best is trial 7 with value: 4.511026909749256.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.18\n",
      "{'n_estimators': 475, 'max_depth': 8, 'learning_rate': 0.08906404868740961}\n",
      "0.08906404868740961 8 475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:29:37,591]\u001b[0m A new study created in memory with name: no-name-d7271f72-14ac-4a5c-b110-6c21a511faae\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:38,965]\u001b[0m Trial 0 finished with value: 0.07725574568885285 and parameters: {'n_estimators': 795, 'max_depth': 7, 'learning_rate': 0.018433671965632677}. Best is trial 0 with value: 0.07725574568885285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:39,669]\u001b[0m Trial 1 finished with value: 0.07924740896180944 and parameters: {'n_estimators': 533, 'max_depth': 5, 'learning_rate': 0.04208254747065396}. Best is trial 0 with value: 0.07725574568885285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:41,370]\u001b[0m Trial 2 finished with value: 0.07763385619324074 and parameters: {'n_estimators': 700, 'max_depth': 9, 'learning_rate': 0.01770280320892484}. Best is trial 0 with value: 0.07725574568885285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:42,108]\u001b[0m Trial 3 finished with value: 0.08595745399274655 and parameters: {'n_estimators': 679, 'max_depth': 3, 'learning_rate': 0.04561562834867869}. Best is trial 0 with value: 0.07725574568885285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:42,370]\u001b[0m Trial 4 finished with value: 0.07749781285893156 and parameters: {'n_estimators': 152, 'max_depth': 7, 'learning_rate': 0.06965105799930524}. Best is trial 0 with value: 0.07725574568885285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:43,303]\u001b[0m Trial 5 finished with value: 0.07919469719576003 and parameters: {'n_estimators': 952, 'max_depth': 4, 'learning_rate': 0.010670585010304682}. Best is trial 0 with value: 0.07725574568885285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:43,697]\u001b[0m Trial 6 finished with value: 0.0778167249569284 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.06579518141611923}. Best is trial 0 with value: 0.07725574568885285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:44,795]\u001b[0m Trial 7 finished with value: 0.08573826656431435 and parameters: {'n_estimators': 642, 'max_depth': 7, 'learning_rate': 0.07024872089506164}. Best is trial 0 with value: 0.07725574568885285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:45,701]\u001b[0m Trial 8 finished with value: 0.07787900692858071 and parameters: {'n_estimators': 714, 'max_depth': 5, 'learning_rate': 0.01602823183812845}. Best is trial 0 with value: 0.07725574568885285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:46,817]\u001b[0m Trial 9 finished with value: 0.07787914807008736 and parameters: {'n_estimators': 741, 'max_depth': 6, 'learning_rate': 0.01988584765158263}. Best is trial 0 with value: 0.07725574568885285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.22\n",
      "{'n_estimators': 795, 'max_depth': 7, 'learning_rate': 0.018433671965632677}\n",
      "0.018433671965632677 7 795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:29:47,115]\u001b[0m A new study created in memory with name: no-name-84b5087d-2d9a-4ae7-92c2-9cb09cce049f\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:47,513]\u001b[0m Trial 0 finished with value: 1.5874024832761044 and parameters: {'n_estimators': 426, 'max_depth': 3, 'learning_rate': 0.02960645196036247}. Best is trial 0 with value: 1.5874024832761044.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:49,308]\u001b[0m Trial 1 finished with value: 1.4836874728183815 and parameters: {'n_estimators': 838, 'max_depth': 7, 'learning_rate': 0.015278607351070159}. Best is trial 1 with value: 1.4836874728183815.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:50,254]\u001b[0m Trial 2 finished with value: 1.4638931210540675 and parameters: {'n_estimators': 429, 'max_depth': 7, 'learning_rate': 0.06914657330634404}. Best is trial 2 with value: 1.4638931210540675.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:51,151]\u001b[0m Trial 3 finished with value: 1.4627477090313523 and parameters: {'n_estimators': 699, 'max_depth': 5, 'learning_rate': 0.028673503619654147}. Best is trial 3 with value: 1.4627477090313523.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:51,674]\u001b[0m Trial 4 finished with value: 1.4713972354388578 and parameters: {'n_estimators': 499, 'max_depth': 4, 'learning_rate': 0.06785312611007763}. Best is trial 3 with value: 1.4627477090313523.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:52,238]\u001b[0m Trial 5 finished with value: 1.4590571655041091 and parameters: {'n_estimators': 193, 'max_depth': 9, 'learning_rate': 0.058507514903104414}. Best is trial 5 with value: 1.4590571655041091.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:52,356]\u001b[0m Trial 6 finished with value: 1.9237997608975141 and parameters: {'n_estimators': 104, 'max_depth': 3, 'learning_rate': 0.014057951427901266}. Best is trial 5 with value: 1.4590571655041091.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:53,004]\u001b[0m Trial 7 finished with value: 1.4869473954727883 and parameters: {'n_estimators': 626, 'max_depth': 4, 'learning_rate': 0.032873803889784704}. Best is trial 5 with value: 1.4590571655041091.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:54,583]\u001b[0m Trial 8 finished with value: 1.4988585076608762 and parameters: {'n_estimators': 869, 'max_depth': 6, 'learning_rate': 0.010139137713255801}. Best is trial 5 with value: 1.4590571655041091.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:55,085]\u001b[0m Trial 9 finished with value: 1.5922305864507904 and parameters: {'n_estimators': 211, 'max_depth': 6, 'learning_rate': 0.012613881661786208}. Best is trial 5 with value: 1.4590571655041091.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:55,175]\u001b[0m A new study created in memory with name: no-name-a6c5ecd8-d421-4a3e-831f-ad60122bef66\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.16\n",
      "{'n_estimators': 193, 'max_depth': 9, 'learning_rate': 0.058507514903104414}\n",
      "0.058507514903104414 9 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:29:55,638]\u001b[0m Trial 0 finished with value: 0.634902805610731 and parameters: {'n_estimators': 171, 'max_depth': 9, 'learning_rate': 0.0390528086426521}. Best is trial 0 with value: 0.634902805610731.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:56,271]\u001b[0m Trial 1 finished with value: 0.6422367202526622 and parameters: {'n_estimators': 756, 'max_depth': 3, 'learning_rate': 0.08408900791224225}. Best is trial 0 with value: 0.634902805610731.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:57,541]\u001b[0m Trial 2 finished with value: 0.6606108939544073 and parameters: {'n_estimators': 933, 'max_depth': 5, 'learning_rate': 0.07587046179930908}. Best is trial 0 with value: 0.634902805610731.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:57,759]\u001b[0m Trial 3 finished with value: 0.6762838245885684 and parameters: {'n_estimators': 167, 'max_depth': 4, 'learning_rate': 0.0208715754244675}. Best is trial 0 with value: 0.634902805610731.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:58,081]\u001b[0m Trial 4 finished with value: 0.6484518309528045 and parameters: {'n_estimators': 354, 'max_depth': 3, 'learning_rate': 0.043756247523836375}. Best is trial 0 with value: 0.634902805610731.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:58,594]\u001b[0m Trial 5 finished with value: 0.6443881857309945 and parameters: {'n_estimators': 222, 'max_depth': 7, 'learning_rate': 0.02095570571920499}. Best is trial 0 with value: 0.634902805610731.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:29:59,407]\u001b[0m Trial 6 finished with value: 0.6340324111863767 and parameters: {'n_estimators': 358, 'max_depth': 8, 'learning_rate': 0.022435215936615877}. Best is trial 6 with value: 0.6340324111863767.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:00,419]\u001b[0m Trial 7 finished with value: 0.651321868650194 and parameters: {'n_estimators': 542, 'max_depth': 7, 'learning_rate': 0.09183452501997551}. Best is trial 6 with value: 0.6340324111863767.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:01,166]\u001b[0m Trial 8 finished with value: 0.6339140265171108 and parameters: {'n_estimators': 465, 'max_depth': 6, 'learning_rate': 0.04870579950202104}. Best is trial 8 with value: 0.6339140265171108.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:02,425]\u001b[0m Trial 9 finished with value: 0.6374252640972858 and parameters: {'n_estimators': 819, 'max_depth': 5, 'learning_rate': 0.021913482829858322}. Best is trial 8 with value: 0.6339140265171108.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:02,588]\u001b[0m A new study created in memory with name: no-name-3363ab8f-de84-4a9d-b835-2aa51b2c01b0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.64.2\n",
      "{'n_estimators': 465, 'max_depth': 6, 'learning_rate': 0.04870579950202104}\n",
      "0.04870579950202104 6 465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:30:04,654]\u001b[0m Trial 0 finished with value: 2.721332856114904 and parameters: {'n_estimators': 788, 'max_depth': 7, 'learning_rate': 0.03741112647948003}. Best is trial 0 with value: 2.721332856114904.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:06,542]\u001b[0m Trial 1 finished with value: 2.754597608626619 and parameters: {'n_estimators': 598, 'max_depth': 9, 'learning_rate': 0.09083061786263537}. Best is trial 0 with value: 2.721332856114904.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:07,413]\u001b[0m Trial 2 finished with value: 2.429614879688212 and parameters: {'n_estimators': 464, 'max_depth': 5, 'learning_rate': 0.019736149462369814}. Best is trial 2 with value: 2.429614879688212.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:10,190]\u001b[0m Trial 3 finished with value: 2.4335827398653618 and parameters: {'n_estimators': 846, 'max_depth': 9, 'learning_rate': 0.010541489859642783}. Best is trial 2 with value: 2.429614879688212.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:11,804]\u001b[0m Trial 4 finished with value: 2.7504961321420787 and parameters: {'n_estimators': 497, 'max_depth': 9, 'learning_rate': 0.09189164914552864}. Best is trial 2 with value: 2.429614879688212.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:13,084]\u001b[0m Trial 5 finished with value: 2.719363218967974 and parameters: {'n_estimators': 435, 'max_depth': 8, 'learning_rate': 0.06295703877894827}. Best is trial 2 with value: 2.429614879688212.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:13,763]\u001b[0m Trial 6 finished with value: 2.3375399155739616 and parameters: {'n_estimators': 222, 'max_depth': 8, 'learning_rate': 0.02727646082748046}. Best is trial 6 with value: 2.3375399155739616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:14,560]\u001b[0m Trial 7 finished with value: 2.632537066931225 and parameters: {'n_estimators': 203, 'max_depth': 9, 'learning_rate': 0.09190401754843275}. Best is trial 6 with value: 2.3375399155739616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:15,255]\u001b[0m Trial 8 finished with value: 2.644237190595478 and parameters: {'n_estimators': 836, 'max_depth': 3, 'learning_rate': 0.0824387733892259}. Best is trial 6 with value: 2.3375399155739616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:16,016]\u001b[0m Trial 9 finished with value: 2.6490485474276513 and parameters: {'n_estimators': 845, 'max_depth': 3, 'learning_rate': 0.08522681574238611}. Best is trial 6 with value: 2.3375399155739616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.1\n",
      "{'n_estimators': 222, 'max_depth': 8, 'learning_rate': 0.02727646082748046}\n",
      "0.02727646082748046 8 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:30:16,249]\u001b[0m A new study created in memory with name: no-name-200625f4-d74f-4291-b7b7-70d58018591d\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:17,886]\u001b[0m Trial 0 finished with value: 0.03029090143644239 and parameters: {'n_estimators': 890, 'max_depth': 7, 'learning_rate': 0.06723180081789207}. Best is trial 0 with value: 0.03029090143644239.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:18,424]\u001b[0m Trial 1 finished with value: 0.038886790707625574 and parameters: {'n_estimators': 734, 'max_depth': 3, 'learning_rate': 0.012404010161750271}. Best is trial 0 with value: 0.03029090143644239.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:18,970]\u001b[0m Trial 2 finished with value: 0.03297530328446761 and parameters: {'n_estimators': 392, 'max_depth': 6, 'learning_rate': 0.029811143136375905}. Best is trial 0 with value: 0.03029090143644239.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:19,309]\u001b[0m Trial 3 finished with value: 0.03231573188991977 and parameters: {'n_estimators': 217, 'max_depth': 7, 'learning_rate': 0.05743309654614882}. Best is trial 0 with value: 0.03029090143644239.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:19,972]\u001b[0m Trial 4 finished with value: 0.043412817972216265 and parameters: {'n_estimators': 410, 'max_depth': 6, 'learning_rate': 0.010873720031380681}. Best is trial 0 with value: 0.03029090143644239.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:20,719]\u001b[0m Trial 5 finished with value: 0.035712585907554564 and parameters: {'n_estimators': 563, 'max_depth': 6, 'learning_rate': 0.01278821231906533}. Best is trial 0 with value: 0.03029090143644239.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:22,009]\u001b[0m Trial 6 finished with value: 0.03244064869665243 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.016010746519577176}. Best is trial 0 with value: 0.03029090143644239.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:22,356]\u001b[0m Trial 7 finished with value: 0.03161654363825713 and parameters: {'n_estimators': 185, 'max_depth': 7, 'learning_rate': 0.097775749068225}. Best is trial 0 with value: 0.03029090143644239.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:23,663]\u001b[0m Trial 8 finished with value: 0.03053601331151084 and parameters: {'n_estimators': 876, 'max_depth': 6, 'learning_rate': 0.08032283056177526}. Best is trial 0 with value: 0.03029090143644239.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:25,067]\u001b[0m Trial 9 finished with value: 0.030303095173066664 and parameters: {'n_estimators': 607, 'max_depth': 8, 'learning_rate': 0.08385836848228131}. Best is trial 0 with value: 0.03029090143644239.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.31\n",
      "{'n_estimators': 890, 'max_depth': 7, 'learning_rate': 0.06723180081789207}\n",
      "0.06723180081789207 7 890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:30:25,400]\u001b[0m A new study created in memory with name: no-name-24327df9-247b-48e6-ab4c-e5a3ae5594fa\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:25,855]\u001b[0m Trial 0 finished with value: 0.05189214440502301 and parameters: {'n_estimators': 577, 'max_depth': 3, 'learning_rate': 0.09767856604013968}. Best is trial 0 with value: 0.05189214440502301.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:26,302]\u001b[0m Trial 1 finished with value: 0.053224033306530125 and parameters: {'n_estimators': 361, 'max_depth': 5, 'learning_rate': 0.05266718588556101}. Best is trial 0 with value: 0.05189214440502301.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:27,610]\u001b[0m Trial 2 finished with value: 0.055145557704261036 and parameters: {'n_estimators': 667, 'max_depth': 7, 'learning_rate': 0.011160499121569698}. Best is trial 0 with value: 0.05189214440502301.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:28,008]\u001b[0m Trial 3 finished with value: 0.054516605086095224 and parameters: {'n_estimators': 209, 'max_depth': 5, 'learning_rate': 0.04582450304411592}. Best is trial 0 with value: 0.05189214440502301.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:28,599]\u001b[0m Trial 4 finished with value: 0.05278091335331131 and parameters: {'n_estimators': 321, 'max_depth': 8, 'learning_rate': 0.05151252502856082}. Best is trial 0 with value: 0.05189214440502301.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:29,050]\u001b[0m Trial 5 finished with value: 0.05223537331084403 and parameters: {'n_estimators': 570, 'max_depth': 3, 'learning_rate': 0.09104876478115709}. Best is trial 0 with value: 0.05189214440502301.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:29,532]\u001b[0m Trial 6 finished with value: 0.053444145746506154 and parameters: {'n_estimators': 489, 'max_depth': 4, 'learning_rate': 0.05805746619829466}. Best is trial 0 with value: 0.05189214440502301.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:29,902]\u001b[0m Trial 7 finished with value: 0.0651850587568434 and parameters: {'n_estimators': 290, 'max_depth': 5, 'learning_rate': 0.013042609981427306}. Best is trial 0 with value: 0.05189214440502301.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:30,629]\u001b[0m Trial 8 finished with value: 0.05481266660312689 and parameters: {'n_estimators': 935, 'max_depth': 3, 'learning_rate': 0.021191024747237216}. Best is trial 0 with value: 0.05189214440502301.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:31,508]\u001b[0m Trial 9 finished with value: 0.053669086899827675 and parameters: {'n_estimators': 898, 'max_depth': 4, 'learning_rate': 0.02226388965592297}. Best is trial 0 with value: 0.05189214440502301.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:31,611]\u001b[0m A new study created in memory with name: no-name-18e1fe7f-d587-4724-b666-e6a353f1ba8c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.27\n",
      "{'n_estimators': 577, 'max_depth': 3, 'learning_rate': 0.09767856604013968}\n",
      "0.09767856604013968 3 577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:30:32,254]\u001b[0m Trial 0 finished with value: 0.12121116740511728 and parameters: {'n_estimators': 274, 'max_depth': 6, 'learning_rate': 0.05160246405079092}. Best is trial 0 with value: 0.12121116740511728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:32,435]\u001b[0m Trial 1 finished with value: 0.13722962206332376 and parameters: {'n_estimators': 179, 'max_depth': 3, 'learning_rate': 0.02247537390787348}. Best is trial 0 with value: 0.12121116740511728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:33,216]\u001b[0m Trial 2 finished with value: 0.12210599131822415 and parameters: {'n_estimators': 417, 'max_depth': 6, 'learning_rate': 0.031199920923253896}. Best is trial 0 with value: 0.12121116740511728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:34,820]\u001b[0m Trial 3 finished with value: 0.11908732764341586 and parameters: {'n_estimators': 622, 'max_depth': 8, 'learning_rate': 0.03241515279950935}. Best is trial 3 with value: 0.11908732764341586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:36,312]\u001b[0m Trial 4 finished with value: 0.12271018045421651 and parameters: {'n_estimators': 790, 'max_depth': 7, 'learning_rate': 0.06050557197957833}. Best is trial 3 with value: 0.11908732764341586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:37,929]\u001b[0m Trial 5 finished with value: 0.12368795023353556 and parameters: {'n_estimators': 918, 'max_depth': 6, 'learning_rate': 0.010467944183689747}. Best is trial 3 with value: 0.11908732764341586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:39,054]\u001b[0m Trial 6 finished with value: 0.12484992194465575 and parameters: {'n_estimators': 648, 'max_depth': 6, 'learning_rate': 0.07098917993278299}. Best is trial 3 with value: 0.11908732764341586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:39,761]\u001b[0m Trial 7 finished with value: 0.12569573379569737 and parameters: {'n_estimators': 859, 'max_depth': 3, 'learning_rate': 0.04254822075941113}. Best is trial 3 with value: 0.11908732764341586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:40,691]\u001b[0m Trial 8 finished with value: 0.12261748065982561 and parameters: {'n_estimators': 800, 'max_depth': 4, 'learning_rate': 0.03513099676915195}. Best is trial 3 with value: 0.11908732764341586.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:40,996]\u001b[0m Trial 9 finished with value: 0.12583879872362105 and parameters: {'n_estimators': 334, 'max_depth': 3, 'learning_rate': 0.08118737727783046}. Best is trial 3 with value: 0.11908732764341586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.11\n",
      "{'n_estimators': 622, 'max_depth': 8, 'learning_rate': 0.03241515279950935}\n",
      "0.03241515279950935 8 622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:30:41,297]\u001b[0m A new study created in memory with name: no-name-e8f585d4-979b-4a84-92cb-81bd097cd258\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:44,168]\u001b[0m Trial 0 finished with value: 0.14544894503343433 and parameters: {'n_estimators': 930, 'max_depth': 9, 'learning_rate': 0.030676003461432726}. Best is trial 0 with value: 0.14544894503343433.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:44,885]\u001b[0m Trial 1 finished with value: 0.14865411968112902 and parameters: {'n_estimators': 647, 'max_depth': 4, 'learning_rate': 0.0787018650017772}. Best is trial 0 with value: 0.14544894503343433.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:46,599]\u001b[0m Trial 2 finished with value: 0.14284832842597212 and parameters: {'n_estimators': 652, 'max_depth': 8, 'learning_rate': 0.012295752040205657}. Best is trial 2 with value: 0.14284832842597212.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:46,841]\u001b[0m Trial 3 finished with value: 0.1486193768553119 and parameters: {'n_estimators': 251, 'max_depth': 3, 'learning_rate': 0.0550054112187571}. Best is trial 2 with value: 0.14284832842597212.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:47,826]\u001b[0m Trial 4 finished with value: 0.14425864883649828 and parameters: {'n_estimators': 535, 'max_depth': 6, 'learning_rate': 0.023247450390390178}. Best is trial 2 with value: 0.14284832842597212.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:49,420]\u001b[0m Trial 5 finished with value: 0.14877664952772127 and parameters: {'n_estimators': 757, 'max_depth': 7, 'learning_rate': 0.06388641770461148}. Best is trial 2 with value: 0.14284832842597212.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:50,522]\u001b[0m Trial 6 finished with value: 0.1495839152691913 and parameters: {'n_estimators': 936, 'max_depth': 4, 'learning_rate': 0.0673859189164664}. Best is trial 2 with value: 0.14284832842597212.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:51,484]\u001b[0m Trial 7 finished with value: 0.1451655714423252 and parameters: {'n_estimators': 594, 'max_depth': 5, 'learning_rate': 0.014482759692021598}. Best is trial 2 with value: 0.14284832842597212.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:53,373]\u001b[0m Trial 8 finished with value: 0.14750250897177913 and parameters: {'n_estimators': 709, 'max_depth': 9, 'learning_rate': 0.04976761473040325}. Best is trial 2 with value: 0.14284832842597212.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:54,205]\u001b[0m Trial 9 finished with value: 0.14467257707340964 and parameters: {'n_estimators': 468, 'max_depth': 5, 'learning_rate': 0.0374322111217386}. Best is trial 2 with value: 0.14284832842597212.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.4\n",
      "{'n_estimators': 652, 'max_depth': 8, 'learning_rate': 0.012295752040205657}\n",
      "0.012295752040205657 8 652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:30:54,546]\u001b[0m A new study created in memory with name: no-name-6a5b1984-9382-4618-ba55-c0545812ce3b\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:55,806]\u001b[0m Trial 0 finished with value: 0.11034852621276318 and parameters: {'n_estimators': 738, 'max_depth': 6, 'learning_rate': 0.033304725432375996}. Best is trial 0 with value: 0.11034852621276318.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:56,148]\u001b[0m Trial 1 finished with value: 0.13469679740045032 and parameters: {'n_estimators': 369, 'max_depth': 3, 'learning_rate': 0.026697039945248052}. Best is trial 0 with value: 0.11034852621276318.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:56,355]\u001b[0m Trial 2 finished with value: 0.14738333468546985 and parameters: {'n_estimators': 216, 'max_depth': 3, 'learning_rate': 0.017992901674225906}. Best is trial 0 with value: 0.11034852621276318.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:57,378]\u001b[0m Trial 3 finished with value: 0.12444411265749782 and parameters: {'n_estimators': 337, 'max_depth': 9, 'learning_rate': 0.011844901057938999}. Best is trial 0 with value: 0.11034852621276318.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:58,152]\u001b[0m Trial 4 finished with value: 0.11785504690330917 and parameters: {'n_estimators': 240, 'max_depth': 9, 'learning_rate': 0.0245019765471294}. Best is trial 0 with value: 0.11034852621276318.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:30:58,968]\u001b[0m Trial 5 finished with value: 0.1061983483600751 and parameters: {'n_estimators': 495, 'max_depth': 6, 'learning_rate': 0.09855750081680859}. Best is trial 5 with value: 0.1061983483600751.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:00,261]\u001b[0m Trial 6 finished with value: 0.10731724880767701 and parameters: {'n_estimators': 493, 'max_depth': 9, 'learning_rate': 0.03200858722253722}. Best is trial 5 with value: 0.1061983483600751.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:01,332]\u001b[0m Trial 7 finished with value: 0.11563146744071247 and parameters: {'n_estimators': 769, 'max_depth': 5, 'learning_rate': 0.019200378044978057}. Best is trial 5 with value: 0.1061983483600751.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:02,458]\u001b[0m Trial 8 finished with value: 0.10994440121449436 and parameters: {'n_estimators': 771, 'max_depth': 5, 'learning_rate': 0.061806123011476456}. Best is trial 5 with value: 0.1061983483600751.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:03,391]\u001b[0m Trial 9 finished with value: 0.11517528000925203 and parameters: {'n_estimators': 660, 'max_depth': 5, 'learning_rate': 0.023619752682565377}. Best is trial 5 with value: 0.1061983483600751.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:03,577]\u001b[0m A new study created in memory with name: no-name-eff15fda-3c71-4b1b-93e4-b6bc59ddccdc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.12\n",
      "{'n_estimators': 495, 'max_depth': 6, 'learning_rate': 0.09855750081680859}\n",
      "0.09855750081680859 6 495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:31:04,799]\u001b[0m Trial 0 finished with value: 0.23056679970665134 and parameters: {'n_estimators': 452, 'max_depth': 9, 'learning_rate': 0.07252432665410138}. Best is trial 0 with value: 0.23056679970665134.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:05,276]\u001b[0m Trial 1 finished with value: 0.20720238543832986 and parameters: {'n_estimators': 537, 'max_depth': 3, 'learning_rate': 0.057169969740664406}. Best is trial 1 with value: 0.20720238543832986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:06,322]\u001b[0m Trial 2 finished with value: 0.25266406355802323 and parameters: {'n_estimators': 985, 'max_depth': 4, 'learning_rate': 0.08732686051695696}. Best is trial 1 with value: 0.20720238543832986.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:07,063]\u001b[0m Trial 3 finished with value: 0.19598236155822782 and parameters: {'n_estimators': 556, 'max_depth': 5, 'learning_rate': 0.015008152765867012}. Best is trial 3 with value: 0.19598236155822782.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:08,282]\u001b[0m Trial 4 finished with value: 0.20117772862771388 and parameters: {'n_estimators': 438, 'max_depth': 8, 'learning_rate': 0.032995525578824576}. Best is trial 3 with value: 0.19598236155822782.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:08,629]\u001b[0m Trial 5 finished with value: 0.2005387822126278 and parameters: {'n_estimators': 429, 'max_depth': 3, 'learning_rate': 0.0281849358486478}. Best is trial 3 with value: 0.19598236155822782.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:09,909]\u001b[0m Trial 6 finished with value: 0.19825703448757567 and parameters: {'n_estimators': 747, 'max_depth': 7, 'learning_rate': 0.013836328817532901}. Best is trial 3 with value: 0.19598236155822782.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:10,239]\u001b[0m Trial 7 finished with value: 0.19789010817121164 and parameters: {'n_estimators': 196, 'max_depth': 6, 'learning_rate': 0.030438890625964294}. Best is trial 3 with value: 0.19598236155822782.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:10,762]\u001b[0m Trial 8 finished with value: 0.19832643332851085 and parameters: {'n_estimators': 498, 'max_depth': 4, 'learning_rate': 0.023871953142904627}. Best is trial 3 with value: 0.19598236155822782.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:12,238]\u001b[0m Trial 9 finished with value: 0.2012329263442434 and parameters: {'n_estimators': 760, 'max_depth': 8, 'learning_rate': 0.016624850097971464}. Best is trial 3 with value: 0.19598236155822782.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:12,375]\u001b[0m A new study created in memory with name: no-name-9910fbc2-b227-438f-83ec-81fd17d37b37\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.26\n",
      "{'n_estimators': 556, 'max_depth': 5, 'learning_rate': 0.015008152765867012}\n",
      "0.015008152765867012 5 556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:31:12,658]\u001b[0m Trial 0 finished with value: 0.525310791499864 and parameters: {'n_estimators': 404, 'max_depth': 3, 'learning_rate': 0.04425363039961003}. Best is trial 0 with value: 0.525310791499864.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:13,927]\u001b[0m Trial 1 finished with value: 0.3908835411263765 and parameters: {'n_estimators': 751, 'max_depth': 6, 'learning_rate': 0.012446980217435068}. Best is trial 1 with value: 0.3908835411263765.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:15,006]\u001b[0m Trial 2 finished with value: 0.3739795890404388 and parameters: {'n_estimators': 570, 'max_depth': 7, 'learning_rate': 0.015356044937162994}. Best is trial 2 with value: 0.3739795890404388.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:15,399]\u001b[0m Trial 3 finished with value: 0.5629636074468364 and parameters: {'n_estimators': 141, 'max_depth': 8, 'learning_rate': 0.016747529700369756}. Best is trial 2 with value: 0.3739795890404388.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:16,002]\u001b[0m Trial 4 finished with value: 0.44730188942072935 and parameters: {'n_estimators': 825, 'max_depth': 3, 'learning_rate': 0.06944201415163022}. Best is trial 2 with value: 0.3739795890404388.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:17,689]\u001b[0m Trial 5 finished with value: 0.30273892994997376 and parameters: {'n_estimators': 828, 'max_depth': 8, 'learning_rate': 0.0962390965487154}. Best is trial 5 with value: 0.30273892994997376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:19,066]\u001b[0m Trial 6 finished with value: 0.3863900791977106 and parameters: {'n_estimators': 866, 'max_depth': 6, 'learning_rate': 0.011472160257371286}. Best is trial 5 with value: 0.30273892994997376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:19,961]\u001b[0m Trial 7 finished with value: 0.3112762048018779 and parameters: {'n_estimators': 509, 'max_depth': 7, 'learning_rate': 0.05458361150684372}. Best is trial 5 with value: 0.30273892994997376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:20,128]\u001b[0m Trial 8 finished with value: 0.5296088297584377 and parameters: {'n_estimators': 218, 'max_depth': 3, 'learning_rate': 0.06225263032935957}. Best is trial 5 with value: 0.30273892994997376.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:20,706]\u001b[0m Trial 9 finished with value: 0.5418108652074679 and parameters: {'n_estimators': 149, 'max_depth': 7, 'learning_rate': 0.016918810276512215}. Best is trial 5 with value: 0.30273892994997376.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.64\n",
      "{'n_estimators': 828, 'max_depth': 8, 'learning_rate': 0.0962390965487154}\n",
      "0.0962390965487154 8 828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:31:21,036]\u001b[0m A new study created in memory with name: no-name-4e88956f-4a94-43c5-988b-4f0ea022be9c\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:21,803]\u001b[0m Trial 0 finished with value: 1.0778533683899951 and parameters: {'n_estimators': 625, 'max_depth': 5, 'learning_rate': 0.03825111342629591}. Best is trial 0 with value: 1.0778533683899951.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:21,896]\u001b[0m Trial 1 finished with value: 1.044164004095406 and parameters: {'n_estimators': 122, 'max_depth': 3, 'learning_rate': 0.05205487269515977}. Best is trial 1 with value: 1.044164004095406.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:22,706]\u001b[0m Trial 2 finished with value: 1.1538679725446668 and parameters: {'n_estimators': 926, 'max_depth': 4, 'learning_rate': 0.08178432887623555}. Best is trial 1 with value: 1.044164004095406.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:23,118]\u001b[0m Trial 3 finished with value: 1.0867757413933337 and parameters: {'n_estimators': 636, 'max_depth': 3, 'learning_rate': 0.06141161485163768}. Best is trial 1 with value: 1.044164004095406.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:23,739]\u001b[0m Trial 4 finished with value: 1.0764732157733699 and parameters: {'n_estimators': 864, 'max_depth': 3, 'learning_rate': 0.03571384864185366}. Best is trial 1 with value: 1.044164004095406.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:24,020]\u001b[0m Trial 5 finished with value: 1.0225527871754447 and parameters: {'n_estimators': 102, 'max_depth': 8, 'learning_rate': 0.018723886903277403}. Best is trial 5 with value: 1.0225527871754447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:25,012]\u001b[0m Trial 6 finished with value: 1.1468920253280952 and parameters: {'n_estimators': 545, 'max_depth': 6, 'learning_rate': 0.07439675709473813}. Best is trial 5 with value: 1.0225527871754447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:25,378]\u001b[0m Trial 7 finished with value: 1.0297375475716593 and parameters: {'n_estimators': 211, 'max_depth': 7, 'learning_rate': 0.02448425180908991}. Best is trial 5 with value: 1.0225527871754447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:26,980]\u001b[0m Trial 8 finished with value: 1.0535191448971781 and parameters: {'n_estimators': 850, 'max_depth': 8, 'learning_rate': 0.012151446899972305}. Best is trial 5 with value: 1.0225527871754447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:27,574]\u001b[0m Trial 9 finished with value: 1.0653543893531427 and parameters: {'n_estimators': 809, 'max_depth': 3, 'learning_rate': 0.028181028287588665}. Best is trial 5 with value: 1.0225527871754447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:27,684]\u001b[0m A new study created in memory with name: no-name-20ea4d24-f397-4d80-b380-d94e8de0dfd3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.37\n",
      "{'n_estimators': 102, 'max_depth': 8, 'learning_rate': 0.018723886903277403}\n",
      "0.018723886903277403 8 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:31:28,670]\u001b[0m Trial 0 finished with value: 0.40407772116230367 and parameters: {'n_estimators': 449, 'max_depth': 9, 'learning_rate': 0.012078367892692144}. Best is trial 0 with value: 0.40407772116230367.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:29,461]\u001b[0m Trial 1 finished with value: 0.41343155076357174 and parameters: {'n_estimators': 713, 'max_depth': 4, 'learning_rate': 0.01341121425137411}. Best is trial 0 with value: 0.40407772116230367.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:30,456]\u001b[0m Trial 2 finished with value: 0.417695224393866 and parameters: {'n_estimators': 959, 'max_depth': 3, 'learning_rate': 0.011803748372307854}. Best is trial 0 with value: 0.40407772116230367.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:30,751]\u001b[0m Trial 3 finished with value: 0.41368319933707653 and parameters: {'n_estimators': 316, 'max_depth': 4, 'learning_rate': 0.025507103013668247}. Best is trial 0 with value: 0.40407772116230367.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:31,619]\u001b[0m Trial 4 finished with value: 0.41240582431525474 and parameters: {'n_estimators': 980, 'max_depth': 4, 'learning_rate': 0.02564155176750671}. Best is trial 0 with value: 0.40407772116230367.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:32,259]\u001b[0m Trial 5 finished with value: 0.4059396592855496 and parameters: {'n_estimators': 467, 'max_depth': 6, 'learning_rate': 0.07109689116775379}. Best is trial 0 with value: 0.40407772116230367.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:33,251]\u001b[0m Trial 6 finished with value: 0.40202623104470014 and parameters: {'n_estimators': 519, 'max_depth': 9, 'learning_rate': 0.05941957503017391}. Best is trial 6 with value: 0.40202623104470014.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:33,734]\u001b[0m Trial 7 finished with value: 0.41112018412352375 and parameters: {'n_estimators': 444, 'max_depth': 5, 'learning_rate': 0.029685071084222386}. Best is trial 6 with value: 0.40202623104470014.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:34,985]\u001b[0m Trial 8 finished with value: 0.4073616767135267 and parameters: {'n_estimators': 607, 'max_depth': 8, 'learning_rate': 0.08088773736298982}. Best is trial 6 with value: 0.40202623104470014.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:35,771]\u001b[0m Trial 9 finished with value: 0.40778432497969985 and parameters: {'n_estimators': 417, 'max_depth': 7, 'learning_rate': 0.011184361049131692}. Best is trial 6 with value: 0.40202623104470014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.32\n",
      "{'n_estimators': 519, 'max_depth': 9, 'learning_rate': 0.05941957503017391}\n",
      "0.05941957503017391 9 519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:31:35,988]\u001b[0m A new study created in memory with name: no-name-98a1a40c-9bfa-4838-bbb4-2bdfeeb3d3b0\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:36,462]\u001b[0m Trial 0 finished with value: 0.8536929792577734 and parameters: {'n_estimators': 379, 'max_depth': 5, 'learning_rate': 0.03870833549605539}. Best is trial 0 with value: 0.8536929792577734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:37,992]\u001b[0m Trial 1 finished with value: 0.854321252941195 and parameters: {'n_estimators': 682, 'max_depth': 8, 'learning_rate': 0.02777077302741777}. Best is trial 0 with value: 0.8536929792577734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:39,341]\u001b[0m Trial 2 finished with value: 0.8543097904274598 and parameters: {'n_estimators': 978, 'max_depth': 5, 'learning_rate': 0.023899279428120992}. Best is trial 0 with value: 0.8536929792577734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:39,657]\u001b[0m Trial 3 finished with value: 0.8668074197403154 and parameters: {'n_estimators': 359, 'max_depth': 3, 'learning_rate': 0.07123900745742082}. Best is trial 0 with value: 0.8536929792577734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:41,369]\u001b[0m Trial 4 finished with value: 0.8551482183557619 and parameters: {'n_estimators': 833, 'max_depth': 8, 'learning_rate': 0.014043340403073899}. Best is trial 0 with value: 0.8536929792577734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:42,958]\u001b[0m Trial 5 finished with value: 0.8547630793228438 and parameters: {'n_estimators': 958, 'max_depth': 7, 'learning_rate': 0.03324748947318565}. Best is trial 0 with value: 0.8536929792577734.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:44,176]\u001b[0m Trial 6 finished with value: 0.8532999125491265 and parameters: {'n_estimators': 667, 'max_depth': 8, 'learning_rate': 0.03432491022254679}. Best is trial 6 with value: 0.8532999125491265.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:45,482]\u001b[0m Trial 7 finished with value: 0.849474924639827 and parameters: {'n_estimators': 871, 'max_depth': 6, 'learning_rate': 0.04155294008298901}. Best is trial 7 with value: 0.849474924639827.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:46,246]\u001b[0m Trial 8 finished with value: 0.8520316742394176 and parameters: {'n_estimators': 491, 'max_depth': 6, 'learning_rate': 0.05603560086225186}. Best is trial 7 with value: 0.849474924639827.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:31:47,752]\u001b[0m Trial 9 finished with value: 0.8538340730611391 and parameters: {'n_estimators': 712, 'max_depth': 9, 'learning_rate': 0.03156888852474815}. Best is trial 7 with value: 0.849474924639827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For y = 0.96\n",
      "{'n_estimators': 871, 'max_depth': 6, 'learning_rate': 0.04155294008298901}\n",
      "0.04155294008298901 6 871\n"
     ]
    }
   ],
   "source": [
    "y_values = ['0.21', '0.32.1', '0.41', '0.29', '3.756', '0.35', '0.25', '0.15', \n",
    "                        '0.64.1', '0.38', '0.45', '0.6', '0.33', '0.42', '0.14', '0.9', '0.10', \n",
    "                        '0.3', '0.13', '0.8', '0.19', '0.23', '0.18', '0.22', '0.16', '0.64.2', \n",
    "                        '0.1', '0.31', '0.27', '0.11', '0.4', '0.12', '0.26', '0.64', '0.37', '0.32', '0.96']  # y 값을 포함하는 리스트\n",
    "\n",
    "for y in y_values:\n",
    "    train_X_new = train_X.loc[:, test_data_columns]\n",
    "    train_y_new = train_X.loc[:, y]\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "\n",
    "    # study 실행 (n_trials는 시도 횟수)\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    # 최적화된 하이퍼파라미터 값 출력\n",
    "    print(\"For y =\", y)\n",
    "    print(study.best_params)\n",
    "\n",
    "    (est, depth, rate) = study.best_params.values()\n",
    "    print(rate, depth, est)\n",
    "\n",
    "    bestreg_parametertuning(rate, depth, est, test_data_columns, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.7</th>\n",
       "      <th>278</th>\n",
       "      <th>61</th>\n",
       "      <th>0</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.30</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.778</th>\n",
       "      <th>...</th>\n",
       "      <th>0.31</th>\n",
       "      <th>0.27</th>\n",
       "      <th>0.11</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.12</th>\n",
       "      <th>0.26</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.37</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.019632</td>\n",
       "      <td>-0.001841</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.177928</td>\n",
       "      <td>0.550175</td>\n",
       "      <td>0.018455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007723</td>\n",
       "      <td>0.016784</td>\n",
       "      <td>0.045578</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>0.149726</td>\n",
       "      <td>-0.008465</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.431179</td>\n",
       "      <td>0.140337</td>\n",
       "      <td>0.568936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>133</td>\n",
       "      <td>51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.158220</td>\n",
       "      <td>0.109590</td>\n",
       "      <td>0.040135</td>\n",
       "      <td>0.053696</td>\n",
       "      <td>0.283900</td>\n",
       "      <td>-0.007289</td>\n",
       "      <td>0.165669</td>\n",
       "      <td>0.108198</td>\n",
       "      <td>0.136107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.26</td>\n",
       "      <td>290</td>\n",
       "      <td>287</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032151</td>\n",
       "      <td>-0.017787</td>\n",
       "      <td>2.941139</td>\n",
       "      <td>0.899773</td>\n",
       "      <td>1.238776</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>-0.038205</td>\n",
       "      <td>0.135875</td>\n",
       "      <td>0.904080</td>\n",
       "      <td>3.704916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013580</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.028926</td>\n",
       "      <td>0.022617</td>\n",
       "      <td>-0.014180</td>\n",
       "      <td>-0.009212</td>\n",
       "      <td>-0.066776</td>\n",
       "      <td>0.535388</td>\n",
       "      <td>0.127661</td>\n",
       "      <td>0.745868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.14</td>\n",
       "      <td>898</td>\n",
       "      <td>217</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224858</td>\n",
       "      <td>-0.033515</td>\n",
       "      <td>0.099559</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.411254</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0.538370</td>\n",
       "      <td>0.104851</td>\n",
       "      <td>0.298272</td>\n",
       "      <td>2.026425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0.00</td>\n",
       "      <td>740</td>\n",
       "      <td>54</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014636</td>\n",
       "      <td>-0.012334</td>\n",
       "      <td>0.117354</td>\n",
       "      <td>0.032608</td>\n",
       "      <td>0.084607</td>\n",
       "      <td>0.015811</td>\n",
       "      <td>0.540825</td>\n",
       "      <td>0.425974</td>\n",
       "      <td>0.385703</td>\n",
       "      <td>1.282773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.019632</td>\n",
       "      <td>-0.001841</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.177928</td>\n",
       "      <td>0.550175</td>\n",
       "      <td>0.018455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0.00</td>\n",
       "      <td>92</td>\n",
       "      <td>11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>0.221773</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.047490</td>\n",
       "      <td>0.139738</td>\n",
       "      <td>0.055540</td>\n",
       "      <td>0.169529</td>\n",
       "      <td>0.281917</td>\n",
       "      <td>0.379545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0.00</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110449</td>\n",
       "      <td>0.030579</td>\n",
       "      <td>0.032763</td>\n",
       "      <td>0.098092</td>\n",
       "      <td>-0.003132</td>\n",
       "      <td>0.396347</td>\n",
       "      <td>-0.151690</td>\n",
       "      <td>0.312676</td>\n",
       "      <td>0.076827</td>\n",
       "      <td>0.107394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.7  278   61     0  0.34  0.30   0.5   0.44  0.40  0.778  ...  \\\n",
       "0    0.00    3    1  0.00   0.0   0.0  0.00  0.000   0.0  0.000  ...   \n",
       "1    0.00   32    2  0.71   0.0   0.0  0.00  0.000   0.0  0.000  ...   \n",
       "2    0.00  133   51  0.00   0.0   0.0  0.00  0.000   0.0  0.000  ...   \n",
       "3    1.26  290  287  0.00   0.0   0.0  1.26  0.000   0.0  0.537  ...   \n",
       "4    0.00   23    3  0.00   0.0   0.0  0.00  0.000   0.0  0.000  ...   \n",
       "..    ...  ...  ...   ...   ...   ...   ...    ...   ...    ...  ...   \n",
       "915  0.14  898  217  0.14   0.0   0.0  1.47  0.215   0.0  1.004  ...   \n",
       "916  0.00  740   54  0.09   0.0   0.0  0.09  0.979   0.0  5.213  ...   \n",
       "917  0.00    3    1  0.00   0.0   0.0  0.00  0.000   0.0  0.000  ...   \n",
       "918  0.00   92   11  0.00   0.0   0.0  0.00  0.000   0.0  0.000  ...   \n",
       "919  0.00   29    7  0.00   0.0   0.0  0.00  0.000   0.0  0.000  ...   \n",
       "\n",
       "         0.31      0.27      0.11       0.4      0.12      0.26      0.64  \\\n",
       "0    0.000933  0.005337  0.000799  0.019632 -0.001841  0.008735  0.005209   \n",
       "1   -0.007723  0.016784  0.045578  0.005986  0.149726 -0.008465  0.000696   \n",
       "2    0.003049  0.158220  0.109590  0.040135  0.053696  0.283900 -0.007289   \n",
       "3   -0.032151 -0.017787  2.941139  0.899773  1.238776  0.009469 -0.038205   \n",
       "4   -0.013580  0.006331  0.028926  0.022617 -0.014180 -0.009212 -0.066776   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "915  0.224858 -0.033515  0.099559  0.638000  0.411254  0.020380  0.538370   \n",
       "916  0.014636 -0.012334  0.117354  0.032608  0.084607  0.015811  0.540825   \n",
       "917  0.000933  0.005337  0.000799  0.019632 -0.001841  0.008735  0.005209   \n",
       "918  0.012103  0.221773  0.006330  0.020667  0.047490  0.139738  0.055540   \n",
       "919 -0.110449  0.030579  0.032763  0.098092 -0.003132  0.396347 -0.151690   \n",
       "\n",
       "         0.37      0.32      0.96  \n",
       "0    0.177928  0.550175  0.018455  \n",
       "1    0.431179  0.140337  0.568936  \n",
       "2    0.165669  0.108198  0.136107  \n",
       "3    0.135875  0.904080  3.704916  \n",
       "4    0.535388  0.127661  0.745868  \n",
       "..        ...       ...       ...  \n",
       "915  0.104851  0.298272  2.026425  \n",
       "916  0.425974  0.385703  1.282773  \n",
       "917  0.177928  0.550175  0.018455  \n",
       "918  0.169529  0.281917  0.379545  \n",
       "919  0.312676  0.076827  0.107394  \n",
       "\n",
       "[920 rows x 57 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtestdata=pd.concat([new_test_data_X,new_test_data_y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.7</th>\n",
       "      <th>278</th>\n",
       "      <th>61</th>\n",
       "      <th>0</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.30</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.778</th>\n",
       "      <th>...</th>\n",
       "      <th>0.27</th>\n",
       "      <th>0.11</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.12</th>\n",
       "      <th>0.26</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.37</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.96</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.019632</td>\n",
       "      <td>-0.001841</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.177928</td>\n",
       "      <td>0.550175</td>\n",
       "      <td>0.018455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016784</td>\n",
       "      <td>0.045578</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>0.149726</td>\n",
       "      <td>-0.008465</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.431179</td>\n",
       "      <td>0.140337</td>\n",
       "      <td>0.568936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>133</td>\n",
       "      <td>51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158220</td>\n",
       "      <td>0.109590</td>\n",
       "      <td>0.040135</td>\n",
       "      <td>0.053696</td>\n",
       "      <td>0.283900</td>\n",
       "      <td>-0.007289</td>\n",
       "      <td>0.165669</td>\n",
       "      <td>0.108198</td>\n",
       "      <td>0.136107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.26</td>\n",
       "      <td>290</td>\n",
       "      <td>287</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017787</td>\n",
       "      <td>2.941139</td>\n",
       "      <td>0.899773</td>\n",
       "      <td>1.238776</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>-0.038205</td>\n",
       "      <td>0.135875</td>\n",
       "      <td>0.904080</td>\n",
       "      <td>3.704916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.028926</td>\n",
       "      <td>0.022617</td>\n",
       "      <td>-0.014180</td>\n",
       "      <td>-0.009212</td>\n",
       "      <td>-0.066776</td>\n",
       "      <td>0.535388</td>\n",
       "      <td>0.127661</td>\n",
       "      <td>0.745868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0.7  278   61     0  0.34  0.30   0.5  0.44  0.40  0.778  ...      0.27  \\\n",
       "0  0.00    3    1  0.00   0.0   0.0  0.00   0.0   0.0  0.000  ...  0.005337   \n",
       "1  0.00   32    2  0.71   0.0   0.0  0.00   0.0   0.0  0.000  ...  0.016784   \n",
       "2  0.00  133   51  0.00   0.0   0.0  0.00   0.0   0.0  0.000  ...  0.158220   \n",
       "3  1.26  290  287  0.00   0.0   0.0  1.26   0.0   0.0  0.537  ... -0.017787   \n",
       "4  0.00   23    3  0.00   0.0   0.0  0.00   0.0   0.0  0.000  ...  0.006331   \n",
       "\n",
       "       0.11       0.4      0.12      0.26      0.64      0.37      0.32  \\\n",
       "0  0.000799  0.019632 -0.001841  0.008735  0.005209  0.177928  0.550175   \n",
       "1  0.045578  0.005986  0.149726 -0.008465  0.000696  0.431179  0.140337   \n",
       "2  0.109590  0.040135  0.053696  0.283900 -0.007289  0.165669  0.108198   \n",
       "3  2.941139  0.899773  1.238776  0.009469 -0.038205  0.135875  0.904080   \n",
       "4  0.028926  0.022617 -0.014180 -0.009212 -0.066776  0.535388  0.127661   \n",
       "\n",
       "       0.96  1  \n",
       "0  0.018455  0  \n",
       "1  0.568936  0  \n",
       "2  0.136107  0  \n",
       "3  3.704916  1  \n",
       "4  0.745868  0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtestdata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:36:10,979]\u001b[0m A new study created in memory with name: lgb_boost_opt\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:36:11,170]\u001b[0m Trial 0 finished with value: 0.9845141872453762 and parameters: {'learning_rate': 0.05149450129162212, 'max_depth': 3, 'n_estimators': 111}. Best is trial 0 with value: 0.9845141872453762.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:36:13,381]\u001b[0m Trial 1 finished with value: 0.99031537304876 and parameters: {'learning_rate': 0.028177994367239483, 'max_depth': 5, 'n_estimators': 947}. Best is trial 1 with value: 0.99031537304876.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:36:15,268]\u001b[0m Trial 2 finished with value: 0.9889534041921169 and parameters: {'learning_rate': 0.013004985445763399, 'max_depth': 5, 'n_estimators': 725}. Best is trial 1 with value: 0.99031537304876.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:36:15,481]\u001b[0m Trial 3 finished with value: 0.9724628421792714 and parameters: {'learning_rate': 0.012015590998075388, 'max_depth': 3, 'n_estimators': 134}. Best is trial 1 with value: 0.99031537304876.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:36:16,209]\u001b[0m Trial 4 finished with value: 0.9899392891876998 and parameters: {'learning_rate': 0.04563482475767045, 'max_depth': 4, 'n_estimators': 413}. Best is trial 1 with value: 0.99031537304876.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:36:16,818]\u001b[0m Trial 5 finished with value: 0.9875618805126823 and parameters: {'learning_rate': 0.025733153119304367, 'max_depth': 3, 'n_estimators': 436}. Best is trial 1 with value: 0.99031537304876.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:36:19,211]\u001b[0m Trial 6 finished with value: 0.9899232376593841 and parameters: {'learning_rate': 0.06998417043623208, 'max_depth': 9, 'n_estimators': 558}. Best is trial 1 with value: 0.99031537304876.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:36:20,219]\u001b[0m Trial 7 finished with value: 0.9858989437561549 and parameters: {'learning_rate': 0.01408883664586898, 'max_depth': 9, 'n_estimators': 216}. Best is trial 1 with value: 0.99031537304876.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:36:21,703]\u001b[0m Trial 8 finished with value: 0.987580566639622 and parameters: {'learning_rate': 0.010514105370562027, 'max_depth': 4, 'n_estimators': 769}. Best is trial 1 with value: 0.99031537304876.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:36:25,585]\u001b[0m Trial 9 finished with value: 0.9899636065227553 and parameters: {'learning_rate': 0.019383073751797826, 'max_depth': 8, 'n_estimators': 986}. Best is trial 1 with value: 0.99031537304876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.028177994367239483, 'max_depth': 5, 'n_estimators': 947}\n",
      "Best AUC: 0.9903\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameters to optimize \n",
    "    params={\n",
    "        'boosting_type':'gbdt',\n",
    "        'objective':'binary',\n",
    "        'metric':'binary_logloss',\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.1),\n",
    "        'max_depth':trial.suggest_int('max_depth',3,9),\n",
    "        'n_estimators':trial.suggest_int(\"n_estimators\",100,1000)\n",
    "    }\n",
    "    # Train and evaluate model \n",
    "    lgb_cv=lgb.LGBMClassifier(**params, random_state=42,scale_pos_weight=ratio)\n",
    "    scores=cross_val_score(lgb_cv,train_X,train_y,cv=5,scoring='roc_auc')\n",
    "    auc=scores.mean()\n",
    "    return auc \n",
    "\n",
    "# Define study object and optimize \n",
    "\n",
    "study=optuna.create_study(direction='maximize',study_name='lgb_boost_opt',load_if_exists=True)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Print best hyperparameters and auc\n",
    "print(f'Best hyperparameters: {study.best_params}')\n",
    "print(f'Best AUC: {study.best_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb=lgb.LGBMClassifier(learning_rate= 0.028177994367239483,max_depth= 5,n_estimators=947,scale_pos_weight=ratio,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.028177994367239483, max_depth=5,\n",
       "               n_estimators=947, random_state=42,\n",
       "               scale_pos_weight=1.5879043600562588)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.028177994367239483, max_depth=5,\n",
       "               n_estimators=947, random_state=42,\n",
       "               scale_pos_weight=1.5879043600562588)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.028177994367239483, max_depth=5,\n",
       "               n_estimators=947, random_state=42,\n",
       "               scale_pos_weight=1.5879043600562588)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=lgb.predict_proba(new_test_data_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "def get_clf_prob(y_test, probability):\n",
    "  pred=np.where(probability > 0.50,1,0)\n",
    "  confusion=confusion_matrix(y_test, pred)\n",
    "  accuracy=accuracy_score(y_test,pred)\n",
    "  precision=precision_score(y_test,pred) \n",
    "  recall=recall_score(y_test,pred) \n",
    "  # F1 스코어 추가 \n",
    "  f1=f1_score(y_test,pred,average='macro')\n",
    "  Roc_score=roc_auc_score(y_test,probability)\n",
    "  print('임계값: ', 0.5) \n",
    "  print('오차행렬')\n",
    "  print(confusion) \n",
    "  # f1 score print 추가 \n",
    "  print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}, AUC:{4: .4f}'.format(accuracy,precision,recall,f1,Roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계값:  0.5\n",
      "오차행렬\n",
      "[[521   9]\n",
      " [163 227]]\n",
      "정확도: 0.8130, 정밀도: 0.9619, 재현율: 0.5821, F1:0.7918, AUC: 0.9297\n"
     ]
    }
   ],
   "source": [
    "get_clf_prob(new_test_data_y,pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "son",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
