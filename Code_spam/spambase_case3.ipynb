{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score,roc_auc_score,mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import random\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('/home/iai/son/lastcheck/spambase_train_data.csv')\n",
    "test_data=pd.read_csv('/home/iai/son/lastcheck/spambase_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stage_features=['0.7', '278', '61', '0', '0.34', '0.30', '0.5', '0.44', '0.40', '0.778',\n",
    "                        '0.24', '1.93', '0.39', '1.29', '0.43', '0.2', '0.36', '0.17', '0.20','0.96']\n",
    "test_stage_features=['0.7', '278', '61', '0', '0.34', '0.30', '0.5', '0.44', '0.40', '0.778',\n",
    "                        '0.24', '1.93', '0.39', '1.29', '0.43', '0.2', '0.36', '0.17', '0.20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=train_data.loc[:,train_stage_features]\n",
    "train_y=train_data['1']\n",
    "new_test_data_X=test_data.loc[:,test_stage_features]\n",
    "new_test_data_y=test_data['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=train_y.value_counts()[0]/train_y.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.96'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train에는 있는데 test data에는 없는 컬럼 찾기\n",
    "\n",
    "train_data_columns=np.array(train_X.columns)\n",
    "test_data_columns=np.array(new_test_data_X.columns)\n",
    "np.setdiff1d(train_data_columns,test_data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:41:53,558]\u001b[0m A new study created in memory with name: no-name-0eed969e-135c-49d0-aa6b-034c6eacc550\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:41:54,787]\u001b[0m Trial 0 finished with value: 0.8560944942676644 and parameters: {'n_estimators': 443, 'max_depth': 7, 'learning_rate': 0.02199825365749966}. Best is trial 0 with value: 0.8560944942676644.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:41:55,858]\u001b[0m Trial 1 finished with value: 0.8505050451886884 and parameters: {'n_estimators': 884, 'max_depth': 5, 'learning_rate': 0.04202845262638555}. Best is trial 1 with value: 0.8505050451886884.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:41:57,147]\u001b[0m Trial 2 finished with value: 0.8530636212081486 and parameters: {'n_estimators': 649, 'max_depth': 8, 'learning_rate': 0.043106832401420714}. Best is trial 1 with value: 0.8505050451886884.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:41:57,816]\u001b[0m Trial 3 finished with value: 0.8553789746871852 and parameters: {'n_estimators': 382, 'max_depth': 7, 'learning_rate': 0.02967309335767157}. Best is trial 1 with value: 0.8505050451886884.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:41:58,076]\u001b[0m Trial 4 finished with value: 0.8607180087242388 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.05300005538388497}. Best is trial 1 with value: 0.8505050451886884.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:41:58,276]\u001b[0m Trial 5 finished with value: 0.8548894318213648 and parameters: {'n_estimators': 158, 'max_depth': 4, 'learning_rate': 0.09784686741080247}. Best is trial 1 with value: 0.8505050451886884.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:41:59,621]\u001b[0m Trial 6 finished with value: 0.8818651748712144 and parameters: {'n_estimators': 707, 'max_depth': 8, 'learning_rate': 0.08805671425489643}. Best is trial 1 with value: 0.8505050451886884.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:42:00,689]\u001b[0m Trial 7 finished with value: 0.8512774251345372 and parameters: {'n_estimators': 834, 'max_depth': 5, 'learning_rate': 0.048478088003698114}. Best is trial 1 with value: 0.8505050451886884.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:42:01,432]\u001b[0m Trial 8 finished with value: 0.8827661582388492 and parameters: {'n_estimators': 230, 'max_depth': 7, 'learning_rate': 0.01736420230607943}. Best is trial 1 with value: 0.8505050451886884.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:42:01,769]\u001b[0m Trial 9 finished with value: 0.8569822900911482 and parameters: {'n_estimators': 162, 'max_depth': 8, 'learning_rate': 0.08860055837240188}. Best is trial 1 with value: 0.8505050451886884.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 884, 'max_depth': 5, 'learning_rate': 0.04202845262638555}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import optuna\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "test_data_columns=test_stage_features\n",
    "y='0.96'\n",
    "\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "\n",
    "\n",
    "\n",
    "# Objective 함수 정의\n",
    "def objective(trial):\n",
    "    \n",
    "    # 하이퍼파라미터 탐색할 공간 정의\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators',100,1000),\n",
    "        'max_depth': trial.suggest_int('max_depth',3,9),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate',0.01,0.1),\n",
    "    }\n",
    "    \n",
    "    # LGBMRegressor 모델 객체 생성\n",
    "    model = LGBMRegressor(**params, random_state=42)\n",
    "    \n",
    "    # 교차검증 수행하여 모델 성능 측정\n",
    "    scores = -1 * cross_val_score(model, train_X_new, train_y_new,\n",
    "                                  cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # 교차검증 평균 점수 리턴\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Optuna study 생성\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 884, 'max_depth': 5, 'learning_rate': 0.04202845262638555}\n",
      "Best RMSE: 0.8505\n"
     ]
    }
   ],
   "source": [
    "# Print best hyperparameters and auc\n",
    "\n",
    "print(f'Best hyperparameters: {study.best_params}')\n",
    "print(f'Best RMSE: {study.best_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(est,depth,rate)=study.best_params.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestreg_parametertuning(rate,depth,est,test_data_columns,y):\n",
    "    best_lgbmreg=LGBMRegressor(learning_rate=rate,max_depth=depth,n_estimators=est,random_state=42)\n",
    "    best_lgbmreg.fit(train_X[test_data_columns], train_X[y])\n",
    "    new_test_data_X[y]=best_lgbmreg.predict(new_test_data_X[test_data_columns])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'0.96')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.7</th>\n",
       "      <th>278</th>\n",
       "      <th>61</th>\n",
       "      <th>0</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.30</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.24</th>\n",
       "      <th>1.93</th>\n",
       "      <th>0.39</th>\n",
       "      <th>1.29</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.36</th>\n",
       "      <th>0.17</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.607997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>133</td>\n",
       "      <td>51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.26</td>\n",
       "      <td>290</td>\n",
       "      <td>287</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.769185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.668797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.14</td>\n",
       "      <td>898</td>\n",
       "      <td>217</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.056721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0.00</td>\n",
       "      <td>740</td>\n",
       "      <td>54</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.296863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0.00</td>\n",
       "      <td>92</td>\n",
       "      <td>11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0.00</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.7  278   61     0  0.34  0.30   0.5   0.44  0.40  0.778  0.24  1.93  \\\n",
       "0    0.00    3    1  0.00   0.0   0.0  0.00  0.000   0.0  0.000   0.0  0.00   \n",
       "1    0.00   32    2  0.71   0.0   0.0  0.00  0.000   0.0  0.000   0.0  1.43   \n",
       "2    0.00  133   51  0.00   0.0   0.0  0.00  0.000   0.0  0.000   0.0  0.00   \n",
       "3    1.26  290  287  0.00   0.0   0.0  1.26  0.000   0.0  0.537   0.0  2.53   \n",
       "4    0.00   23    3  0.00   0.0   0.0  0.00  0.000   0.0  0.000   0.0  3.75   \n",
       "..    ...  ...  ...   ...   ...   ...   ...    ...   ...    ...   ...   ...   \n",
       "915  0.14  898  217  0.14   0.0   0.0  1.47  0.215   0.0  1.004   0.0  2.35   \n",
       "916  0.00  740   54  0.09   0.0   0.0  0.09  0.979   0.0  5.213   0.0  3.75   \n",
       "917  0.00    3    1  0.00   0.0   0.0  0.00  0.000   0.0  0.000   0.0  0.00   \n",
       "918  0.00   92   11  0.00   0.0   0.0  0.00  0.000   0.0  0.000   0.0  1.12   \n",
       "919  0.00   29    7  0.00   0.0   0.0  0.00  0.000   0.0  0.000   0.0  0.00   \n",
       "\n",
       "     0.39  1.29  0.43   0.2  0.36  0.17  0.20      0.96  \n",
       "0     0.0  0.00   0.0  0.00   0.0  0.00   0.0 -0.014747  \n",
       "1     0.0  0.00   0.0  0.00   0.0  0.00   0.0  0.607997  \n",
       "2     0.0  0.00   0.0  0.00   0.0  1.09   0.0  0.143300  \n",
       "3     0.0  0.00   0.0  0.00   0.0  0.00   0.0  3.769185  \n",
       "4     0.0  0.00   0.0  0.00   0.0  0.00   0.0  0.668797  \n",
       "..    ...   ...   ...   ...   ...   ...   ...       ...  \n",
       "915   0.0  1.62   0.0  0.29   0.0  0.00   0.0  2.056721  \n",
       "916   0.0  0.00   0.0  0.19   0.0  0.00   0.0  1.296863  \n",
       "917   0.0  0.00   0.0  0.00   0.0  0.00   0.0 -0.014747  \n",
       "918   0.0  0.00   0.0  0.00   0.0  0.56   0.0  0.460694  \n",
       "919   0.0  0.00   0.0  0.00   0.0  3.44   0.0  0.109757  \n",
       "\n",
       "[920 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 15:42:34,424]\u001b[0m A new study created in memory with name: lgb_boost_opt\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:42:36,604]\u001b[0m Trial 0 finished with value: 0.9682281901794564 and parameters: {'learning_rate': 0.012976352518534484, 'max_depth': 7, 'n_estimators': 820}. Best is trial 0 with value: 0.9682281901794564.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:42:38,354]\u001b[0m Trial 1 finished with value: 0.9683193738631031 and parameters: {'learning_rate': 0.017427210583795393, 'max_depth': 6, 'n_estimators': 709}. Best is trial 1 with value: 0.9683193738631031.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:42:39,178]\u001b[0m Trial 2 finished with value: 0.9649793114949535 and parameters: {'learning_rate': 0.019070090964182593, 'max_depth': 3, 'n_estimators': 905}. Best is trial 1 with value: 0.9683193738631031.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:42:39,412]\u001b[0m Trial 3 finished with value: 0.9672773032910726 and parameters: {'learning_rate': 0.09791837669113711, 'max_depth': 4, 'n_estimators': 171}. Best is trial 1 with value: 0.9683193738631031.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:42:41,377]\u001b[0m Trial 4 finished with value: 0.9673483295373313 and parameters: {'learning_rate': 0.010074221090184172, 'max_depth': 6, 'n_estimators': 777}. Best is trial 1 with value: 0.9683193738631031.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:42:42,645]\u001b[0m Trial 5 finished with value: 0.9682778889485469 and parameters: {'learning_rate': 0.02342071675567597, 'max_depth': 7, 'n_estimators': 466}. Best is trial 1 with value: 0.9683193738631031.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:42:43,682]\u001b[0m Trial 6 finished with value: 0.9669562481244297 and parameters: {'learning_rate': 0.031169241727937867, 'max_depth': 4, 'n_estimators': 824}. Best is trial 1 with value: 0.9683193738631031.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:42:44,045]\u001b[0m Trial 7 finished with value: 0.9583397499640007 and parameters: {'learning_rate': 0.013303304643208403, 'max_depth': 3, 'n_estimators': 391}. Best is trial 1 with value: 0.9683193738631031.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:42:45,998]\u001b[0m Trial 8 finished with value: 0.9676615402785881 and parameters: {'learning_rate': 0.011526507042610786, 'max_depth': 6, 'n_estimators': 807}. Best is trial 1 with value: 0.9683193738631031.\u001b[0m\n",
      "\u001b[32m[I 2023-04-26 15:42:48,714]\u001b[0m Trial 9 finished with value: 0.9667330382147477 and parameters: {'learning_rate': 0.02746295035484062, 'max_depth': 9, 'n_estimators': 831}. Best is trial 1 with value: 0.9683193738631031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.017427210583795393, 'max_depth': 6, 'n_estimators': 709}\n",
      "Best AUC: 0.9683\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameters to optimize \n",
    "    params={\n",
    "        'boosting_type':'gbdt',\n",
    "        'objective':'binary',\n",
    "        'metric':'binary_logloss',\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.1),\n",
    "        'max_depth':trial.suggest_int('max_depth',3,9),\n",
    "        'n_estimators':trial.suggest_int(\"n_estimators\",100,1000)\n",
    "    }\n",
    "    # Train and evaluate model \n",
    "    lgb_cv=lgb.LGBMClassifier(**params, random_state=42,scale_pos_weight=ratio)\n",
    "    scores=cross_val_score(lgb_cv,train_X,train_y,cv=5,scoring='roc_auc')\n",
    "    auc=scores.mean()\n",
    "    return auc \n",
    "\n",
    "# Define study object and optimize \n",
    "\n",
    "study=optuna.create_study(direction='maximize',study_name='lgb_boost_opt',load_if_exists=True)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Print best hyperparameters and auc\n",
    "print(f'Best hyperparameters: {study.best_params}')\n",
    "print(f'Best AUC: {study.best_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb=lgb.LGBMClassifier(learning_rate= 0.017427210583795393,max_depth=6,n_estimators=709,scale_pos_weight=ratio,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.017427210583795393, max_depth=6,\n",
       "               n_estimators=709, random_state=42,\n",
       "               scale_pos_weight=1.5879043600562588)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.017427210583795393, max_depth=6,\n",
       "               n_estimators=709, random_state=42,\n",
       "               scale_pos_weight=1.5879043600562588)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.017427210583795393, max_depth=6,\n",
       "               n_estimators=709, random_state=42,\n",
       "               scale_pos_weight=1.5879043600562588)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=lgb.predict_proba(new_test_data_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "def get_clf_prob(y_test, probability):\n",
    "  pred=np.where(probability > 0.50,1,0)\n",
    "  confusion=confusion_matrix(y_test, pred)\n",
    "  accuracy=accuracy_score(y_test,pred)\n",
    "  precision=precision_score(y_test,pred) \n",
    "  recall=recall_score(y_test,pred) \n",
    "  # F1 스코어 추가 \n",
    "  f1=f1_score(y_test,pred,average='macro')\n",
    "  Roc_score=roc_auc_score(y_test,probability)\n",
    "  print('임계값: ', 0.5) \n",
    "  print('오차행렬')\n",
    "  print(confusion) \n",
    "  # f1 score print 추가 \n",
    "  print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}, AUC:{4: .4f}'.format(accuracy,precision,recall,f1,Roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계값:  0.5\n",
      "오차행렬\n",
      "[[491  39]\n",
      " [ 61 329]]\n",
      "정확도: 0.8913, 정밀도: 0.8940, 재현율: 0.8436, F1:0.8878, AUC: 0.9520\n"
     ]
    }
   ],
   "source": [
    "get_clf_prob(new_test_data_y,pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "son",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
