{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요한 라이브러리 Import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score,roc_auc_score,mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import random\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train data와 Test data를 로드해준다.\n",
    "\n",
    "train_data=pd.read_csv('/dshome/WoongLab/heo/construction_oil/preprocessed_data/breastcancer_train_data.csv')\n",
    "test_data=pd.read_csv('/dshome/WoongLab/heo/construction_oil/preprocessed_data/breastcancer_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stage_features=['A Stage','differentiate','Race','T Stage ','Grade','Estrogen Status','Progesterone Status','Marital Status','N Stage','Survival Months']\n",
    "test_stage_features=['A Stage','differentiate','Race','T Stage ','Grade','Estrogen Status','Progesterone Status','Marital Status','N Stage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train data와 Test data의 독립변수와 종속변수 설정하기\n",
    "\n",
    "train_X=train_data.loc[:,train_stage_features]\n",
    "train_y=train_data['Status']\n",
    "new_test_data_X=test_data.loc[:,test_stage_features]\n",
    "new_test_data_y=test_data['Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weight을 구하기 위해 y label의 비율을 뜻하는 ratio 변수 생성해주기\n",
    "\n",
    "ratio=train_y.value_counts()[0]/train_y.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Survival Months'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train에는 있는데 test data에는 없는 컬럼 찾기\n",
    "\n",
    "train_data_columns=np.array(train_X.columns)\n",
    "test_data_columns=np.array(new_test_data_X.columns)\n",
    "np.setdiff1d(train_data_columns,test_data_columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data에 없는 변수들을 다 생성했으므로 LightgbmRegressor 분류모델을 만듬\n",
    "\n",
    "### 베이지안 최적화해주기 - LightgbmRegressor\n",
    "\n",
    "**1. 5-fold 교차검증 이용해서 Train data로 Validation set을 RMSE가 최저였을 때의 하이퍼파라미터 구하기**\n",
    "\n",
    "**2. Learning rate 0.01~0.1, max_depth 3~9, n_estimators 100~1000이었을 때에서 가장 최적의 하이퍼파라미터 구하기**\n",
    "\n",
    "**3. Test data에 Survival Months 피처를 하나를 생성해준다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 12:12:03,019]\u001b[0m A new study created in memory with name: no-name-0cd332f6-57ca-4906-81fd-0b855b524147\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:12:06,281]\u001b[0m Trial 0 finished with value: 536.3548642148135 and parameters: {'n_estimators': 716, 'max_depth': 5, 'learning_rate': 0.0633900438740771}. Best is trial 0 with value: 536.3548642148135.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:12:15,198]\u001b[0m Trial 1 finished with value: 544.3246950510107 and parameters: {'n_estimators': 986, 'max_depth': 9, 'learning_rate': 0.027833255509034382}. Best is trial 0 with value: 536.3548642148135.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:12:24,030]\u001b[0m Trial 2 finished with value: 567.1977679902386 and parameters: {'n_estimators': 989, 'max_depth': 9, 'learning_rate': 0.0719126387927958}. Best is trial 0 with value: 536.3548642148135.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:12:24,643]\u001b[0m Trial 3 finished with value: 511.0212399947296 and parameters: {'n_estimators': 267, 'max_depth': 3, 'learning_rate': 0.061639523506063464}. Best is trial 3 with value: 511.0212399947296.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:12:30,413]\u001b[0m Trial 4 finished with value: 563.0528845249862 and parameters: {'n_estimators': 793, 'max_depth': 7, 'learning_rate': 0.08975901925333567}. Best is trial 3 with value: 511.0212399947296.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:12:33,023]\u001b[0m Trial 5 finished with value: 522.7130541821762 and parameters: {'n_estimators': 455, 'max_depth': 6, 'learning_rate': 0.03339103930257792}. Best is trial 3 with value: 511.0212399947296.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:12:40,202]\u001b[0m Trial 6 finished with value: 558.5047001505798 and parameters: {'n_estimators': 790, 'max_depth': 9, 'learning_rate': 0.06082448420210512}. Best is trial 3 with value: 511.0212399947296.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:12:45,404]\u001b[0m Trial 7 finished with value: 529.2609073999726 and parameters: {'n_estimators': 581, 'max_depth': 8, 'learning_rate': 0.02561916505608328}. Best is trial 3 with value: 511.0212399947296.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:12:48,466]\u001b[0m Trial 8 finished with value: 539.7537463932498 and parameters: {'n_estimators': 527, 'max_depth': 6, 'learning_rate': 0.07154951379901267}. Best is trial 3 with value: 511.0212399947296.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:12:49,642]\u001b[0m Trial 9 finished with value: 512.0197490454 and parameters: {'n_estimators': 189, 'max_depth': 6, 'learning_rate': 0.029754588569735462}. Best is trial 3 with value: 511.0212399947296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 267, 'max_depth': 3, 'learning_rate': 0.061639523506063464}\n"
     ]
    }
   ],
   "source": [
    "# 변수중요도가 가장 높은 Survival Months을 예측하는 모형 만들어 주기\n",
    "\n",
    "import optuna\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "test_data_columns=test_stage_features\n",
    "y='Survival Months'\n",
    "\n",
    "train_X_new=train_X.loc[:,test_data_columns]\n",
    "train_y_new=train_X.loc[:,y]\n",
    "\n",
    "\n",
    "\n",
    "# Objective 함수 정의\n",
    "def objective(trial):\n",
    "    \n",
    "    # 하이퍼파라미터 탐색할 공간 정의\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators',100,1000),\n",
    "        'max_depth': trial.suggest_int('max_depth',3,9),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate',0.01,0.1),\n",
    "    }\n",
    "    \n",
    "    # LGBMRegressor 모델 객체 생성\n",
    "    model = LGBMRegressor(**params, random_state=42)\n",
    "    \n",
    "    # 교차검증 수행하여 모델 성능 측정\n",
    "    scores = -1 * cross_val_score(model, train_X_new, train_y_new,\n",
    "                                  cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # 교차검증 평균 점수 리턴\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Optuna study 생성\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# study 실행 (n_trials는 시도 횟수)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적화된 하이퍼파라미터 값 출력\n",
    "print(study.best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 267, 'max_depth': 3, 'learning_rate': 0.061639523506063464}\n",
      "Best RMSE: 511.0212\n"
     ]
    }
   ],
   "source": [
    "# Print best hyperparameters and auc\n",
    "\n",
    "print(f'Best hyperparameters: {study.best_params}')\n",
    "print(f'Best RMSE: {study.best_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(est,depth,rate)=study.best_params.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞서 구한 최적의 파라미터들로 파인튜닝하여 Test data에 Survival Months 피처 만들어주기\n",
    "\n",
    "def bestreg_parametertuning(rate,depth,est,test_data_columns,y):\n",
    "    best_lgbmreg=LGBMRegressor(learning_rate=rate,max_depth=depth,n_estimators=est,random_state=42)\n",
    "    best_lgbmreg.fit(train_X[test_data_columns], train_X[y])\n",
    "    new_test_data_X[y]=best_lgbmreg.predict(new_test_data_X[test_data_columns])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestreg_parametertuning(rate,depth,est,test_data_columns,'Survival Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A Stage</th>\n",
       "      <th>differentiate</th>\n",
       "      <th>Race</th>\n",
       "      <th>T Stage</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Estrogen Status</th>\n",
       "      <th>Progesterone Status</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>N Stage</th>\n",
       "      <th>Survival Months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73.214154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.470363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.925537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72.913847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.073051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72.913847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>67.543090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.143556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74.228422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.466583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>805 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A Stage  differentiate  Race  T Stage   Grade  Estrogen Status  \\\n",
       "0          1              3     2         1      1                1   \n",
       "1          1              0     2         2      2                1   \n",
       "2          1              0     2         1      2                1   \n",
       "3          1              1     2         1      3                1   \n",
       "4          1              0     2         1      2                1   \n",
       "..       ...            ...   ...       ...    ...              ...   \n",
       "800        1              1     2         1      3                1   \n",
       "801        1              0     2         2      2                1   \n",
       "802        1              0     2         0      2                1   \n",
       "803        1              3     2         0      1                1   \n",
       "804        1              1     2         2      3                1   \n",
       "\n",
       "     Progesterone Status  Marital Status  N Stage  Survival Months  \n",
       "0                      1               1        1        73.214154  \n",
       "1                      0               1        0        71.470363  \n",
       "2                      1               1        1        71.925537  \n",
       "3                      1               1        0        72.913847  \n",
       "4                      1               0        0        70.073051  \n",
       "..                   ...             ...      ...              ...  \n",
       "800                    1               1        0        72.913847  \n",
       "801                    1               1        2        67.543090  \n",
       "802                    1               0        0        74.143556  \n",
       "803                    1               1        0        74.228422  \n",
       "804                    0               1        1        71.466583  \n",
       "\n",
       "[805 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_data_X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 베이지안 최적화해주기 - LightgbmClassifier\n",
    "\n",
    "**1. 5-fold 교차검증 이용해서 Train data로 Validation set을 Auc가 최고였을 때의 하이퍼파라미터 구하기**\n",
    "\n",
    "**2. Learning rate 0.01~0.1, max_depth 3~9, n_estimators 100~1000이었을 때에서 가장 최적의 하이퍼파라미터 구하기**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 12:14:09,510]\u001b[0m A new study created in memory with name: lgb_boost_opt\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:14:11,658]\u001b[0m Trial 0 finished with value: 0.8509068928325622 and parameters: {'learning_rate': 0.07993393703676338, 'max_depth': 4, 'n_estimators': 505}. Best is trial 0 with value: 0.8509068928325622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:14:14,580]\u001b[0m Trial 1 finished with value: 0.843737084962511 and parameters: {'learning_rate': 0.04722512813320992, 'max_depth': 8, 'n_estimators': 313}. Best is trial 0 with value: 0.8509068928325622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:14:19,028]\u001b[0m Trial 2 finished with value: 0.8428905094988226 and parameters: {'learning_rate': 0.03065838907224806, 'max_depth': 6, 'n_estimators': 753}. Best is trial 0 with value: 0.8509068928325622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:14:20,383]\u001b[0m Trial 3 finished with value: 0.869105342638389 and parameters: {'learning_rate': 0.011531144266024003, 'max_depth': 4, 'n_estimators': 335}. Best is trial 3 with value: 0.869105342638389.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:14:23,871]\u001b[0m Trial 4 finished with value: 0.8515871460291982 and parameters: {'learning_rate': 0.012417418467820752, 'max_depth': 8, 'n_estimators': 399}. Best is trial 3 with value: 0.869105342638389.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:14:29,479]\u001b[0m Trial 5 finished with value: 0.8537729418847186 and parameters: {'learning_rate': 0.013467311987453002, 'max_depth': 6, 'n_estimators': 892}. Best is trial 3 with value: 0.869105342638389.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:14:32,844]\u001b[0m Trial 6 finished with value: 0.8593030856679984 and parameters: {'learning_rate': 0.018775554374138706, 'max_depth': 5, 'n_estimators': 674}. Best is trial 3 with value: 0.869105342638389.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:14:36,881]\u001b[0m Trial 7 finished with value: 0.8570139104898514 and parameters: {'learning_rate': 0.0187159841016336, 'max_depth': 5, 'n_estimators': 862}. Best is trial 3 with value: 0.869105342638389.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:14:42,549]\u001b[0m Trial 8 finished with value: 0.836855565433547 and parameters: {'learning_rate': 0.036930677352276384, 'max_depth': 7, 'n_estimators': 838}. Best is trial 3 with value: 0.869105342638389.\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 12:14:44,729]\u001b[0m Trial 9 finished with value: 0.8463820717134702 and parameters: {'learning_rate': 0.08608438350339616, 'max_depth': 4, 'n_estimators': 685}. Best is trial 3 with value: 0.869105342638389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.011531144266024003, 'max_depth': 4, 'n_estimators': 335}\n",
      "Best AUC: 0.8691\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameters to optimize \n",
    "    params={\n",
    "        'boosting_type':'gbdt',\n",
    "        'objective':'binary',\n",
    "        'metric':'binary_logloss',\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.1),\n",
    "        'max_depth':trial.suggest_int('max_depth',3,9),\n",
    "        'n_estimators':trial.suggest_int(\"n_estimators\",100,1000)\n",
    "    }\n",
    "    # Train and evaluate model \n",
    "    lgb_cv=lgb.LGBMClassifier(**params, random_state=42,scale_pos_weight=ratio)\n",
    "    scores=cross_val_score(lgb_cv,train_X,train_y,cv=5,scoring='roc_auc')\n",
    "    auc=scores.mean()\n",
    "    return auc \n",
    "\n",
    "# Define study object and optimize \n",
    "\n",
    "study=optuna.create_study(direction='maximize',study_name='lgb_boost_opt',load_if_exists=True)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Print best hyperparameters and auc\n",
    "print(f'Best hyperparameters: {study.best_params}')\n",
    "print(f'Best AUC: {study.best_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb=lgb.LGBMClassifier(learning_rate= 0.011531144266024003,max_depth=4,n_estimators=335,scale_pos_weight=ratio,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.011531144266024003, max_depth=4,\n",
       "               n_estimators=335, random_state=42,\n",
       "               scale_pos_weight=5.529411764705882)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.011531144266024003, max_depth=4,\n",
       "               n_estimators=335, random_state=42,\n",
       "               scale_pos_weight=5.529411764705882)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.011531144266024003, max_depth=4,\n",
       "               n_estimators=335, random_state=42,\n",
       "               scale_pos_weight=5.529411764705882)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=lgb.predict_proba(new_test_data_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능을 평가할 수 있는 함수 만들어주기\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "def get_clf_prob(y_test, probability):\n",
    "  pred=np.where(probability > 0.50,1,0)\n",
    "  confusion=confusion_matrix(y_test, pred)\n",
    "  accuracy=accuracy_score(y_test,pred)\n",
    "  precision=precision_score(y_test,pred) \n",
    "  recall=recall_score(y_test,pred) \n",
    "  # F1 스코어 추가 \n",
    "  f1=f1_score(y_test,pred,average='macro')\n",
    "  Roc_score=roc_auc_score(y_test,probability)\n",
    "  print('임계값: ', 0.5) \n",
    "  print('오차행렬')\n",
    "  print(confusion) \n",
    "  # f1 score print 추가 \n",
    "  print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}, AUC:{4: .4f}'.format(accuracy,precision,recall,f1,Roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계값:  0.5\n",
      "오차행렬\n",
      "[[612  70]\n",
      " [ 82  41]]\n",
      "정확도: 0.8112, 정밀도: 0.3694, 재현율: 0.3333, F1:0.6200, AUC: 0.6822\n"
     ]
    }
   ],
   "source": [
    "get_clf_prob(new_test_data_y,pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "son",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
